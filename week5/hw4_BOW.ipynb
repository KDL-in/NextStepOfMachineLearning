{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"“hw4_BOW.ipynb”的副本","provenance":[{"file_id":"134vcAJGaJQpBnXeNBGBp42HStSZPIp1t","timestamp":1586594419137}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"XPevzrFV5dcl","colab_type":"text"},"source":["# Bag of Words"]},{"cell_type":"code","metadata":{"id":"8LAsexcU6wIf","colab_type":"code","colab":{}},"source":["path_prefix = './'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Flw8rdFP3_oa","colab_type":"code","outputId":"f61af5ee-24a7-4748-b267-944f56acdc00","executionInfo":{"status":"ok","timestamp":1586594446696,"user_tz":-480,"elapsed":7996,"user":{"displayName":"KD Lin","photoUrl":"","userId":"07150804307204552996"}},"colab":{"base_uri":"https://localhost:8080/","height":197}},"source":["!gdown --id '1lz0Wtwxsh5YCPdqQ3E3l_nbfJT1N13V8' --output data.zip\n","!unzip data.zip\n","!ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1lz0Wtwxsh5YCPdqQ3E3l_nbfJT1N13V8\n","To: /content/data.zip\n","45.1MB [00:00, 124MB/s] \n","Archive:  data.zip\n","  inflating: training_label.txt      \n","  inflating: testing_data.txt        \n","  inflating: training_nolabel.txt    \n","data.zip     testing_data.txt\t training_nolabel.txt\n","sample_data  training_label.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JkNZ-T4V5vBn","colab_type":"code","colab":{}},"source":["# this is for filtering the warnings\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mlr2DSoN5vfc","colab_type":"code","colab":{}},"source":["# utils.py\n","# 這個block用來先定義一些等等常用到的函式\n","import torch\n","import numpy as np\n","import pandas as pd\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","def load_training_data(path='training_label.txt'):\n","    # 把training時需要的data讀進來\n","    # 如果是'training_label.txt'，需要讀取label，如果是'training_nolabel.txt'，不需要讀取label\n","    if 'training_label' in path:\n","        with open(path, 'r') as f:\n","            lines = f.readlines()\n","            lines = [line.strip('\\n').split(' ') for line in lines]\n","        x = [line[2:] for line in lines]\n","        y = [line[0] for line in lines]\n","        return x, y\n","    else:\n","        with open(path, 'r') as f:\n","            lines = f.readlines()\n","            x = [line.strip('\\n').split(' ') for line in lines]\n","        return x\n","\n","def load_testing_data(path='testing_data'):\n","    # 把testing時需要的data讀進來\n","    with open(path, 'r') as f:\n","        lines = f.readlines()\n","        X = [\"\".join(line.strip('\\n').split(\",\")[1:]).strip() for line in lines[1:]]\n","        X = [sen.split(' ') for sen in X]\n","    return X\n","\n","def evaluation(outputs, labels):\n","    #outputs => probability (float)\n","    #labels => labels\n","    outputs[outputs>=0.5] = 1 # 大於等於0.5為有惡意\n","    outputs[outputs<0.5] = 0 # 小於0.5為無惡意\n","    correct = torch.sum(torch.eq(outputs, labels)).item()\n","    return correct"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jhqkDaWu5yj6","colab_type":"code","colab":{}},"source":["import numpy as np\n","# bow.py\n","class BOW():\n","    def __init__(self, max_len=10000):\n","        self.wordfreq = {}\n","        self.vector_size = max_len\n","        self.word2idx = {}\n","    def bow(self, train_sentences, test_sentences):\n","        # 统计词频\n","        for sentence in train_sentences + test_sentences:\n","            for word in sentence:\n","                if word in self.wordfreq.keys(): self.wordfreq[word] += 1\n","                else: self.wordfreq[word] = 1\n","        self.wordfreq = sorted(self.wordfreq.items(), key=lambda x: x[1], reverse=True)\n","        if self.vector_size > len(self.wordfreq): self.vector_size = len(self.wordfreq)\n","        # 按照词频排序编号\n","        for idx, (word, freq) in enumerate(self.wordfreq):\n","            if idx == self.vector_size: break\n","            self.word2idx[word] = len(self.word2idx)\n","        self.train_bow_list = np.zeros((len(train_sentences), self.vector_size))\n","        self.test_bow_list = np.zeros((len(test_sentences), self.vector_size))\n","        # bag of word 统计\n","        for idx, sentence in enumerate(train_sentences):\n","            for word in sentence:\n","                if word in self.word2idx.keys():\n","                    self.train_bow_list[idx][self.word2idx[word]] += 1\n","        for idx, sentence in enumerate(test_sentences):\n","            for word in sentence:\n","                if word in self.word2idx.keys():\n","                    self.test_bow_list[idx][self.word2idx[word]] += 1\n","    def __getitem__(self, data_type):\n","        if data_type == 'train':\n","            return torch.FloatTensor(self.train_bow_list)\n","        elif data_type == 'test':\n","            return torch.FloatTensor(self.test_bow_list)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ub1d5aqY52wr","colab_type":"code","colab":{}},"source":["# data.py\n","# 實作了dataset所需要的'__init__', '__getitem__', '__len__'\n","# 好讓dataloader能使用\n","import torch\n","from torch.utils import data\n","\n","class TwitterDataset(data.Dataset):\n","    \"\"\"\n","    Expected data shape like:(data_num, data_len)\n","    Data can be a list of numpy array or a list of lists\n","    input data shape : (data_num, seq_len, feature_dim)\n","    \n","    __len__ will return the number of data\n","    \"\"\"\n","    def __init__(self, X, y):\n","        self.data = X\n","        self.label = y\n","    def __getitem__(self, idx):\n","        if self.label is None: return self.data[idx]\n","        return self.data[idx], self.label[idx]\n","    def __len__(self):\n","        return len(self.data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RhulO2dg55aK","colab_type":"code","colab":{}},"source":["# model.py\n","# 這個block是要拿來訓練的模型\n","import torch\n","from torch import nn\n","class LSTM_Net(nn.Module):\n","    def __init__(self, embedding_dim, num_layers):\n","        super(LSTM_Net, self).__init__()\n","        self.num_layers = num_layers\n","        self.classifier = nn.Sequential( nn.Linear(embedding_dim, 512),\n","                                         nn.Linear(512, 128),\n","                                         nn.Linear(128, 1),\n","                                         nn.Sigmoid() )\n","    def forward(self, inputs):\n","        x = self.classifier(inputs.float())\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tElKi-3158di","colab_type":"code","colab":{}},"source":["# train.py\n","# 這個block是用來訓練模型的\n","import torch\n","from torch import nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","def training(batch_size, n_epoch, lr, model_dir, train, valid, model, device):\n","    total = sum(p.numel() for p in model.parameters())\n","    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    print('\\nstart training, parameter total:{}, trainable:{}\\n'.format(total, trainable))\n","    model.train() # 將model的模式設為train，這樣optimizer就可以更新model的參數\n","    criterion = nn.BCELoss() # 定義損失函數，這裡我們使用binary cross entropy loss\n","    t_batch = len(train) \n","    v_batch = len(valid) \n","    optimizer = optim.Adam(model.parameters(), lr=lr) # 將模型的參數給optimizer，並給予適當的learning rate\n","    total_loss, total_acc, best_acc = 0, 0, 0\n","    for epoch in range(n_epoch):\n","        total_loss, total_acc = 0, 0\n","        # 這段做training\n","        for i, (inputs, labels) in enumerate(train):\n","            inputs = inputs.to(device, dtype=torch.long) # device為\"cuda\"，將inputs轉成torch.cuda.LongTensor\n","            labels = labels.to(device, dtype=torch.float) # device為\"cuda\"，將labels轉成torch.cuda.FloatTensor，因為等等要餵進criterion，所以型態要是float\n","            optimizer.zero_grad() # 由於loss.backward()的gradient會累加，所以每次餵完一個batch後需要歸零\n","            outputs = model(inputs) # 將input餵給模型\n","            outputs = outputs.squeeze() # 去掉最外面的dimension，好讓outputs可以餵進criterion()\n","            loss = criterion(outputs, labels) # 計算此時模型的training loss\n","            loss.backward() # 算loss的gradient\n","            optimizer.step() # 更新訓練模型的參數\n","            correct = evaluation(outputs, labels) # 計算此時模型的training accuracy\n","            total_acc += (correct / batch_size)\n","            total_loss += loss.item()\n","            print('[ Epoch{}: {}/{} ] loss:{:.3f} acc:{:.3f} '.format(\n","            \tepoch+1, i+1, t_batch, loss.item(), correct*100/batch_size), end='\\r')\n","        print('\\nTrain | Loss:{:.5f} Acc: {:.3f}'.format(total_loss/t_batch, total_acc/t_batch*100))\n","\n","        # 這段做validation\n","        model.eval() # 將model的模式設為eval，這樣model的參數就會固定住\n","        with torch.no_grad():\n","            total_loss, total_acc = 0, 0\n","            for i, (inputs, labels) in enumerate(valid):\n","                inputs = inputs.to(device, dtype=torch.long) # device為\"cuda\"，將inputs轉成torch.cuda.LongTensor\n","                labels = labels.to(device, dtype=torch.float) # device為\"cuda\"，將labels轉成torch.cuda.FloatTensor，因為等等要餵進criterion，所以型態要是float\n","                outputs = model(inputs) # 將input餵給模型\n","                outputs = outputs.squeeze() # 去掉最外面的dimension，好讓outputs可以餵進criterion()\n","                loss = criterion(outputs, labels) # 計算此時模型的validation loss\n","                correct = evaluation(outputs, labels) # 計算此時模型的validation accuracy\n","                total_acc += (correct / batch_size)\n","                total_loss += loss.item()\n","\n","            print(\"Valid | Loss:{:.5f} Acc: {:.3f} \".format(total_loss/v_batch, total_acc/v_batch*100))\n","            if total_acc > best_acc:\n","                # 如果validation的結果優於之前所有的結果，就把當下的模型存下來以備之後做預測時使用\n","                best_acc = total_acc\n","                #torch.save(model, \"{}/val_acc_{:.3f}.model\".format(model_dir,total_acc/v_batch*100))\n","                torch.save(model, \"{}/ckpt_bow\".format(model_dir))\n","                print('saving model with acc {:.3f}'.format(total_acc/v_batch*100))\n","        print('-----------------------------------------------')\n","        model.train() # 將model的模式設為train，這樣optimizer就可以更新model的參數（因為剛剛轉成eval模式）\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"voDSa3m56AE2","colab_type":"code","colab":{}},"source":["# test.py\n","# 這個block用來對testing_data.txt做預測\n","import torch\n","from torch import nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","def testing(batch_size, test_loader, model, device):\n","    model.eval()\n","    ret_output = []\n","    with torch.no_grad():\n","        for i, inputs in enumerate(test_loader):\n","            inputs = inputs.to(device, dtype=torch.long)\n","            outputs = model(inputs)\n","            outputs = outputs.squeeze()\n","            outputs[outputs>=0.5] = 1 # 大於等於0.5為負面\n","            outputs[outputs<0.5] = 0 # 小於0.5為正面\n","            ret_output += outputs.int().tolist()\n","    \n","    return ret_output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vrQ7D_5D6LMs","colab_type":"code","outputId":"a47a48b6-118b-4215-c480-f6a629c2b874","executionInfo":{"status":"ok","timestamp":1586594841965,"user_tz":-480,"elapsed":403224,"user":{"displayName":"KD Lin","photoUrl":"","userId":"07150804307204552996"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# main.py\n","import os\n","import torch\n","import argparse\n","import numpy as np\n","from torch import nn\n","from gensim.models import word2vec\n","from sklearn.model_selection import train_test_split\n","\n","# 通過torch.cuda.is_available()的回傳值進行判斷是否有使用GPU的環境，如果有的話device就設為\"cuda\"，沒有的話就設為\"cpu\"\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 處理好各個data的路徑\n","train_with_label = os.path.join(path_prefix, 'training_label.txt')\n","train_no_label = os.path.join(path_prefix, 'training_nolabel.txt')\n","testing_data = os.path.join(path_prefix, 'testing_data.txt')\n","\n","w2v_path = os.path.join(path_prefix, 'w2v_all.model') # 處理word to vec model的路徑\n","\n","# 定義句子長度、要不要固定embedding、batch大小、要訓練幾個epoch、learning rate的值、model的資料夾路徑\n","sen_len = 30\n","fix_embedding = True # fix embedding during training\n","batch_size = 128\n","epoch = 15\n","lr = 0.001\n","# model_dir = os.path.join(path_prefix, 'model/') # model directory for checkpoint model\n","model_dir = path_prefix # model directory for checkpoint model\n","\n","print(\"loading data ...\") # 把'training_label.txt'跟'training_nolabel.txt'讀進來\n","train_x, y = load_training_data(train_with_label)\n","train_x_no_label = load_training_data(train_no_label)\n","test_x = load_testing_data(testing_data)\n","\n","# 對input跟labels做預處理\n","max_len = 1200\n","b = BOW(max_len=max_len)\n","b.bow(train_x, test_x)\n","train_x = b['train']\n","#import pdb\n","#pdb.set_trace()\n","y = [int(label) for label in y]\n","y = torch.LongTensor(y)\n","\n","# 製作一個model的對象\n","model = LSTM_Net(embedding_dim=max_len, num_layers=1)\n","model = model.to(device) # device為\"cuda\"，model使用GPU來訓練(餵進去的inputs也需要是cuda tensor)\n","\n","# 把data分為training data跟validation data(將一部份training data拿去當作validation data)\n","X_train, X_val, y_train, y_val = train_x[:190000], train_x[190000:], y[:190000], y[190000:]\n","\n","# 把data做成dataset供dataloader取用\n","train_dataset = TwitterDataset(X=X_train, y=y_train)\n","val_dataset = TwitterDataset(X=X_val, y=y_val)\n","\n","# 把data 轉成 batch of tensors\n","train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n","                                            batch_size = batch_size,\n","                                            shuffle = True,\n","                                            num_workers = 8)\n","\n","val_loader = torch.utils.data.DataLoader(dataset = val_dataset,\n","                                            batch_size = batch_size,\n","                                            shuffle = False,\n","                                            num_workers = 8)\n","\n","# 開始訓練\n","training(batch_size, epoch, lr, model_dir, train_loader, val_loader, model, device)\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["loading data ...\n","\n","start training, parameter total:680705, trainable:680705\n","\n","\n","Train | Loss:0.51313 Acc: 75.768\n","Valid | Loss:0.50377 Acc: 75.791 \n","saving model with acc 75.791\n","-----------------------------------------------\n","\n","Train | Loss:0.50092 Acc: 76.564\n","Valid | Loss:0.50190 Acc: 75.692 \n","-----------------------------------------------\n","\n","Train | Loss:0.49906 Acc: 76.721\n","Valid | Loss:0.50323 Acc: 75.307 \n","-----------------------------------------------\n","\n","Train | Loss:0.49815 Acc: 76.869\n","Valid | Loss:0.49870 Acc: 76.019 \n","saving model with acc 76.019\n","-----------------------------------------------\n","\n","Train | Loss:0.49717 Acc: 76.883\n","Valid | Loss:0.49921 Acc: 75.712 \n","-----------------------------------------------\n","\n","Train | Loss:0.49681 Acc: 76.931\n","Valid | Loss:0.49880 Acc: 76.177 \n","saving model with acc 76.177\n","-----------------------------------------------\n","\n","Train | Loss:0.49616 Acc: 76.962\n","Valid | Loss:0.49995 Acc: 76.058 \n","-----------------------------------------------\n","\n","Train | Loss:0.49586 Acc: 76.896\n","Valid | Loss:0.49826 Acc: 75.811 \n","-----------------------------------------------\n","\n","Train | Loss:0.49549 Acc: 77.008\n","Valid | Loss:0.49813 Acc: 75.850 \n","-----------------------------------------------\n","\n","Train | Loss:0.49490 Acc: 77.040\n","Valid | Loss:0.49835 Acc: 75.910 \n","-----------------------------------------------\n","\n","Train | Loss:0.49528 Acc: 77.040\n","Valid | Loss:0.49840 Acc: 75.712 \n","-----------------------------------------------\n","\n","Train | Loss:0.49477 Acc: 76.972\n","Valid | Loss:0.49725 Acc: 75.880 \n","-----------------------------------------------\n","\n","Train | Loss:0.49455 Acc: 77.052\n","Valid | Loss:0.49929 Acc: 75.692 \n","-----------------------------------------------\n","\n","Train | Loss:0.49438 Acc: 77.040\n","Valid | Loss:0.49631 Acc: 75.949 \n","-----------------------------------------------\n","\n","Train | Loss:0.49417 Acc: 77.043\n","Valid | Loss:0.49613 Acc: 76.068 \n","-----------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NQNGCB9C6NgG","colab_type":"code","outputId":"03b61e5c-f1dc-47a4-d272-17271f6fcde0","executionInfo":{"status":"ok","timestamp":1586594853426,"user_tz":-480,"elapsed":414676,"user":{"displayName":"KD Lin","photoUrl":"","userId":"07150804307204552996"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["# 開始測試模型並做預測\n","print(\"loading testing data ...\")\n","\n","test_x = b['test']\n","test_dataset = TwitterDataset(X=test_x, y=None)\n","test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n","                                            batch_size = batch_size,\n","                                            shuffle = False,\n","                                            num_workers = 8)\n","print('\\nload model ...')\n","model = torch.load(os.path.join(model_dir, 'ckpt_bow'))\n","outputs = testing(batch_size, test_loader, model, device)\n","\n","# 寫到csv檔案供上傳kaggle\n","tmp = pd.DataFrame({\"id\":[str(i) for i in range(len(test_x))],\"label\":outputs})\n","print(\"save csv ...\")\n","tmp.to_csv(os.path.join(path_prefix, 'predict_bow.csv'), index=False)\n","print(\"Finish Predicting\")\n","\n","# 以下是使用command line上傳到kaggle的方式\n","# 需要先pip install kaggle、Create API Token，詳細請看https://github.com/Kaggle/kaggle-api以及https://www.kaggle.com/code1110/how-to-submit-from-google-colab\n","# kaggle competitions submit [competition-name] -f [csv file path]] -m [message]\n","# ex: kaggle competitions submit ml-2020spring-hw4 -f output/predict.csv -m \"......\""],"execution_count":11,"outputs":[{"output_type":"stream","text":["loading testing data ...\n","\n","load model ...\n","save csv ...\n","Finish Predicting\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fwdrJ00L6QZk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"outputId":"283e67e5-170e-4fc1-d473-3ace1bb5fce5","executionInfo":{"status":"error","timestamp":1586594858320,"user_tz":-480,"elapsed":419567,"user":{"displayName":"KD Lin","photoUrl":"","userId":"07150804307204552996"}}},"source":["#!pwd\n","#!ls\n","\n","from google.colab import files\n","files.download('predict_bow.csv')"],"execution_count":12,"outputs":[{"output_type":"error","ename":"MessageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-0c9ccbe16a8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict_bow.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: TypeError: Failed to fetch"]}]}]}