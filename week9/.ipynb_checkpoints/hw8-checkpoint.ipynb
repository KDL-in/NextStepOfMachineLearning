{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 34770,
     "status": "ok",
     "timestamp": 1589639957061,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "vgtIlUlN4o4g",
    "outputId": "9ef5ac25-b4fc-485c-e229-41d953cabfb6"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive as gdrive\n",
    "gdrive.mount('/content/drive')\n",
    "!pip install pytorch-model-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kLirLyZp58zR"
   },
   "outputs": [],
   "source": [
    "!cp -Rf /content/drive/My\\ Drive/hw8/cmn-eng ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RjCVQLe24iTH"
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "set_seed(9)\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HBsdsJBJ4iTN"
   },
   "source": [
    "# Seq2Seq\n",
    "\n",
    "机器翻译，英文到中文的seq2seq实验。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wbGEsBfg4iTO"
   },
   "source": [
    "# Data Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CEJigvLp4iTP"
   },
   "source": [
    "## Data Structure\n",
    "\n",
    "提供训练集、测试集、验证集，都是一句英文一句英文。其中中文利用jieba进行分词，英文使用subword-nmt将word转化为subword。如\"loved\",\"loving\",\"loves\"这三个单词，其本身的语义都是”爱”的意思。BPE通过训练，能够把上面的3个单词拆分成”lov”,”ed”,”ing”,”es”几部分，这样可以把词的本身的意思和时态分开，有效的减少了词表的数量。词与词之间用空白隔开，中英文之间用tab隔开。\n",
    "\n",
    "````python\n",
    "what were you doing in the at@@ tic ? \t你 在 閣樓 上 做 了 什麼 ？ \n",
    "````\n",
    "\n",
    "字典部分，已经处理好中英的字典，放在json文件中，word2int，int2word都有。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ul2UNwZF4iTQ"
   },
   "source": [
    "## Preprocess - SeqDataset\n",
    "\n",
    "需要做的事主要是：\n",
    "\n",
    "- 特殊字元： < PAD >, < BOS >, < EOS >, < UNK >转化，分别用于填充，标记开始，标记结束，标记未知\n",
    "- 长度规整，输入输出，需要规整到相同长度\n",
    "- word to index，中英文分别处理。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-kP0IaIE4iTQ"
   },
   "outputs": [],
   "source": [
    "class SeqDataset(data.Dataset):\n",
    "    def __init__(self, path, name, sen_len):\n",
    "        self.path = path # data path\n",
    "        self.sen_len = sen_len\n",
    "        self.name = name\n",
    "        # load dict\n",
    "        self.word2idx_cn, self.idx2word_cn = self.load_dict('cn')\n",
    "        self.word2idx_en, self.idx2word_en = self.load_dict('en')\n",
    "        # sentence to idx\n",
    "        self.data, self.labels = self.load_data()\n",
    "        self.cn_vocab_size = len(self.word2idx_cn)\n",
    "        self.en_vocab_size = len(self.word2idx_en)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def load_dict(self, lang):\n",
    "        with open(os.path.join(self.path, f'int2word_{lang}.json'), 'r', encoding='utf-8') as f:\n",
    "            idx2word = json.load(f)\n",
    "        with open(os.path.join(self.path, f'word2int_{lang}.json'), 'r', encoding='utf-8') as f:\n",
    "            word2idx = json.load(f)\n",
    "        return word2idx,idx2word\n",
    "    \n",
    "    def load_data(self):    \n",
    "        # building method\n",
    "        def format_len(temp, sen_len, pad):\n",
    "            if len(temp) > sen_len:\n",
    "                end = temp[-1]\n",
    "                temp = temp[:sen_len]\n",
    "                temp[-1] = end\n",
    "            else:\n",
    "                temp = np.pad(temp, (0, sen_len - len(temp)), constant_values = pad)\n",
    "            return np.array(temp)\n",
    "\n",
    "        def sentence_to_idxs(sens, word2idx, sen_len):\n",
    "            data = []\n",
    "            BOS, EOS, UNK, PAD = word2idx['<BOS>'],word2idx['<EOS>'],word2idx['<UNK>'],word2idx['<PAD>']\n",
    "            for sen in sens:\n",
    "                temp = [BOS]\n",
    "                for word in list(filter(None, sen.split(' '))):\n",
    "                    temp.append(word2idx.get(word, UNK))\n",
    "                temp.append(EOS)\n",
    "                temp  = format_len(temp, sen_len, PAD)\n",
    "                data.append(temp[np.newaxis, :])\n",
    "            data = np.concatenate(data)\n",
    "            return data\n",
    "\n",
    "        # read data\n",
    "        with open(os.path.join(self.path, f'{self.name}.txt'), 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            en,cn = [],[]\n",
    "        lines = list(filter(None, lines))\n",
    "        # split cn en\n",
    "        for line in lines:\n",
    "            temp = re.split('[\\t\\n]', line.strip())\n",
    "            assert len(temp) == 2 and temp[0] is not None and temp[1] is not None\n",
    "            en.append(temp[0])\n",
    "            cn.append(temp[1])\n",
    "        # word to idx\n",
    "        data = sentence_to_idxs(en, self.word2idx_en, self.sen_len)\n",
    "        labels = sentence_to_idxs(cn, self.word2idx_cn, self.sen_len)\n",
    "\n",
    "        return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G9phcPvo4iTU"
   },
   "outputs": [],
   "source": [
    "path = './cmn-eng/'\n",
    "name = 'testing'\n",
    "lang = 'cn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 53449,
     "status": "ok",
     "timestamp": 1589639975813,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "JWVPscHu4iTX",
    "outputId": "04eb9481-c444-4877-c6ac-77a0adaef408"
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "train_set = SeqDataset(path, name, 10)\n",
    "print(train_set.word2idx_cn['快樂'], train_set.idx2word_cn['847'], train_set.word2idx_en['happy'])\n",
    "train_set.labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-yuWxOq_4iTc"
   },
   "source": [
    "# Achitecture \n",
    "\n",
    "模型的主体，包含\n",
    "\n",
    "- Encoder\n",
    "- Decoder\n",
    "- Seq2Seq\n",
    "- Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Im3lmInp4iTc"
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UallM0Vr4iTd"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, en_vocab_size, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(en_vocab_size, emb_dim)\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_):\n",
    "        # input = [batch size, sequence len, vocab size]\n",
    "        embedding = self.embedding(input_)\n",
    "        # embedding = [none, seq_len, emb_dim]\n",
    "        outputs, hidden = self.rnn(self.dropout(embedding))\n",
    "        # outputs = [batch size, sequence len, hid dim * directions]\n",
    "        # hidden =  [num_layers * directions, batch size  , hid dim]\n",
    "        # outputs 是最上層RNN的輸出\n",
    "\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UBkkM09A4iTg"
   },
   "outputs": [],
   "source": [
    "from pytorch_model_summary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 62799,
     "status": "ok",
     "timestamp": 1589639985214,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "lvuUCReG4iTk",
    "outputId": "1b8baa43-9389-4323-e6e3-0c02e33d9bf1"
   },
   "outputs": [],
   "source": [
    "print(summary(Encoder(100,256, 256, 2, 0.5).to(device), torch.zeros((2, 10), dtype = torch.long).to(device), show_hierarchical=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HZLcSbMG4iTp"
   },
   "source": [
    "## Attention\n",
    "\n",
    "Attention的实现，主要是通过decoder当前时间步的信息 => seq len个权重。具体的实现方法有很多。我看了一些资料，小结一下。\n",
    "\n",
    "Attenion输入，\n",
    "\n",
    "- encoder_outputs = [none, seq_len, hidden_dim], 注意hidden_dim和encoder中GRU的方向有关，可能得x2\n",
    "- hidden = [num_layers <* num_directions>, batch, hidden_dim] 当前时间步的hidden output，默认情况下，decoder中GRU为单向, 如果使用encoder_hidden做decoder第一个时间步的输入，那么需要把双向的结果接起来，最后维度x2\n",
    "- input = [batch, 1]，输入，因为decoder是单步执行，所以只传一个时间步上的值，经过embedding会变成[batch, 1, emb_dim]\n",
    "\n",
    "notes：attention求法\n",
    "\n",
    "- $\\boldsymbol{h}_{t}^{\\top} \\boldsymbol{W} \\overline{\\boldsymbol{h}}_{s} \\quad$ [Luong's multiplicative style]， 其中h分别为encoder_outputs和hidden\n",
    "- $\\boldsymbol{v}_{a}^{\\top} \\tanh \\left(\\boldsymbol{W}_{1} \\boldsymbol{h}_{t}+\\boldsymbol{W}_{2} \\overline{\\boldsymbol{h}}_{s}\\right)$，其中v，w都为参数矩阵，也就是linear\n",
    "- 只使用input和hidden进行concatenate，然后利用linear转为seq len个单元\n",
    "\n",
    "最后使用softmax求除权重。\n",
    "\n",
    "注意上述过程中，会出现维度不匹配问题，多半是层次数引起的，其实在该维度上，上述方法都可以直接广播复制，只关注最后的维度即可。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y8k0FClR4iTp"
   },
   "source": [
    "notes：\n",
    "\n",
    "无需担心3d矩阵乘法问题，实际上以下代码只关注dim 2的值，对这个dim上的值做线性变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 62781,
     "status": "ok",
     "timestamp": 1589639985216,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "_454jXZt4iTq",
    "outputId": "807ea956-bbb9-4f85-9365-c394613656ef"
   },
   "outputs": [],
   "source": [
    "a = torch.zeros(128, 10, 256)\n",
    "linear = nn.Linear(256,10)\n",
    "b = linear(a)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lEBUQDBk4iTt"
   },
   "outputs": [],
   "source": [
    "# [2, 10, 512], [4, 2, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ToA_I9vM4iTw"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_layer, hidden_dim):\n",
    "        # 这里的hidden_dim 为decoder的，是encoder的两倍\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.W1 = nn.Linear(num_layer * hidden_dim, hidden_dim)\n",
    "        self.W2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.V = nn.Linear(hidden_dim, 1)\n",
    "    \n",
    "    def forward(self, input_, hidden, encoder_outputs):\n",
    "        '''\n",
    "        input_:  decoder的输入，经过embedding [batch, 1, emb_dim]\n",
    "        hidden: decoder的隐藏层，[num_layers x 1 , batch, hidden_dim], 其中的参数为decoder中的参数\n",
    "        encoder_outputs: encoder输出，[batch, seq_len, hidden_dim]\n",
    "        '''\n",
    "        hidden = torch.cat([hidden[i, :, :] for i in range(hidden.size(0))], dim = 1).unsqueeze(1)\n",
    "        # [batch, 1, total dim], 拼接所有层的最后一个dim\n",
    "        score = torch.tanh(self.W1(hidden) + self.W2(encoder_outputs))\n",
    "        # [batch, seq_len, hidden_dim], 两者通过linear转化最后一个维度，最后相加（中间维度广播道seq len）\n",
    "        score = self.V(score)\n",
    "        # [batch, seq_len,1]\n",
    "        ahlpas = torch.softmax(score, dim = 1)\n",
    "        # [batch, seq_len,1]\n",
    "        context = torch.sum(encoder_outputs * ahlpas, dim = 1)\n",
    "        # [batch, hidden_dim]\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 62715,
     "status": "ok",
     "timestamp": 1589639985219,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "YV6QfaX74iT0",
    "outputId": "60f71f73-52cf-4502-eaea-df6a8a145dea"
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "num_layer = 2\n",
    "hidden_dim = 256 * num_layer\n",
    "input_ = torch.zeros((128, 1), dtype = torch.int64)\n",
    "hidden = torch.zeros((num_layer, 128, hidden_dim))\n",
    "encoder_outputs = torch.zeros((128, 10, hidden_dim))\n",
    "att = Attention(num_layer, hidden_dim)\n",
    "print(att(input_, hidden, encoder_outputs).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gxPu7Da04iT3"
   },
   "source": [
    "## Decoder\n",
    "\n",
    "Decoder任务比较简单，就是跑数据，不用管teacher force以及beam search，需要注意的是，decoder的输入是当个time step上的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mMkOL3yz4iT4"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, cn_vocab_size,  emb_dim,  hidden_dim, num_layer,dropout, isatt):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(cn_vocab_size, emb_dim)\n",
    "        t_dim =  emb_dim\n",
    "        self.isatt = False\n",
    "        if isatt == True:\n",
    "            self.isatt = isatt\n",
    "            self.att = Attention(num_layer, hidden_dim)\n",
    "            t_dim += hidden_dim\n",
    "        \n",
    "        self.rnn = nn.GRU(t_dim, hidden_dim, num_layer, dropout = dropout, batch_first = True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim * 4),\n",
    "            nn.Linear(hidden_dim * 4, cn_vocab_size)\n",
    "        )\n",
    "        self.cn_vocab_size = cn_vocab_size\n",
    "    def forward(self, input_, hidden, encoder_outputs):\n",
    "        '''\n",
    "        input_ = [batch, 1]\n",
    "        hidden = [num_layer, batch, hidden_dim], 其中hidden dim受GRU层数的影响，方向定为单向\n",
    "        encoder_outputs = [batch, seq_len, hidden_dim]\n",
    "        '''\n",
    "        emb = self.emb(input_)\n",
    "        emb = self.dropout(emb)\n",
    "        in_cat = emb\n",
    "        # [batch, 1, emb_dim]\n",
    "        # attention\n",
    "        if self.isatt == True:\n",
    "            context = self.att(input_, hidden, encoder_outputs)\n",
    "            # context = [batch, hidden_dim]\n",
    "            context = context.unsqueeze(1)\n",
    "            # [batch, 1, hidden_dim]\n",
    "            in_cat = torch.cat([emb, context], dim = 2)\n",
    "        # [batch, i, hidden_dim + emb_dim]\n",
    "        out, hidden = self.rnn(in_cat)\n",
    "\n",
    "        # out = [batch, 1, hidden_dim]\n",
    "        out = out.squeeze(1)\n",
    "        #[batch, hidden_dim]\n",
    "        out = self.fc(out)\n",
    "        # [batch, cn_vocab_size]\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ewj6Tc94iT7"
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "cn_vocab_size, en_vocab_size = 3000, 2500\n",
    "emb_dim, num_layer =  128, 3\n",
    "hidden_dim, dropout = 256, 0.5\n",
    "decoder = Decoder(cn_vocab_size, emb_dim, hidden_dim, num_layer, dropout, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 701
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 62681,
     "status": "ok",
     "timestamp": 1589639985221,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "iN3TLenA4iT-",
    "outputId": "ec29a44a-8e48-4dbe-aa86-157af81d37b6"
   },
   "outputs": [],
   "source": [
    "print(summary(decoder, torch.zeros((2, 1), dtype = torch.long), torch.zeros(3, 2, 256), torch.zeros(2, 10, 256), show_hierarchical=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 62665,
     "status": "ok",
     "timestamp": 1589639985222,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "rc49zRRY4iUB",
    "outputId": "f6e75347-f02b-4359-d7c4-a848a5f477b9"
   },
   "outputs": [],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kM-Dwpyn4iUE"
   },
   "source": [
    "## Seq2Seq\n",
    "\n",
    "这个负责构建整个模型架构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hhgmYiSd4iUF"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, input_, target, teacher_force_rate):\n",
    "        '''\n",
    "        input_ = [batch, seq_len], 输入句子样本, en\n",
    "        target = [batch, seq_len], 输出翻译样本，cn\n",
    "        '''\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_)\n",
    "        # encoder_outputs = [batch size, sequence len, hid dim * directions]\n",
    "        # encoder_hidden =  [num_layers * directions, batch size  , hid dim]\n",
    "        shape = encoder_hidden.size()\n",
    "        hidden = encoder_hidden.view(int(shape[0]/2), 2,  shape[1], shape[2])\n",
    "        hidden = torch.cat([hidden[:, i, :, :] for i in range(2)], dim = 2)\n",
    "        # [num_layter, batch_size, hid_dim_dec]\n",
    "        x_dec = target[:, 0:1]\n",
    "        # 预测概率和标签\n",
    "        outputs = torch.zeros(input_.shape[0], input_.shape[1], self.decoder.cn_vocab_size).to(device)\n",
    "        preds = []\n",
    "        for step in range(1, target.size(1)):\n",
    "            # [batch, 1]\n",
    "            out, hidden = self.decoder(x_dec, hidden, encoder_outputs)\n",
    "            # out = [batch, cn_vocab_size]\n",
    "            # hidden = [num_layter, batch_size, hid_dim_dec]\n",
    "            pred = out.argmax(1, keepdim = True)\n",
    "            outputs[:,step, :] = out\n",
    "            teacher_force = random.random() <= teacher_force_rate\n",
    "            x_dec = target[:, step:step+1] if teacher_force else pred\n",
    "            preds.append(pred)\n",
    "        preds = torch.cat(preds, dim = 1).to(device)\n",
    "        # preds = [batch,]\n",
    "        # outputs = [batch, seq_len, cn_vocab_size]\n",
    "        return outputs, preds\n",
    "\n",
    "    def inference(self, input_, target):\n",
    "        '''\n",
    "        input_ = [batch, seq_len], 输入句子样本, en\n",
    "        target = [batch, seq_len], 输出翻译样本，cn\n",
    "        '''\n",
    "        teacher_force_rate = 1\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_)\n",
    "        # encoder_outputs = [batch size, sequence len, hid dim * directions]\n",
    "        # encoder_hidden =  [num_layers * directions, batch size  , hid dim]\n",
    "        shape = encoder_hidden.size()\n",
    "        hidden = encoder_hidden.view(int(shape[0]/2), 2,  shape[1], shape[2])\n",
    "        hidden = torch.cat([hidden[:, i, :, :] for i in range(2)], dim = 2)\n",
    "        # [num_layter, batch_size, hid_dim_dec]\n",
    "        x_dec = target[:, 0]\n",
    "        # 预测概率和标签\n",
    "        outputs = torch.zeros(input_.shape[0], input_.shape[1], self.decoder.cn_vocab_size).to(device)\n",
    "        preds = []\n",
    "        for step in range(1, target.size(1)):\n",
    "            x_dec = x_dec.unsqueeze(1)\n",
    "            # [batch, 1]\n",
    "            out, hidden = self.decoder(x_dec, hidden, encoder_outputs)\n",
    "            # out = [batch, cn_vocab_size]\n",
    "            # hidden = [num_layter, batch_size, hid_dim_dec]\n",
    "            pred = out.argmax(1, keepdim = True)\n",
    "            outputs[:,step, :] = out\n",
    "            teacher_force = random.random() <= teacher_force_rate\n",
    "            x_dec = target[:, step] if teacher_force else pred\n",
    "            preds.append(pred)\n",
    "        preds = torch.cat(preds, dim = 1).to(device)\n",
    "        # preds = [batch,]\n",
    "        # outputs = [batch, seq_len, cn_vocab_size]\n",
    "        return outputs, preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 63163,
     "status": "ok",
     "timestamp": 1589639985737,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "WiIdFIrm4iUI",
    "outputId": "7a91f5f6-9b28-4c83-905b-f48ec5456e68"
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "cn_vocab_size, en_vocab_size = train_set.cn_vocab_size,train_set.en_vocab_size\n",
    "emb_dim, num_layer =  128, 3\n",
    "hidden_dim, dropout = 256, 0.5\n",
    "batch_size = 64\n",
    "decoder = Decoder(cn_vocab_size, emb_dim, hidden_dim, num_layer, dropout, True)\n",
    "encoder = Encoder(en_vocab_size, emb_dim, int(hidden_dim/2), num_layer, dropout)\n",
    "seq2seq = Seq2Seq(encoder, decoder)\n",
    "dataloader = data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "for input_, target in dataloader:\n",
    "    break\n",
    "input_ = torch.tensor(input_, dtype = torch.long)\n",
    "target = torch.tensor(target, dtype = torch.long)\n",
    "pred_probs,pred_labels =seq2seq(input_, target,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BvKStK_u4iUL"
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MyMW8oHV4iUM"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_8U7rL8n4iUM"
   },
   "outputs": [],
   "source": [
    "def save_model(model, store_model_path, step):\n",
    "    torch.save(model.state_dict(), f'{store_model_path}/model_{step}.ckpt')\n",
    "    return\n",
    "\n",
    "def load_model(model, load_model_path):\n",
    "    print(f'Load model from {load_model_path}')\n",
    "    model.load_state_dict(torch.load(f'{load_model_path}.ckpt'))\n",
    "    return model\n",
    "\n",
    "def build_model(config, en_vocab_size, cn_vocab_size):\n",
    "    # 建構模型\n",
    "    encoder = Encoder(en_vocab_size, config.emb_dim, config.hid_dim, config.n_layers, config.dropout).to(device)\n",
    "    decoder = Decoder(cn_vocab_size, config.emb_dim, config.hid_dim * 2, config.n_layers, config.dropout, config.attention).to(device)\n",
    "    model = Seq2Seq(encoder, decoder)\n",
    "    print(model)\n",
    "    # 建構 optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    print(optimizer)\n",
    "    if config.load_model:\n",
    "        model = load_model(model, config.load_model_path)\n",
    "    model = model.to(device)\n",
    "\n",
    "    return model, optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SbqE2AHP4iUP"
   },
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9QkrHlU04iUP"
   },
   "outputs": [],
   "source": [
    "def tokens2sentence(outputs, int2word):\n",
    "    sentences = []\n",
    "    for tokens in outputs:\n",
    "        sentence = []\n",
    "        for token in tokens:\n",
    "            word = int2word[str(int(token))]\n",
    "            if word == '<EOS>':\n",
    "                break\n",
    "            sentence.append(word)\n",
    "        sentences.append(sentence)\n",
    "  \n",
    "    return sentences\n",
    "\n",
    "def infinite_iter(data_loader):\n",
    "    it = iter(data_loader)\n",
    "    while True:\n",
    "        try:\n",
    "            ret = next(it)\n",
    "            yield ret\n",
    "        except StopIteration:\n",
    "            it = iter(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "72LjLlol4iUS"
   },
   "source": [
    "## BLEU score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a7VIDiT34iUS"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "def computebleu(sentences, targets):\n",
    "    score = 0 \n",
    "    assert (len(sentences) == len(targets))\n",
    "    #  cut_token 将中文分词切分成字\n",
    "    def cut_token(sentence):\n",
    "        tmp = []\n",
    "        for token in sentence:\n",
    "            if token == '<UNK>' or token.isdigit() or len(bytes(token[0], encoding='utf-8')) == 1:\n",
    "                tmp.append(token)\n",
    "            else:\n",
    "                tmp += [word for word in token]\n",
    "        return tmp \n",
    "\n",
    "    for sentence, target in zip(sentences, targets):\n",
    "        sentence = cut_token(sentence)\n",
    "        target = cut_token(target)\n",
    "        # notes: bleus score，其中weight指定的是n-grams的权重，reference需要是一个列表，我还不知道为什么\n",
    "        score += sentence_bleu([target], sentence, weights=(1, 0, 0, 0))                                                                                          \n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nutyedui4iUV"
   },
   "source": [
    "## PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7YXW9e3W4iUV"
   },
   "outputs": [],
   "source": [
    "def plot(train_losses, val_losses, bleu_scores):\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses)\n",
    "    plt.xlabel('次數')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('train loss')\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    plt.plot(val_losses)\n",
    "    plt.xlabel('次數')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('validation loss')\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    plt.plot(bleu_scores)\n",
    "    plt.xlabel('次數')\n",
    "    plt.ylabel('BLEU score')\n",
    "    plt.title('BLEU score')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LWTZ8q3W4iUY"
   },
   "source": [
    "## Schedule Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9BU9fb54iUY"
   },
   "outputs": [],
   "source": [
    "def schedule_sampling():\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cgqEpmJD4iUc"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "STQeSxWU4iUd"
   },
   "source": [
    "## train epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "apgGaoqr4iUd"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_iter, loss_function, total_steps, summary_steps, train_dataset):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    losses = []\n",
    "    loss_sum = 0.0\n",
    "    for step in range(summary_steps):\n",
    "        sources, targets = next(train_iter)\n",
    "        sources, targets = sources.to(device, torch.long), targets.to(device, torch.long)\n",
    "        outputs, preds = model(sources, targets, schedule_sampling())\n",
    "        # notes: seq2seq loss计算，问题一，忽略<BOS>\n",
    "        # notes: seq2seq loss计算，问题二，由于cross_entropy直接收二维数据，这里直接reshape到二维\\\n",
    "        outputs = outputs[:, 1:].reshape(-1, outputs.size(2))\n",
    "        targets = targets[:, 1:].reshape(-1)\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # notes: seq2seq 梯度限制，nlp lstm会遇到的问题之一，函数部分区域非常陡峭，梯度会突然很大，导致无法训练\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        # notes: loss技巧，下面使用了exp(loss)，方便观察变化\n",
    "        # 每五次step打印一次，打印loss平均值，不再以\"epoch\"为单位\n",
    "        loss_sum += loss.item()\n",
    "        if (step + 1) % 5 == 0:\n",
    "            loss_sum = loss_sum / 5\n",
    "            print (\"\\r\", \"train [{}] loss: {:.3f}, Perplexity: {:.3f}      \".format(total_steps + step + 1, loss_sum, np.exp(loss_sum)), end=\" \")\n",
    "            losses.append(loss_sum)\n",
    "            loss_sum = 0.0\n",
    "\n",
    "    return model, optimizer, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UyMcjkR64iUg"
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eRgfhsuH4iUh"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RD2qBcFB4iUj"
   },
   "outputs": [],
   "source": [
    "def test(model, dataloader, loss_function):\n",
    "    model.eval()\n",
    "    loss_sum, bleu_score= 0.0, 0.0\n",
    "    n = 0\n",
    "    result = []\n",
    "    time_start = time.time()\n",
    "    for sources, targets in dataloader:\n",
    "        sources, targets = sources.to(device, torch.long), targets.to(device, torch.long)\n",
    "        batch_size = sources.size(0)\n",
    "        outputs, preds = model.inference(sources, targets)\n",
    "        \n",
    "        outputs = outputs[:, 1:].reshape(-1, outputs.size(2))\n",
    "        targets = targets[:, 1:].reshape(-1)\n",
    "\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "        # 將預測結果轉為文字\n",
    "        targets = targets.view(sources.size(0), -1) # 维度恢复\n",
    "        preds = tokens2sentence(preds, dataloader.dataset.idx2word_cn)\n",
    "        sources = tokens2sentence(sources, dataloader.dataset.idx2word_en)\n",
    "        targets = tokens2sentence(targets, dataloader.dataset.idx2word_cn)\n",
    "        for source, pred, target in zip(sources, preds, targets):\n",
    "            result.append((source, pred, target))\n",
    "        # 計算 Bleu Score\n",
    "        bleu_score += computebleu(preds, targets)\n",
    "        n += batch_size\n",
    "    time_end = time.time()\n",
    "    # print(time_end - time_start)\n",
    "    return loss_sum / len(dataloader), bleu_score / n, result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 49344,
     "status": "ok",
     "timestamp": 1589640067819,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "5VUfIfrF4iUm",
    "outputId": "09cb0d7b-fe6c-403c-fe8c-b190f494f3f6"
   },
   "outputs": [],
   "source": [
    "# train_dataset = SeqDataset(config.data_path, 'training', config.max_output_len)\n",
    "# model, optimizer = build_model(config, train_dataset.en_vocab_size, train_dataset.cn_vocab_size)\n",
    "# loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "# val_dataset = SeqDataset(config.data_path, 'validation', config.max_output_len)\n",
    "# val_loader = data.DataLoader(val_dataset, batch_size=1)\n",
    "# test(model, val_loader, loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iCMAS-Vr4iUs"
   },
   "source": [
    "## Train Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A3GgCyBt4iUt"
   },
   "outputs": [],
   "source": [
    "# notes: 大量参数的参数技巧，简化api，config存放可变参数，尽量不用全局变量，但config不接触底层\n",
    "def train_process(config):\n",
    "    # 準備訓練資料\n",
    "    train_dataset = SeqDataset(config.data_path, 'training', config.max_output_len)\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "    train_iter = infinite_iter(train_loader)\n",
    "    # 準備檢驗資料\n",
    "    # valid过程无法批量操作\n",
    "    val_dataset = SeqDataset(config.data_path, 'validation', config.max_output_len)\n",
    "    val_loader = data.DataLoader(val_dataset, batch_size=1)\n",
    "    # 建構模型\n",
    "    model, optimizer = build_model(config, train_dataset.en_vocab_size, train_dataset.cn_vocab_size)\n",
    "    loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "    train_losses, val_losses, bleu_scores = [], [], []\n",
    "    total_steps = 0\n",
    "    # notes：训练的另一种写法，无epoch如何控制训练过程\n",
    "    while (total_steps < config.num_steps):\n",
    "        # 訓練模型\n",
    "        model, optimizer, loss = train(model, optimizer, train_iter, loss_function, total_steps, config.summary_steps, train_dataset)\n",
    "        train_losses += loss\n",
    "        # 檢驗模型\n",
    "    \n",
    "        val_loss, bleu_score, result = test(model, val_loader, loss_function)\n",
    "        val_losses.append(val_loss)\n",
    "        bleu_scores.append(bleu_score)\n",
    "        \n",
    "        total_steps += config.summary_steps\n",
    "        print (\"\\r\", \"val [{}] loss: {:.3f}, Perplexity: {:.3f}, blue score: {:.3f}       \".format(total_steps, val_loss, np.exp(val_loss), bleu_score))\n",
    "\n",
    "        # 儲存模型和結果\n",
    "        # notes：机器翻译任务early stop，因为bleus不像acc，它不是精准的指标，所以此处每隔一定的step保存一次模型，靠人为选择出合适的模型\n",
    "        if total_steps % config.store_steps == 0 or total_steps >= config.num_steps:\n",
    "            save_model(model, config.store_model_path, total_steps)\n",
    "            with open(f'{config.store_model_path}/output_{total_steps}.txt', 'w') as f:\n",
    "                for line in result:\n",
    "                    print (line, file=f)\n",
    "    \n",
    "    return train_losses, val_losses, bleu_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-dXgNFW4iUx"
   },
   "outputs": [],
   "source": [
    "# #     train_dataset = SeqDataset(config.data_path, 'training', config.max_output_len)\n",
    "#     train_loader = data.DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "#     train_iter = infinite_iter(train_loader)\n",
    "#     # 準備檢驗資料\n",
    "#     # valid过程无法批量操作\n",
    "#     val_dataset = SeqDataset(config.data_path, 'validation', config.max_output_len)\n",
    "#     val_loader = data.DataLoader(val_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xths_ZJl4iU5"
   },
   "source": [
    "## Test Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W9coOvV74iU5"
   },
   "outputs": [],
   "source": [
    "def test_process(config):\n",
    "    # 準備測試資料\n",
    "    test_dataset = SeqDataset(config.data_path, 'testing', config.max_output_len)\n",
    "    # 无法批量操作，所以只能当个执行，效率也很慢就是\n",
    "    test_loader = data.DataLoader(test_dataset, batch_size=1)\n",
    "    # 建構模型\n",
    "    model, optimizer = build_model(config, test_dataset.en_vocab_size, test_dataset.cn_vocab_size)\n",
    "    print (\"Finish build model\")\n",
    "    loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "    model.eval()\n",
    "    # 測試模型\n",
    "    test_loss, bleu_score, result = test(model, test_loader, loss_function)\n",
    "    # 儲存結果\n",
    "    with open(f'./test_output.txt', 'w') as f:\n",
    "        for line in result:\n",
    "            print (line, file=f)\n",
    "\n",
    "    return test_loss, bleu_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8QSzhlZA4iU8"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "khIG9DZM4iU8"
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8E0w4ymx4iU9"
   },
   "outputs": [],
   "source": [
    "class configurations(object):\n",
    "    def __init__(self):\n",
    "        self.batch_size = 60\n",
    "        self.emb_dim = 128\n",
    "        self.hid_dim = 128\n",
    "        self.n_layers = 3\n",
    "        self.dropout = 0.5\n",
    "        self.learning_rate = 0.00005\n",
    "        self.max_output_len = 50              # 最後輸出句子的最大長度\n",
    "        self.num_steps = 3000                # 總訓練次數\n",
    "        self.store_steps = 100                # 訓練多少次後須儲存模型\n",
    "        self.summary_steps = 100              # 訓練多少次後須檢驗是否有overfitting\n",
    "        self.load_model = False               # 是否需載入模型\n",
    "        self.load_model_path = None           # 載入模型的位置 e.g. \"./ckpt/model_{step}\" \n",
    "        self.attention = True                # 是否使用 Attention Mechanism\n",
    "        self.base_path = './'\n",
    "        self.store_model_path = os.path.join(self.base_path, 'ckpt')     # 儲存模型的位置\n",
    "        self.data_path =  os.path.join(self.base_path, 'cmn-eng')         # 資料存放的位置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "drlcWL0g4iU_"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1398,
     "status": "ok",
     "timestamp": 1589640070766,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "Zv-b5_eZ4iVA",
    "outputId": "a543d46a-bb35-4383-d538-d83e7ee69bb3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    config = configurations()\n",
    "    print ('config:\\n', vars(config))\n",
    "    set_seed(9)\n",
    "    # train_losses, val_dataset_losses, bleu_scores = train_process(config)\n",
    "    # plot(train_lossesn, val_dataset_losses, bleu_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3481,
     "status": "ok",
     "timestamp": 1589640072865,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "V0h_11x74iVC",
    "outputId": "7736ae62-6e44-4faf-d5d4-176c0926c10f"
   },
   "outputs": [],
   "source": [
    "# # summary\n",
    "# train_dataset = SeqDataset(config.data_path, 'training', config.max_output_len)\n",
    "# train_loader = data.DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "# train_iter = infinite_iter(train_loader)\n",
    "# # 準備檢驗資料\n",
    "# # valid过程无法批量操作\n",
    "# val_dataset = SeqDataset(config.data_path, 'validation', config.max_output_len)\n",
    "# val_loader = data.DataLoader(val_dataset, batch_size=1)\n",
    "# # 建構模型\n",
    "# model, optimizer = build_model(config, train_dataset.en_vocab_size, train_dataset.cn_vocab_size)\n",
    "# input_,target = next(train_iter)\n",
    "# print(summary(model, input_.to(device, torch.long), target.to(device, torch.long), 1,show_hierarchical=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9PleF88z4iVF"
   },
   "source": [
    "# 实验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3NCdRbl44iVG"
   },
   "source": [
    "## 无Teacher Force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "colab_type": "code",
    "id": "k6OdrBor4iVG",
    "outputId": "6a8ac5e7-d734-4876-b24f-ebef4771e41a"
   },
   "outputs": [],
   "source": [
    "class configurations(object):\n",
    "    def __init__(self):\n",
    "        self.batch_size = 60\n",
    "        self.emb_dim = 256\n",
    "        self.hid_dim = 512\n",
    "        self.n_layers = 3\n",
    "        self.dropout = 0.5\n",
    "        self.learning_rate = 0.00005\n",
    "        self.max_output_len = 50              # 最後輸出句子的最大長度\n",
    "        self.num_steps = 12000                # 總訓練次數\n",
    "        self.store_steps = 300                # 訓練多少次後須儲存模型\n",
    "        self.summary_steps = 300              # 訓練多少次後須檢驗是否有overfitting\n",
    "        self.load_model = False               # 是否需載入模型\n",
    "        self.load_model_path = None           # 載入模型的位置 e.g. \"./ckpt/model_{step}\" \n",
    "        self.attention = False                # 是否使用 Attention Mechanism\n",
    "        self.base_path = './drive/My Drive/hw8'\n",
    "        self.store_model_path = os.path.join(self.base_path, 'ckpt')     # 儲存模型的位置\n",
    "        self.data_path =  os.path.join(self.base_path, 'cmn-eng')         # 資料存放的位置\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    config = configurations()\n",
    "    print ('config:\\n', vars(config))\n",
    "    set_seed(9)\n",
    "    train_losses, val_dataset_losses, bleu_scores = train_process(config)\n",
    "    plot(train_lossesn, val_dataset_losses, bleu_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6FaanqIx-0-h"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "hw8.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "551.2px",
    "left": "672px",
    "top": "66.8px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
