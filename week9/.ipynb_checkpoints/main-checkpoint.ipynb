{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq\n",
    "\n",
    "机器翻译，英文到中文的seq2seq实验。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Structure\n",
    "\n",
    "提供训练集、测试集、验证集，都是一句英文一句英文。其中中文利用jieba进行分词，英文使用subword-nmt将word转化为subword。如\"loved\",\"loving\",\"loves\"这三个单词，其本身的语义都是”爱”的意思。BPE通过训练，能够把上面的3个单词拆分成”lov”,”ed”,”ing”,”es”几部分，这样可以把词的本身的意思和时态分开，有效的减少了词表的数量。词与词之间用空白隔开，中英文之间用tab隔开。\n",
    "\n",
    "````python\n",
    "what were you doing in the at@@ tic ? \t你 在 閣樓 上 做 了 什麼 ？ \n",
    "````\n",
    "\n",
    "字典部分，已经处理好中英的字典，放在json文件中，word2int，int2word都有。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess - SeqDataset\n",
    "\n",
    "需要做的事主要是：\n",
    "\n",
    "- 特殊字元： < PAD >, < BOS >, < EOS >, < UNK >转化，分别用于填充，标记开始，标记结束，标记未知\n",
    "- 长度规整，输入输出，需要规整到相同长度\n",
    "- word to index，中英文分别处理。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataset(data.Dataset):\n",
    "    def __init__(self, path, name, sen_len = 10):\n",
    "        self.path = path # data path\n",
    "        self.sen_len = sen_len\n",
    "        # load dict\n",
    "        self.word2idx_cn, self.idx2word_cn = self.load_dict('cn')\n",
    "        self.word2idx_en, self.idx2word_en = self.load_dict('en')\n",
    "        # sentence to idx\n",
    "        self.data, self.labels = self.load_data()\n",
    "        self.cn_vocab_size = len(self.word2idx_cn)\n",
    "        self.en_vocab_size = len(self.word2idx_en)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def load_dict(self, lang):\n",
    "        with open(os.path.join(self.path, f'int2word_{lang}.json'), 'r', encoding='utf-8') as f:\n",
    "            idx2word = json.load(f)\n",
    "        with open(os.path.join(self.path, f'word2int_{lang}.json'), 'r', encoding='utf-8') as f:\n",
    "            word2idx = json.load(f)\n",
    "        return word2idx,idx2word\n",
    "    \n",
    "    def load_data(self):    \n",
    "        # building method\n",
    "        def format_len(temp, sen_len, pad):\n",
    "            if len(temp) > sen_len:\n",
    "                end = temp[-1]\n",
    "                temp = temp[:sen_len]\n",
    "                temp[-1] = end\n",
    "            else:\n",
    "                temp = np.pad(temp, (0, sen_len - len(temp)), constant_values = pad)\n",
    "            return np.array(temp)\n",
    "\n",
    "        def sentence_to_idxs(sens, word2idx, sen_len):\n",
    "            data = []\n",
    "            BOS, EOS, UNK, PAD = word2idx['<BOS>'],word2idx['<EOS>'],word2idx['<UNK>'],word2idx['<PAD>']\n",
    "            for sen in sens:\n",
    "                temp = [BOS]\n",
    "                for word in list(filter(None, sen.split(' '))):\n",
    "                    temp.append(word2idx.get(word, UNK))\n",
    "                temp.append(EOS)\n",
    "                temp  = format_len(temp, sen_len, PAD)\n",
    "                data.append(temp[np.newaxis, :])\n",
    "            data = np.concatenate(data)\n",
    "            return data\n",
    "\n",
    "        # read data\n",
    "        with open(os.path.join(self.path, f'{name}.txt'), 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            en,cn = [],[]\n",
    "        lines = list(filter(None, lines))\n",
    "        # split cn en\n",
    "        for line in lines:\n",
    "            temp = re.split('[\\t\\n]', line.strip())\n",
    "            assert len(temp) == 2 and temp[0] is not None and temp[1] is not None\n",
    "            en.append(temp[0])\n",
    "            cn.append(temp[1])\n",
    "        # word to idx\n",
    "        data = sentence_to_idxs(cn, self.word2idx_cn, self.sen_len)\n",
    "        labels = sentence_to_idxs(en, self.word2idx_en, self.sen_len)\n",
    "\n",
    "        return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './cmn-eng/'\n",
    "name = 'testing'\n",
    "lang = 'cn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847 快樂 219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2636, 10)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "train_set = SeqDataset(path, name, sen_len=10)\n",
    "print(train_set.word2idx_cn['快樂'], train_set.idx2word_cn['847'], train_set.word2idx_en['happy'])\n",
    "train_set.labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Achitecture \n",
    "\n",
    "模型的主体，包含\n",
    "\n",
    "- Encoder\n",
    "- Decoder\n",
    "- Seq2Seq\n",
    "- Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, en_vocab_size, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(en_vocab_size, emb_dim)\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input = [batch size, sequence len, vocab size]\n",
    "        embedding = self.embedding(input)\n",
    "        # embedding = [none, seq_len, emb_dim]\n",
    "        outputs, hidden = self.rnn(self.dropout(embedding))\n",
    "        # outputs = [batch size, sequence len, hid dim * directions]\n",
    "        # hidden =  [num_layers * directions, batch size  , hid dim]\n",
    "        # outputs 是最上層RNN的輸出\n",
    "\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_model_summary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "      Layer (type)                  Output Shape         Param #     Tr. Param #\n",
      "=================================================================================\n",
      "       Embedding-1                  [2, 10, 256]          25,600          25,600\n",
      "         Dropout-2                  [2, 10, 256]               0               0\n",
      "             GRU-3     [2, 10, 512], [4, 2, 256]       1,972,224       1,972,224\n",
      "=================================================================================\n",
      "Total params: 1,997,824\n",
      "Trainable params: 1,997,824\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "========================================== Hierarchical Summary ==========================================\n",
      "\n",
      "Encoder(\n",
      "  (embedding): Embedding(100, 256), 25,600 params\n",
      "  (rnn): GRU(256, 256, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True), 1,972,224 params\n",
      "  (dropout): Dropout(p=0.5, inplace=False), 0 params\n",
      "), 1,997,824 params\n",
      "\n",
      "\n",
      "==========================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(summary(Encoder(100,256, 256, 2, 0.5), torch.zeros((2, 10), dtype = torch.long), show_hierarchical=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention\n",
    "\n",
    "Attention的实现，主要是通过decoder当前时间步的信息 => seq len个权重。具体的实现方法有很多。我看了一些资料，小结一下。\n",
    "\n",
    "Attenion输入，\n",
    "\n",
    "- encoder_outputs = [none, seq_len, hidden_dim], 注意hidden_dim和encoder中GRU的方向有关，可能得x2\n",
    "- hidden = [num_layers <* num_directions>, batch, hidden_dim] 当前时间步的hidden output，默认情况下，decoder中GRU为单向, 如果使用encoder_hidden做decoder第一个时间步的输入，那么需要把双向的结果接起来，最后维度x2\n",
    "- input = [batch, 1]，输入，因为decoder是单步执行，所以只传一个时间步上的值，经过embedding会变成[batch, 1, emb_dim]\n",
    "\n",
    "notes：attention求法\n",
    "\n",
    "- $\\boldsymbol{h}_{t}^{\\top} \\boldsymbol{W} \\overline{\\boldsymbol{h}}_{s} \\quad$ [Luong's multiplicative style]， 其中h分别为encoder_outputs和hidden\n",
    "- $\\boldsymbol{v}_{a}^{\\top} \\tanh \\left(\\boldsymbol{W}_{1} \\boldsymbol{h}_{t}+\\boldsymbol{W}_{2} \\overline{\\boldsymbol{h}}_{s}\\right)$，其中v，w都为参数矩阵，也就是linear\n",
    "- 只使用input和hidden进行concatenate，然后利用linear转为seq len个单元\n",
    "\n",
    "最后使用softmax求除权重。\n",
    "\n",
    "注意上述过程中，会出现维度不匹配问题，多半是层次数引起的，其实在该维度上，上述方法都可以直接广播复制，只关注最后的维度即可。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notes：\n",
    "\n",
    "无需担心3d矩阵乘法问题，实际上以下代码只关注dim 2的值，对这个dim上的值做线性变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(128, 10, 256)\n",
    "linear = nn.Linear(256,10)\n",
    "b = linear(a)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2, 10, 512], [4, 2, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_layer, hidden_dim):\n",
    "        # 这里的hidden_dim 为decoder的，是encoder的两倍\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.W1 = nn.Linear(num_layer * hidden_dim, hidden_dim)\n",
    "        self.W2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.V = nn.Linear(hidden_dim, 1)\n",
    "    \n",
    "    def forward(self, input_, hidden, encoder_outputs):\n",
    "        '''\n",
    "        input_:  decoder的输入，经过embedding [batch, 1, emb_dim]\n",
    "        hidden: decoder的隐藏层，[num_layers x 1 , batch, hidden_dim], 其中的参数为decoder中的参数\n",
    "        encoder_outputs: encoder输出，[batch, seq_len, hidden_dim]\n",
    "        '''\n",
    "        hidden = torch.cat([hidden[i, :, :] for i in range(hidden.size(0))], dim = 1).unsqueeze(1)\n",
    "        # [batch, 1, total dim], 拼接所有层的最后一个dim\n",
    "\n",
    "        score = torch.tanh(self.W1(hidden) + self.W2(encoder_outputs))\n",
    "        # [batch, seq_len, hidden_dim], 两者通过linear转化最后一个维度，最后相加（中间维度广播道seq len）\n",
    "        score = self.V(score)\n",
    "        # [batch, seq_len,1]\n",
    "        ahlpas = torch.softmax(score, dim = 1)\n",
    "        # [batch, seq_len,1]\n",
    "        context = torch.sum(encoder_outputs * ahlpas, dim = 1)\n",
    "        # [batch, hidden_dim]\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 512])\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "num_layer = 2\n",
    "hidden_dim = 256 * num_layer\n",
    "input_ = torch.zeros((128, 1), dtype = torch.int64)\n",
    "hidden = torch.zeros((num_layer, 128, hidden_dim))\n",
    "encoder_outputs = torch.zeros((128, 10, hidden_dim))\n",
    "att = Attention(num_layer, hidden_dim)\n",
    "print(att(input_, hidden, encoder_outputs).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "\n",
    "Decoder任务比较简单，就是跑数据，不用管teacher force以及beam search，需要注意的是，decoder的输入是当个time step上的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, cn_vocab_size,  emb_dim,  hidden_dim, num_layer,dropout, isatt):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(cn_vocab_size, emb_dim)\n",
    "        t_dim =  hidden_dim\n",
    "        if isatt == True:\n",
    "            self.isatt = isatt\n",
    "            self.att = Attention(num_layer, hidden_dim)\n",
    "            t_dim += emb_dim\n",
    "        \n",
    "        self.rnn = nn.GRU(t_dim, hidden_dim, num_layer, dropout = dropout, batch_first = True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim * 4),\n",
    "            nn.Linear(hidden_dim * 4, cn_vocab_size)\n",
    "        )\n",
    "        self.cn_vocab_size = cn_vocab_size\n",
    "    def forward(self, input_, hidden, encoder_outputs):\n",
    "        '''\n",
    "        input_ = [batch, 1]\n",
    "        hidden = [num_layer, batch, hidden_dim], 其中hidden dim受GRU层数的影响，方向定为单向\n",
    "        encoder_outputs = [batch, seq_len, hidden_dim]\n",
    "        '''\n",
    "        emb = self.emb(input_)\n",
    "        emb = self.dropout(emb)\n",
    "        # [batch, 1, emb_dim]\n",
    "        # attention\n",
    "        if self.isatt == True:\n",
    "            context = self.att(input_, hidden, encoder_outputs)\n",
    "            # context = [batch, hidden_dim]\n",
    "            context = context.unsqueeze(1)\n",
    "            # [batch, 1, hidden_dim]\n",
    "        in_cat = torch.cat([emb, context], dim = 2)\n",
    "        # [batch, i, hidden_dim + emb_dim]\n",
    "        out, hidden = self.rnn(in_cat)\n",
    "\n",
    "        # out = [batch, 1, hidden_dim]\n",
    "        out = torch.squeeze(out)\n",
    "        #[batch, hidden_dim]\n",
    "        out = self.fc(out)\n",
    "        # [batch, cn_vocab_size]\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "cn_vocab_size, en_vocab_size = 3000, 2500\n",
    "emb_dim, num_layer =  128, 3\n",
    "hidden_dim, dropout = 256, 0.5\n",
    "decoder = Decoder(cn_vocab_size, en_vocab_size, emb_dim, num_layer, hidden_dim, dropout, isatt= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 128]) torch.Size([2, 1, 256])\n",
      "--------------------------------------------------------------------------------\n",
      "      Layer (type)                 Output Shape         Param #     Tr. Param #\n",
      "================================================================================\n",
      "       Embedding-1                  [2, 1, 128]         384,000         384,000\n",
      "         Dropout-2                  [2, 1, 128]               0               0\n",
      "       Attention-3                     [2, 256]         262,913         262,913\n",
      "             GRU-4     [2, 1, 256], [3, 2, 256]       1,282,560       1,282,560\n",
      "          Linear-5                     [2, 512]         131,584         131,584\n",
      "          Linear-6                    [2, 1024]         525,312         525,312\n",
      "          Linear-7                    [2, 2500]       2,562,500       2,562,500\n",
      "================================================================================\n",
      "Total params: 5,148,869\n",
      "Trainable params: 5,148,869\n",
      "Non-trainable params: 0\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "================================ Hierarchical Summary ================================\n",
      "\n",
      "Decoder(\n",
      "  (emb): Embedding(3000, 128), 384,000 params\n",
      "  (att): Attention(\n",
      "    (W1): Linear(in_features=768, out_features=256, bias=True), 196,864 params\n",
      "    (W2): Linear(in_features=256, out_features=256, bias=True), 65,792 params\n",
      "    (V): Linear(in_features=256, out_features=1, bias=True), 257 params\n",
      "  ), 262,913 params\n",
      "  (rnn): GRU(384, 256, num_layers=3, batch_first=True, dropout=0.5), 1,282,560 params\n",
      "  (dropout): Dropout(p=0.5, inplace=False), 0 params\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=512, bias=True), 131,584 params\n",
      "    (1): Linear(in_features=512, out_features=1024, bias=True), 525,312 params\n",
      "    (2): Linear(in_features=1024, out_features=2500, bias=True), 2,562,500 params\n",
      "  ), 3,219,396 params\n",
      "), 5,148,869 params\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(summary(decoder, torch.zeros((2, 1), dtype = torch.long), torch.zeros(3, 2, 256), torch.zeros(2, 10, 256), show_hierarchical=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq\n",
    "\n",
    "这个负责构建整个模型架构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, input_, target, teacher_force_rate):\n",
    "        '''\n",
    "        input_ = [batch, seq_len], 输入句子样本, en\n",
    "        target = [batch, seq_len], 输出翻译样本，cn\n",
    "        '''\n",
    "        \n",
    "        encoder_outputs, encoder_hidden = encoder(input_)\n",
    "        # encoder_outputs = [batch size, sequence len, hid dim * directions]\n",
    "        # encoder_hidden =  [num_layers * directions, batch size  , hid dim]\n",
    "        shape = encoder_hidden.size()\n",
    "        hidden = encoder_hidden.view(int(shape[0]/2), 2,  shape[1], shape[2])\n",
    "        hidden = torch.cat([hidden[:, i, :, :] for i in range(2)], dim = 2)\n",
    "        # [num_layter, batch_size, hid_dim_dec]\n",
    "        x_dec = target[:, 0]\n",
    "        # 预测概率和标签\n",
    "        outputs = torch.zeros(input_.shape[0], input_.shape[1], self.decoder.cn_vocab_size)\n",
    "        preds = []\n",
    "        for step in range(1, target.size(1)):\n",
    "            x_dec = x_dec.unsqueeze(1)\n",
    "            # [batch, 1]\n",
    "            out, hidden = decoder(x_dec, hidden, encoder_outputs)\n",
    "            # out = [batch, cn_vocab_size]\n",
    "            # hidden = [num_layter, batch_size, hid_dim_dec]\n",
    "            pred = out.argmax(1, keepdim = True)\n",
    "            outputs[:,step, :] = out\n",
    "            preds.append(pred)\n",
    "            teacher_force = random.random() <= teacher_force_rate\n",
    "            x_dec = target[:, step] if teacher_force else pred\n",
    "\n",
    "            preds.append(pred)\n",
    "        preds = torch.cat(preds, dim = 1)\n",
    "        # preds = [batch,]\n",
    "        # outputs = [batch, seq_len, cn_vocab_size]\n",
    "        return preds, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "cn_vocab_size, en_vocab_size = train_set.cn_vocab_size,train_set.en_vocab_size\n",
    "emb_dim, num_layer =  128, 3\n",
    "hidden_dim, dropout = 256, 0.5\n",
    "batch_size = 64\n",
    "decoder = Decoder(cn_vocab_size, en_vocab_size, emb_dim, num_layer, hidden_dim, dropout, isatt= True)\n",
    "encoder = Encoder(en_vocab_size, emb_dim, int(hidden_dim/2), num_layer, dropout)\n",
    "seq2seq = Seq2Seq(encoder, decoder)\n",
    "dataloader = data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "for input_, target in dataloader:\n",
    "    break\n",
    "input_ = torch.tensor(input_, dtype = torch.long)\n",
    "target = torch.tensor(target, dtype = torch.long)\n",
    "pred_labels, pred_probs =seq2seq(input_, target,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, store_model_path, step):\n",
    "    torch.save(model.state_dict(), f'{store_model_path}/model_{step}.ckpt')\n",
    "    return\n",
    "\n",
    "def load_model(model, load_model_path):\n",
    "    print(f'Load model from {load_model_path}')\n",
    "    model.load_state_dict(torch.load(f'{load_model_path}.ckpt'))\n",
    "    return model\n",
    "\n",
    "def build_model(config, en_vocab_size, cn_vocab_size):\n",
    "    # 建構模型\n",
    "    encoder = Encoder(en_vocab_size, config.emb_dim, config.hid_dim, config.n_layers, config.dropout)\n",
    "    decoder = Decoder(cn_vocab_size, config.emb_dim, config.hid_dim, config.n_layers, config.dropout, config.attention)\n",
    "    model = Seq2Seq(encoder, decoder, device)\n",
    "    print(model)\n",
    "    # 建構 optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    print(optimizer)\n",
    "    if config.load_model:\n",
    "        model = load_model(model, config.load_model_path)\n",
    "    model = model.to(device)\n",
    "\n",
    "    return model, optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens2sentence(outputs, int2word):\n",
    "    sentences = []\n",
    "    for tokens in outputs:\n",
    "        sentence = []\n",
    "    for token in tokens:\n",
    "        word = int2word[str(int(token))]\n",
    "        if word == '<EOS>':\n",
    "            break\n",
    "        sentence.append(word)\n",
    "    sentences.append(sentence)\n",
    "  \n",
    "  return sentences\n",
    "\n",
    "def infinite_iter(data_loader):\n",
    "    it = iter(data_loader)\n",
    "    while True:\n",
    "    try:\n",
    "        ret = next(it)\n",
    "        yield ret\n",
    "    except StopIteration:\n",
    "        it = iter(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "def computebleu(sentences, targets):\n",
    "    score = 0 \n",
    "    assert (len(sentences) == len(targets))\n",
    "    # ？\n",
    "    def cut_token(sentence):\n",
    "        tmp = []\n",
    "        for token in sentence:\n",
    "            if token == '<UNK>' or token.isdigit() or len(bytes(token[0], encoding='utf-8')) == 1:\n",
    "                tmp.append(token)\n",
    "            else:\n",
    "                tmp += [word for word in token]\n",
    "        return tmp \n",
    "\n",
    "    for sentence, target in zip(sentences, targets):\n",
    "        sentence = cut_token(sentence)\n",
    "        target = cut_token(target)\n",
    "        # notes: bleus score，其中weight指定的是n-grams的权重，reference需要是一个列表，我还不知道为什么\n",
    "        score += sentence_bleu([target], sentence, weights=(1, 0, 0, 0))                                                                                          \n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_iter, loss_function, total_steps, summary_steps, train_dataset):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    losses = []\n",
    "    loss_sum = 0.0\n",
    "    for step in range(summary_steps):\n",
    "        sources, targets = next(train_iter)\n",
    "        sources, targets = sources.to(device), targets.to(device)\n",
    "        outputs, preds = model(sources, targets, schedule_sampling())\n",
    "        # notes: seq2seq loss计算，问题一，忽略<BOS>\n",
    "        # notes: seq2seq loss计算，问题二，由于cross_entropy直接收二维数据，这里直接reshape到二维\n",
    "        outputs = outputs[:, 1:].reshape(-1, outputs.size(2))\n",
    "        targets = targets[:, 1:].reshape(-1)\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # notes: seq2seq 梯度限制，nlp lstm会遇到的问题之一，函数部分区域非常陡峭，梯度会突然很大，导致无法训练\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        # notes: loss技巧，下面使用了exp(loss)，方便观察变化\n",
    "        # 每五次step打印一次，打印loss平均值，不再以\"epoch\"为单位\n",
    "        loss_sum += loss.item()\n",
    "        if (step + 1) % 5 == 0:\n",
    "            loss_sum = loss_sum / 5\n",
    "            print (\"\\r\", \"train [{}] loss: {:.3f}, Perplexity: {:.3f}      \".format(total_steps + step + 1, loss_sum, np.exp(loss_sum)), end=\" \")\n",
    "            losses.append(loss_sum)\n",
    "            loss_sum = 0.0\n",
    "\n",
    "    return model, optimizer, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, loss_function):\n",
    "    model.eval()\n",
    "    loss_sum, bleu_score= 0.0, 0.0\n",
    "    n = 0\n",
    "    result = []\n",
    "    for sources, targets in dataloader:\n",
    "        sources, targets = sources.to(device), targets.to(device)\n",
    "        batch_size = sources.size(0)\n",
    "        outputs, preds = model.inference(sources, targets)\n",
    "        \n",
    "        outputs = outputs[:, 1:].reshape(-1, outputs.size(2))\n",
    "        targets = targets[:, 1:].reshape(-1)\n",
    "\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "        # 將預測結果轉為文字\n",
    "        targets = targets.view(sources.size(0), -1)\n",
    "        preds = tokens2sentence(preds, dataloader.dataset.idx2word_cn)\n",
    "        sources = tokens2sentence(sources, dataloader.dataset.idx2word_en)\n",
    "        targets = tokens2sentence(targets, dataloader.dataset.idx2word_cn)\n",
    "        for source, pred, target in zip(sources, preds, targets):\n",
    "            result.append((source, pred, target))\n",
    "        # 計算 Bleu Score\n",
    "        bleu_score += computebleu(preds, targets)\n",
    "\n",
    "        n += batch_size\n",
    "\n",
    "    return loss_sum / len(dataloader), bleu_score / n, result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
