{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "id": "5p79-_FjHSjj",
    "outputId": "56106c86-38ee-45cc-a178-3bbf09222392"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-model-summary in c:\\users\\kundalin\\anaconda3\\lib\\site-packages (0.1.1)\n",
      "Requirement already satisfied: torch in c:\\users\\kundalin\\anaconda3\\lib\\site-packages (from pytorch-model-summary) (1.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\kundalin\\appdata\\roaming\\python\\python37\\site-packages (from pytorch-model-summary) (1.17.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kundalin\\anaconda3\\lib\\site-packages (from pytorch-model-summary) (4.44.1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import random\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "!pip install pytorch-model-summary\n",
    "from pytorch_model_summary import summary as summary\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "      torch.cuda.manual_seed(seed)\n",
    "      torch.cuda.manual_seed_all(seed)\n",
    "set_seed(0)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "path = '/content/drive/My Drive/hw10'\n",
    "path = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IDgyL73-HgtK"
   },
   "source": [
    "\n",
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XGUGVa4AHsyw"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zMoWSy9iIz-J"
   },
   "outputs": [],
   "source": [
    "class ImgDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, data, mode):\n",
    "\n",
    "        if mode == 'cnn':\n",
    "            data = data.transpose([0,3,1,2])\n",
    "        else:\n",
    "            data = data.reshape(len(data), -1)\n",
    "\n",
    "        self.data = data\n",
    "        self.mode = mode\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "def get_dataloader(dataset, mode = 'train', batch_size = 128):\n",
    "    shuffle  = True if mode == 'train' else False\n",
    "    loader = data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gatz7kmAHYnk"
   },
   "outputs": [],
   "source": [
    "train = np.load(os.path.join(path, 'train.npy'), allow_pickle=True)\n",
    "test = np.load(os.path.join(path, 'test.npy'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v2PZCMyhKcww"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vKZ5kbjIIHoH"
   },
   "outputs": [],
   "source": [
    "class fcn_autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(fcn_autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(32 * 32 * 3, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True), nn.Linear(64, 12), nn.ReLU(True), nn.Linear(12, 3))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True), nn.Linear(128, 32 * 32 * 3\n",
    "            ), nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        code = self.encoder(x)\n",
    "        x_rec = self.decoder(code)\n",
    "        return code, x_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZFG1GP_4K6YX"
   },
   "outputs": [],
   "source": [
    "class conv_autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(conv_autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 12, 4, stride=2, padding=1),            # [batch, 12, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(12, 24, 4, stride=2, padding=1),           # [batch, 24, 8, 8]\n",
    "            nn.ReLU(),\n",
    "\t\t\t      nn.Conv2d(24, 48, 4, stride=2, padding=1),           # [batch, 48, 4, 4]\n",
    "            nn.ReLU(),\n",
    "    # \t\t\tnn.Conv2d(48, 96, 4, stride=2, padding=1),           # [batch, 96, 2, 2]\n",
    "    #       nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(96, 48, 4, stride=2, padding=1),  # [batch, 48, 4, 4]\n",
    "#             nn.ReLU(),\n",
    "\t\t\t      nn.ConvTranspose2d(48, 24, 4, stride=2, padding=1),  # [batch, 24, 8, 8]\n",
    "            nn.ReLU(),\n",
    "\t\t\t      nn.ConvTranspose2d(24, 12, 4, stride=2, padding=1),  # [batch, 12, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1),   # [batch, 3, 32, 32]\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.dtype)\n",
    "        code = self.encoder(x)\n",
    "        x_rec = self.decoder(code)\n",
    "        return code,x_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zeXeBYWhLZ8z"
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(32*32*3, 400)\n",
    "        self.fc21 = nn.Linear(400, 20)\n",
    "        self.fc22 = nn.Linear(400, 20)\n",
    "        self.fc3 = nn.Linear(20, 400)\n",
    "        self.fc4 = nn.Linear(400, 32*32*3)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = torch.exp(logvar * 0.5)\n",
    "        e = torch.tensor(np.random.normal(size = std.size())).to(device, dtype=torch.float)\n",
    "        return std * e + mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return F.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        # print(z.dtype)\n",
    "        x_rec = self.decode(z)\n",
    "        return  (mu, logvar), (x_rec, mu, logvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "colab_type": "code",
    "id": "eNqvxOnKLv1R",
    "outputId": "1c067464-7f58-4f07-9592-4634ffbbc47c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Linear-1            [1, 400]       1,229,200       1,229,200\n",
      "          Linear-2             [1, 20]           8,020           8,020\n",
      "          Linear-3             [1, 20]           8,020           8,020\n",
      "          Linear-4            [1, 400]           8,400           8,400\n",
      "          Linear-5           [1, 3072]       1,231,872       1,231,872\n",
      "=======================================================================\n",
      "Total params: 2,485,512\n",
      "Trainable params: 2,485,512\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "============================== Hierarchical Summary ==============================\n",
      "\n",
      "VAE(\n",
      "  (fc1): Linear(in_features=3072, out_features=400, bias=True), 1,229,200 params\n",
      "  (fc21): Linear(in_features=400, out_features=20, bias=True), 8,020 params\n",
      "  (fc22): Linear(in_features=400, out_features=20, bias=True), 8,020 params\n",
      "  (fc3): Linear(in_features=20, out_features=400, bias=True), 8,400 params\n",
      "  (fc4): Linear(in_features=400, out_features=3072, bias=True), 1,231,872 params\n",
      "), 2,485,512 params\n",
      "\n",
      "\n",
      "==================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = VAE().to(device)\n",
    "print(summary(model, torch.zeros((1, 3*32*32)).to(device), show_hierarchical=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vcsr5yMUUNuO"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GxoQP2SAZVX9"
   },
   "outputs": [],
   "source": [
    "def loss_vae(output, x):\n",
    "    \"\"\"\n",
    "    rec_x: generating images\n",
    "    x: origin images\n",
    "    mu: latent mean\n",
    "    logvar: latent log variance\n",
    "    \"\"\"\n",
    "    rec_x, mu, logvar = output\n",
    "    mse = nn.MSELoss(reduction = 'sum')(rec_x, x)  # mse loss\n",
    "    # loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = torch.sum(logvar.exp() - (1 + logvar) + (mu**2)) * (0.5)\n",
    "    # KLD = torch.sum(-(logvar.exp()+(mu**2)) + (1 + logvar) ) * (-0.5)\n",
    "    return mse + KLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Coq5njlEMe1N"
   },
   "outputs": [],
   "source": [
    "def run_epoch(model, dataloader, criterion, optimizer, mode, best_loss = np.inf):\n",
    "    epoch_loss = 0\n",
    "    for x_batch in dataloader:\n",
    "        x_batch = x_batch.to(device, dtype = torch.float)\n",
    "        # ===================forward=====================\n",
    "        code, output = model(x_batch)\n",
    "        # if model_type == 'vae':\n",
    "        # loss = loss_vae(output[0], img, output[1], output[2], criterion)\n",
    "        # else:\n",
    "        loss = criterion(output, x_batch)\n",
    "        epoch_loss += loss.item()\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # ===================save====================\n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            torch.save(model, os.path.join(path, 'best_model_{}.pt'.format(mode)))\n",
    "    # ===================log========================\n",
    "    return epoch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_yzO7x2yQqCF"
   },
   "outputs": [],
   "source": [
    "def train_process(mode, learning_rate, batch_size, num_epochs):\n",
    "    set_seed(0)\n",
    "    train_set = ImgDataset(train, mode = mode)\n",
    "    loader = get_dataloader(train_set, mode = mode, batch_size=batch_size)\n",
    "    model_classes = {'fcn':fcn_autoencoder(), 'cnn':conv_autoencoder(), 'vae':VAE()}\n",
    "    model = model_classes[mode].to(device)\n",
    "    criterion = nn.MSELoss(reduction = 'sum') if mode != 'vae' else loss_vae\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        st = time.time()\n",
    "        model.train()\n",
    "        epoch_loss = run_epoch(model, loader, criterion, optimizer, mode)\n",
    "        ed = time.time()\n",
    "        print('{:.2f}s,epoch [{:0>3d}/{}], loss: {:.8f}'\n",
    "            .format(ed-st, epoch, num_epochs, epoch_loss/len(train_set)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "id": "IbJxKEqUcQNN",
    "outputId": "ce692706-8927-4ee8-dae4-f69d8da553da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.89s,epoch [001/500], loss: 238.67313157\n",
      "3.75s,epoch [002/500], loss: 94.70521890\n",
      "3.49s,epoch [003/500], loss: 70.19295094\n",
      "3.54s,epoch [004/500], loss: 57.87036293\n",
      "3.46s,epoch [005/500], loss: 49.02686215\n",
      "3.46s,epoch [006/500], loss: 44.22183844\n",
      "3.40s,epoch [007/500], loss: 41.35901985\n",
      "3.40s,epoch [008/500], loss: 39.40414973\n",
      "3.45s,epoch [009/500], loss: 37.87608655\n",
      "3.49s,epoch [010/500], loss: 37.06621351\n",
      "3.42s,epoch [011/500], loss: 35.97624120\n",
      "3.47s,epoch [012/500], loss: 35.14260513\n",
      "3.50s,epoch [013/500], loss: 34.49964633\n",
      "3.43s,epoch [014/500], loss: 33.97726877\n",
      "3.42s,epoch [015/500], loss: 33.16445159\n",
      "3.44s,epoch [016/500], loss: 32.69546522\n",
      "3.38s,epoch [017/500], loss: 31.58471420\n",
      "3.48s,epoch [018/500], loss: 30.75670291\n",
      "3.54s,epoch [019/500], loss: 30.39430333\n",
      "3.46s,epoch [020/500], loss: 29.45884884\n",
      "3.48s,epoch [021/500], loss: 28.43016223\n",
      "3.44s,epoch [022/500], loss: 27.63918558\n",
      "3.48s,epoch [023/500], loss: 26.75585568\n",
      "3.46s,epoch [024/500], loss: 25.87029265\n",
      "3.44s,epoch [025/500], loss: 25.24764026\n",
      "3.43s,epoch [026/500], loss: 24.60572611\n",
      "3.41s,epoch [027/500], loss: 24.01940263\n",
      "3.46s,epoch [028/500], loss: 23.27029562\n",
      "3.44s,epoch [029/500], loss: 22.95085961\n",
      "3.46s,epoch [030/500], loss: 22.20067554\n",
      "3.48s,epoch [031/500], loss: 21.65405085\n",
      "3.48s,epoch [032/500], loss: 20.91557518\n",
      "3.47s,epoch [033/500], loss: 20.77575937\n",
      "3.49s,epoch [034/500], loss: 20.27278610\n",
      "3.45s,epoch [035/500], loss: 19.72884217\n",
      "3.41s,epoch [036/500], loss: 19.49515320\n",
      "3.45s,epoch [037/500], loss: 19.16940086\n"
     ]
    }
   ],
   "source": [
    "# cnn\n",
    "num_epochs = 500\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "mode = 'cnn'\n",
    "model = train_process(mode, learning_rate, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QGRqT_TkpfD8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "hw10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
