{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 104187,
     "status": "ok",
     "timestamp": 1589279425568,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "-RFltHkEv8GT",
    "outputId": "abc78673-158c-44a6-e31e-1d0419f915d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n",
      "Collecting pytorch-model-summary\n",
      "  Downloading https://files.pythonhosted.org/packages/a0/de/f3548f3081045cfc4020fc297cc9db74839a6849da8a41b89c48a3307da7/pytorch_model_summary-0.1.1-py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-model-summary) (1.18.4)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pytorch-model-summary) (1.5.0+cu101)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-model-summary) (4.41.1)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->pytorch-model-summary) (0.16.0)\n",
      "Installing collected packages: pytorch-model-summary\n",
      "Successfully installed pytorch-model-summary-0.1.1\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive as gdrive\n",
    "gdrive.mount('/content/drive')\n",
    "!pip install pytorch-model-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UkI6Xss-Bg8f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time as time\n",
    "from pytorch_model_summary import summary\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch import optim\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "set_seed(9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RHIdfB_3xDqW"
   },
   "outputs": [],
   "source": [
    "!unzip -qq /content/drive/My\\ Drive/hw7/food-11.zip\n",
    "# !gdown --id '1B8ljdrxYXJsZv2vmTequdPOofp3VF3NN' --output teacher_resnet18.bin\n",
    "!cp -Rf  /content/drive/My\\ Drive/hw7/* ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3KWIdcR20d1-"
   },
   "source": [
    "# 1. Base Implementation\n",
    "\n",
    "-  CNN Architecture Design\n",
    "-  Knowledge Distillation\n",
    "-  Network Pruning\n",
    "-  Weight Quantization\n",
    "\n",
    "我稍微计算了以下，以最后进行weight quantization为基础，我的模型最多0.6M，稍微计算一下最多容许参数153,600, 当前参数为256,779。缩小模型吧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxAdgT2XDywR"
   },
   "source": [
    "##  1.0 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G55MbJQ5DywS"
   },
   "outputs": [],
   "source": [
    "\n",
    "class StudentNet(nn.Module):\n",
    "    '''\n",
    "      在這個Net裡面，我們會使用Depthwise & Pointwise Convolution Layer來疊model。\n",
    "      你會發現，將原本的Convolution Layer換成Dw & Pw後，Accuracy通常不會降很多。\n",
    "\n",
    "      另外，取名為StudentNet是因為這個Model等會要做Knowledge Distillation。\n",
    "    '''\n",
    "\n",
    "    def __init__(self, base=16, width_mult=1):\n",
    "        '''\n",
    "          Args:\n",
    "            base: 這個model一開始的ch數量，每過一層都會*2，直到base*16為止。\n",
    "            width_mult: 為了之後的Network Pruning使用，在base*8 chs的Layer上會 * width_mult代表剪枝後的ch數量。        \n",
    "        '''\n",
    "        super(StudentNet, self).__init__()\n",
    "        multiplier = [1, 2, 4, 8, 16, 16, 16, 16]\n",
    "\n",
    "        # bandwidth: 每一層Layer所使用的ch數量\n",
    "        bandwidth = [ base * m for m in multiplier]\n",
    "\n",
    "        # 我們只Pruning第三層以後的Layer\n",
    "        for i in range(3, 7):\n",
    "            bandwidth[i] = int(bandwidth[i] * width_mult)\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            # 第一層我們通常不會拆解Convolution Layer。\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(3, bandwidth[0], 3, 1, 1),\n",
    "                nn.BatchNorm2d(bandwidth[0]),\n",
    "                nn.ReLU6(),\n",
    "                nn.MaxPool2d(2, 2, 0),\n",
    "            ),\n",
    "            # 接下來每一個Sequential Block都一樣，所以我們只講一個Block\n",
    "            nn.Sequential(\n",
    "                # Depthwise Convolution\n",
    "                nn.Conv2d(bandwidth[0], bandwidth[0], 3, 1, 1, groups=bandwidth[0]),\n",
    "                # Batch Normalization\n",
    "                nn.BatchNorm2d(bandwidth[0]),\n",
    "                # ReLU6 是限制Neuron最小只會到0，最大只會到6。 MobileNet系列都是使用ReLU6。\n",
    "                # 使用ReLU6的原因是因為如果數字太大，會不好壓到float16 / or further qunatization，因此才給個限制。\n",
    "                nn.ReLU6(),\n",
    "                # Pointwise Convolution\n",
    "                nn.Conv2d(bandwidth[0], bandwidth[1], 1),\n",
    "                # 過完Pointwise Convolution不需要再做ReLU，經驗上Pointwise + ReLU效果都會變差。\n",
    "                nn.MaxPool2d(2, 2, 0),\n",
    "                # 每過完一個Block就Down Sampling\n",
    "            ),\n",
    "\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(bandwidth[1], bandwidth[1], 3, 1, 1, groups=bandwidth[1]),\n",
    "                nn.BatchNorm2d(bandwidth[1]),\n",
    "                nn.ReLU6(),\n",
    "                nn.Conv2d(bandwidth[1], bandwidth[2], 1),\n",
    "                nn.MaxPool2d(2, 2, 0),\n",
    "            ),\n",
    "\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(bandwidth[2], bandwidth[2], 3, 1, 1, groups=bandwidth[2]),\n",
    "                nn.BatchNorm2d(bandwidth[2]),\n",
    "                nn.ReLU6(),\n",
    "                nn.Conv2d(bandwidth[2], bandwidth[3], 1),\n",
    "                nn.MaxPool2d(2, 2, 0),\n",
    "            ),\n",
    "\n",
    "            # 到這邊為止因為圖片已經被Down Sample很多次了，所以就不做MaxPool\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(bandwidth[3], bandwidth[3], 3, 1, 1, groups=bandwidth[3]),\n",
    "                nn.BatchNorm2d(bandwidth[3]),\n",
    "                nn.ReLU6(),\n",
    "                nn.Conv2d(bandwidth[3], bandwidth[4], 1),\n",
    "            ),\n",
    "\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(bandwidth[4], bandwidth[4], 3, 1, 1, groups=bandwidth[4]),\n",
    "                nn.BatchNorm2d(bandwidth[4]),\n",
    "                nn.ReLU6(),\n",
    "                nn.Conv2d(bandwidth[5], bandwidth[5], 1),\n",
    "            ),\n",
    "\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(bandwidth[5], bandwidth[5], 3, 1, 1, groups=bandwidth[5]),\n",
    "                nn.BatchNorm2d(bandwidth[5]),\n",
    "                nn.ReLU6(),\n",
    "                nn.Conv2d(bandwidth[6], bandwidth[6], 1),\n",
    "            ),\n",
    "\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(bandwidth[6], bandwidth[6], 3, 1, 1, groups=bandwidth[6]),\n",
    "                nn.BatchNorm2d(bandwidth[6]),\n",
    "                nn.ReLU6(),\n",
    "                nn.Conv2d(bandwidth[6], bandwidth[7], 1),\n",
    "            ),\n",
    "\n",
    "            # 這邊我們採用Global Average Pooling。\n",
    "            # 如果輸入圖片大小不一樣的話，就會因為Global Average Pooling壓成一樣的形狀，這樣子接下來做FC就不會對不起來。\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            # 這邊我們直接Project到11維輸出答案。\n",
    "            nn.Linear(bandwidth[7], 11),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        return self.fc(out)\n",
    "\n",
    "import re\n",
    "import torch\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, folderName, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.label = []\n",
    "\n",
    "        for img_path in sorted(glob(folderName + '/*.jpg')):\n",
    "            try:\n",
    "                # Get classIdx by parsing image path\n",
    "                class_idx = int(re.findall(re.compile(r'\\d+'), img_path)[1])\n",
    "            except:\n",
    "                # if inference mode (there's no answer), class_idx default 0\n",
    "                class_idx = 0\n",
    "\n",
    "            image = Image.open(img_path)\n",
    "            # Get File Descriptor\n",
    "            image_fp = image.fp\n",
    "            image.load()\n",
    "            # Close File Descriptor (or it'll reach OPEN_MAX)\n",
    "            image_fp.close()\n",
    "\n",
    "            self.data.append(image)\n",
    "            self.label.append(class_idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        image = self.data[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.label[idx]\n",
    "\n",
    "\n",
    "trainTransform = transforms.Compose([\n",
    "    transforms.RandomCrop(256, pad_if_needed=True, padding_mode='symmetric'),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "testTransform = transforms.Compose([\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def get_dataloader(dataset, mode ='training', batch_size=32):\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(mode == 'training'))\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "def kd_loss(pred, hard_labels, teacher_pred, T = 20, alpha = 0.5):\n",
    "    hard_loss = F.cross_entropy(pred, hard_labels) * (1 - alpha)\n",
    "    # 官方api说，必须用batchmean，其次为什么一个要用log_softmax，因为官方api里面只对一个log\n",
    "    soft_loss = nn.KLDivLoss(reduction='batchmean')(F.log_softmax(pred/T, dim=1), F.softmax(teacher_pred/T, dim = 1)) * (alpha * T * T)\n",
    "    return hard_loss+soft_loss\n",
    "def run_epoch(data_loader, mode = 'train', alpha = 0.5, learning_rate = 1e-3):\n",
    "    optimizer = optim.AdamW(student_net.parameters(), lr=learning_rate)\n",
    "    total_hit, total_num, total_loss = 0, 0, 0\n",
    "    loss_func = kd_loss\n",
    "    for i, (x_batch, y_batch) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device, dtype = torch.long)\n",
    "        with torch.no_grad():\n",
    "            soft_labels = teacher_net(x_batch)\n",
    "        if mode == 'train':\n",
    "            pred_batch = student_net(x_batch)\n",
    "            loss = loss_func(pred_batch, y_batch, soft_labels, 20, alpha)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        elif mode == 'eval':\n",
    "            with torch.no_grad():\n",
    "                pred_batch = student_net(x_batch)\n",
    "                loss = loss_func(pred_batch, y_batch, soft_labels, 20, alpha)\n",
    "        total_hit += torch.sum(pred_batch.max(1)[1]==y_batch).item()\n",
    "        total_num += len(x_batch)\n",
    "        total_loss += loss.item() * len(x_batch)\n",
    "    return total_loss/total_num, total_hit/total_num\n",
    "\n",
    "def run_epoch_pruning(data_loader, mode = 'train'):\n",
    "    total_loss, hits, num = 0, 0, 0\n",
    "    loss_fun = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "    for i, (x_batch, y_batch) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device, dtype = torch.long)\n",
    "        pred_batch = net(x_batch)\n",
    "        loss = loss_fun(pred_batch, y_batch)\n",
    "        if mode == 'train':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        hits += torch.sum(pred_batch.max(1)[1]==y_batch).item()\n",
    "        total_loss += loss.item() * len(y_batch)\n",
    "        num += len(y_batch)\n",
    "    return total_loss/num, hits/num\n",
    "\n",
    "def to_float16(params):\n",
    "    for name,p in params.items():\n",
    "        if p.shape != torch.Size([]):\n",
    "            params[name] =  p.to(device, dtype = torch.float16)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rDeufRtLDywV"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "# dataset\n",
    "train_set = MyDataset(\n",
    "    f'./food-11/training',\n",
    "    transform=trainTransform)\n",
    "val_set = MyDataset(\n",
    "    f'./food-11/validation',\n",
    "    transform=testTransform)\n",
    "test_set = MyDataset(\n",
    "    f'./food-11/testing',\n",
    "    transform=testTransform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zBGDvWgVDywY",
    "outputId": "c43aa807-6d09-43db-d4a3-2db0327604a7"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-41-4414fc617837>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-41-4414fc617837>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    train_dataloader = get_dataloader(train_set, 'training' batch_size=64)\u001b[0m\n\u001b[1;37m                                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# get dataloader\n",
    "train_dataloader = get_dataloader(train_set, 'training',batch_size=64)\n",
    "valid_dataloader = get_dataloader(val_set, 'eval', batch_size=64)\n",
    "# net init\n",
    "teacher_net = models.resnet18(pretrained=False, num_classes=11).to(device)\n",
    "student_net = StudentNet(base=16).to(device)\n",
    "teacher_net.load_state_dict(torch.load(f'./teacher_resnet18.bin'))\n",
    "# training student_net\n",
    "alpha = 0.5\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hAD_FWaGDywc"
   },
   "outputs": [],
   "source": [
    "teacher_net.eval()\n",
    "now_best_acc = 0\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    student_net.train()\n",
    "    train_loss, train_acc = run_epoch(train_dataloader, mode = 'train', alpha = alpha)\n",
    "    student_net.eval()\n",
    "    val_loss, val_acc = run_epoch(valid_dataloader, mode='eval', alpha = alpha)\n",
    "    end_time = time.time()\n",
    "    if val_acc > now_best_acc:\n",
    "        now_best_acc = val_acc\n",
    "        torch.save(student_net.state_dict(), 'student_model.bin')\n",
    "        print('{:4.2f}s, epoch{:>3d}: train loss: {:6.4f}, acc {:6.4f} valid loss: {:6.4f}, acc {:6.4f}'.format(end_time - start_time, epoch, train_loss, train_acc, val_loss, val_acc))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qwFcRHze1B2R"
   },
   "source": [
    "## 1.1 CNN Architecture Design\n",
    "\n",
    "CNN架构设计，利用Depthwise & Pointwise Convolution进行设计架构。具体实现方式在pytorch中很简单，\n",
    "- Depthwise设置cnn group = input features，那么每一层都会分开卷积。\n",
    "- Pointwise其实就是设置filter size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JElV2q8A3f06"
   },
   "outputs": [],
   "source": [
    "class StudentNet(nn.Module):\n",
    "    def __init__(self, base=16, width_mult = 1):\n",
    "        super(StudentNet, self).__init__()\n",
    "        multiplier = [1, 2, 4, 8, 16, 16, 16, 16]\n",
    "\n",
    "        # bandwidth: 每一層Layer所使用的ch數量\n",
    "        bandwidth = [ base * m for m in multiplier]\n",
    "\n",
    "        # 我們只Pruning第三層以後的Layer\n",
    "        for i in range(3, 7):\n",
    "            bandwidth[i] = int(bandwidth[i] * width_mult)\n",
    "        \n",
    "        layers = self.init_cnn_layers(bandwidth)\n",
    "        self.cnn = nn.Sequential(*layers)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(bandwidth[-1], 11)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        return self.fc(out)\n",
    "\n",
    "    def init_cnn_layers(self, bandwidth):\n",
    "        def cnn_block(in_c, out_c, downsampling = True):\n",
    "            if downsampling:\n",
    "                return nn.Sequential(\n",
    "                    nn.Conv2d(in_c, in_c, 3, 1, 1, groups=in_c),\n",
    "                    nn.BatchNorm2d(in_c),\n",
    "                    nn.ReLU6(),\n",
    "                    nn.Conv2d(in_c, out_c, 1),\n",
    "                    nn.MaxPool2d(2, 2, 0),\n",
    "                )\n",
    "            return nn.Sequential(\n",
    "                    nn.Conv2d(in_c, in_c, 3, 1, 1, groups=in_c),\n",
    "                    nn.BatchNorm2d(in_c),\n",
    "                    nn.ReLU6(),\n",
    "                    nn.Conv2d(in_c, out_c, 1),\n",
    "                )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(cnn_block(3, bandwidth[0]))\n",
    "        downsampling = True\n",
    "        for i in range(len(bandwidth)-1):\n",
    "            if i == 2:\n",
    "                downsampling = False\n",
    "            layers.append(cnn_block(bandwidth[i], bandwidth[i+1], downsampling = downsampling))\n",
    "\n",
    "        # notes: 這邊我們採用Global Average Pooling。\n",
    "        # 如果輸入圖片大小不一樣的話，就會因為Global Average Pooling壓成一樣的形狀，這樣子接下來做FC就不會對不起來。         \n",
    "        layers.append(nn.AdaptiveAvgPool2d((1,1)))\n",
    "        return layers\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 827
    },
    "colab_type": "code",
    "id": "fW7g3cgL9Hi8",
    "outputId": "c8c1b7fb-35e6-4c32-c445-ba8f9115f917"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "           Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "==============================================================================\n",
      "               Conv2d-1      [1, 3, 128, 128]              30              30\n",
      "          BatchNorm2d-2      [1, 3, 128, 128]               6               6\n",
      "                ReLU6-3      [1, 3, 128, 128]               0               0\n",
      "               Conv2d-4     [1, 16, 128, 128]              64              64\n",
      "            MaxPool2d-5       [1, 16, 64, 64]               0               0\n",
      "               Conv2d-6       [1, 16, 64, 64]             160             160\n",
      "          BatchNorm2d-7       [1, 16, 64, 64]              32              32\n",
      "                ReLU6-8       [1, 16, 64, 64]               0               0\n",
      "               Conv2d-9       [1, 32, 64, 64]             544             544\n",
      "           MaxPool2d-10       [1, 32, 32, 32]               0               0\n",
      "              Conv2d-11       [1, 32, 32, 32]             320             320\n",
      "         BatchNorm2d-12       [1, 32, 32, 32]              64              64\n",
      "               ReLU6-13       [1, 32, 32, 32]               0               0\n",
      "              Conv2d-14       [1, 64, 32, 32]           2,112           2,112\n",
      "           MaxPool2d-15       [1, 64, 16, 16]               0               0\n",
      "              Conv2d-16       [1, 64, 16, 16]             640             640\n",
      "         BatchNorm2d-17       [1, 64, 16, 16]             128             128\n",
      "               ReLU6-18       [1, 64, 16, 16]               0               0\n",
      "              Conv2d-19      [1, 128, 16, 16]           8,320           8,320\n",
      "              Conv2d-20      [1, 128, 16, 16]           1,280           1,280\n",
      "         BatchNorm2d-21      [1, 128, 16, 16]             256             256\n",
      "               ReLU6-22      [1, 128, 16, 16]               0               0\n",
      "              Conv2d-23      [1, 256, 16, 16]          33,024          33,024\n",
      "              Conv2d-24      [1, 256, 16, 16]           2,560           2,560\n",
      "         BatchNorm2d-25      [1, 256, 16, 16]             512             512\n",
      "               ReLU6-26      [1, 256, 16, 16]               0               0\n",
      "              Conv2d-27      [1, 256, 16, 16]          65,792          65,792\n",
      "              Conv2d-28      [1, 256, 16, 16]           2,560           2,560\n",
      "         BatchNorm2d-29      [1, 256, 16, 16]             512             512\n",
      "               ReLU6-30      [1, 256, 16, 16]               0               0\n",
      "              Conv2d-31      [1, 256, 16, 16]          65,792          65,792\n",
      "              Conv2d-32      [1, 256, 16, 16]           2,560           2,560\n",
      "         BatchNorm2d-33      [1, 256, 16, 16]             512             512\n",
      "               ReLU6-34      [1, 256, 16, 16]               0               0\n",
      "              Conv2d-35      [1, 256, 16, 16]          65,792          65,792\n",
      "   AdaptiveAvgPool2d-36        [1, 256, 1, 1]               0               0\n",
      "              Linear-37               [1, 11]           2,827           2,827\n",
      "==============================================================================\n",
      "Total params: 256,399\n",
      "Trainable params: 256,399\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(summary(StudentNet(),  torch.zeros(1,3,128,128)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "snn6Xnn1QFJO"
   },
   "source": [
    "## 1.2 Konwledge Distillation\n",
    "\n",
    "思想是让small student net 学习large teacher net，唯一值得注意的是对于student net，它有两个目标。\n",
    "- 分类任务本身\n",
    "- 分布尽量和teacher net的结果像。\n",
    "\n",
    "从这一点来看，为什么会有效？因为teacher net对于各个分类的概率分布肯定是准得多，它可以识别出更多东西，这些知识，也会被student学到。\n",
    "\n",
    "这个任务的重点是loss function的写法——如何描述分布相似？\n",
    "\n",
    "$$Loss = \\alpha T^2 \\times KL(\\frac{\\text{Teacher's Logits}}{T} || \\frac{\\text{Student's Logits}}{T}) + (1-\\alpha)$$\n",
    "\n",
    "相对熵公式\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\mathrm{D}(\\mathrm{P} \\| \\mathrm{Q})=H^{\\prime}(x)-H(x) &=\\sum_{x \\in X} P(x) * \\log \\left(\\frac{1}{Q(x)}\\right)-\\sum_{x \\in X} P(x) * \\log \\left(\\frac{1}{P(x)}\\right) \\\\\n",
    "&=\\sum_{x \\in X} P(x) *\\left[\\log \\left(\\frac{P(x)}{Q(x)}\\right)\\right]\n",
    "\\end{aligned}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mGhUalM2SFWH"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, folderName, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.label = []\n",
    "\n",
    "        for img_path in sorted(glob(folderName + '/*.jpg')):\n",
    "            try:\n",
    "                # Get classIdx by parsing image path\n",
    "                class_idx = int(re.findall(re.compile(r'\\d+'), img_path)[1])\n",
    "            except:\n",
    "                # if inference mode (there's no answer), class_idx default 0\n",
    "                class_idx = 0\n",
    "\n",
    "            image = Image.open(img_path)\n",
    "            # Get File Descriptor\n",
    "            image_fp = image.fp\n",
    "            image.load()\n",
    "            # Close File Descriptor (or it'll reach OPEN_MAX)\n",
    "            image_fp.close()\n",
    "\n",
    "            self.data.append(image)\n",
    "            self.label.append(class_idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        image = self.data[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.label[idx]\n",
    "\n",
    "\n",
    "trainTransform = transforms.Compose([\n",
    "    transforms.RandomCrop(256, pad_if_needed=True, padding_mode='symmetric'),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "testTransform = transforms.Compose([\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def get_dataloader(dataset, batch_size=32):\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(mode == 'training'))\n",
    "\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oNn6M0YSXlqv"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "# dataset\n",
    "train_set = MyDataset(\n",
    "    f'./food-11/{mode}',\n",
    "    transform=trainTransform if mode == 'training' else testTransform)\n",
    "val_set = MyDataset(\n",
    "    f'./food-11/{mode}',\n",
    "    transform=trainTransform if mode == 'training' else testTransform)\n",
    "# get dataloader\n",
    "train_dataloader = get_dataloader(train_set, batch_size=64)\n",
    "valid_dataloader = get_dataloader(val_set, batch_size=64)\n",
    "# net init\n",
    "teacher_net = models.resnet18(pretrained=False, num_classes=11).to(device)\n",
    "student_net = StudentNet(base=16).to(device)\n",
    "teacher_net.load_state_dict(torch.load(f'./teacher_resnet18.bin'))\n",
    "# training student_net\n",
    "alpha = 0.5\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "uFc_x5lpufAs",
    "outputId": "8ba6c58d-1188-4909-c97f-65d4d2b8c71d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-----------------------------------------------------------------------------\\n           Layer (type)         Output Shape         Param #     Tr. Param #\\n=============================================================================\\n               Conv2d-1      [1, 64, 64, 64]           9,408           9,408\\n          BatchNorm2d-2      [1, 64, 64, 64]             128             128\\n                 ReLU-3      [1, 64, 64, 64]               0               0\\n            MaxPool2d-4      [1, 64, 32, 32]               0               0\\n           BasicBlock-5      [1, 64, 32, 32]          73,984          73,984\\n           BasicBlock-6      [1, 64, 32, 32]          73,984          73,984\\n           BasicBlock-7     [1, 128, 16, 16]         230,144         230,144\\n           BasicBlock-8     [1, 128, 16, 16]         295,424         295,424\\n           BasicBlock-9       [1, 256, 8, 8]         919,040         919,040\\n          BasicBlock-10       [1, 256, 8, 8]       1,180,672       1,180,672\\n          BasicBlock-11       [1, 512, 4, 4]       3,673,088       3,673,088\\n          BasicBlock-12       [1, 512, 4, 4]       4,720,640       4,720,640\\n   AdaptiveAvgPool2d-13       [1, 512, 1, 1]               0               0\\n              Linear-14              [1, 11]           5,643           5,643\\n=============================================================================\\nTotal params: 11,182,155\\nTrainable params: 11,182,155\\nNon-trainable params: 0\\n-----------------------------------------------------------------------------'"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# teacher net config\n",
    "print(summary(teacher_net, torch.zeros(1,3,128,128).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "qoe2y9GGkwxt",
    "outputId": "d16ad41f-e118-432d-cb84-2676b6ef293b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.885131195335277\n"
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "teacher_net.eval()\n",
    "hits,num = 0,0\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in valid_dataloader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device, dtype = torch.long)\n",
    "        pred_batch = teacher_net(x_batch)\n",
    "        hits += torch.sum((pred_batch.max(1)[1] == y_batch)).item()\n",
    "        num += len(y_batch)\n",
    "print(hits/num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "y1x5JuU0XW42",
    "outputId": "1012983f-9f61-4d52-f769-4d1633670273"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.9367344379425s, epoch   0: train loss: 15.4225, acc 0.2946 valid loss: 16.7415, acc 0.3461\n",
      "98.83310675621033s, epoch   1: train loss: 14.2279, acc 0.3649 valid loss: 15.4012, acc 0.3808\n",
      "98.95527124404907s, epoch   2: train loss: 13.3938, acc 0.4044 valid loss: 14.3225, acc 0.4268\n",
      "98.77627301216125s, epoch   4: train loss: 12.3526, acc 0.4657 valid loss: 13.3659, acc 0.4845\n"
     ]
    }
   ],
   "source": [
    "def kd_loss(pred, hard_labels, teacher_pred, T = 20, alpha = 0.5):\n",
    "    hard_loss = F.cross_entropy(pred, hard_labels) * (1 - alpha)\n",
    "    # 官方api说，必须用batchmean，其次为什么一个要用log_softmax，因为官方api里面只对一个log\n",
    "    soft_loss = nn.KLDivLoss(reduction='batchmean')(F.log_softmax(pred/T, dim=1), F.softmax(teacher_pred/T, dim = 1)) * (alpha * T * T)\n",
    "    return hard_loss+soft_loss\n",
    "def run_epoch(data_loader, mode = 'train', alpha = 0.5):\n",
    "    optimizer = optim.AdamW(student_net.parameters(), lr=1e-3)\n",
    "    total_hit, total_num, total_loss = 0, 0, 0\n",
    "    loss_func = kd_loss\n",
    "    for i, (x_batch, y_batch) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device, dtype = torch.long)\n",
    "        with torch.no_grad():\n",
    "            soft_labels = teacher_net(x_batch)\n",
    "        if mode == 'train':\n",
    "            pred_batch = student_net(x_batch)\n",
    "            loss = loss_func(pred_batch, y_batch, soft_labels, 20, alpha)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        elif mode == 'eval':\n",
    "            with torch.no_grad():\n",
    "                pred_batch = student_net(x_batch)\n",
    "                loss = loss_func(pred_batch, y_batch, soft_labels, 20, alpha)\n",
    "        total_hit += torch.sum(pred_batch.max(1)[1]==y_batch).item()\n",
    "        total_num += len(x_batch)\n",
    "        total_loss += loss.item() * len(x_batch)\n",
    "    return total_loss/total_num, total_hit/total_num\n",
    "\n",
    "teacher_net.eval()\n",
    "now_best_acc = 0\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    student_net.train()\n",
    "    train_loss, train_acc = run_epoch(train_dataloader, mode = 'train', alpha = alpha)\n",
    "    student_net.eval()\n",
    "    val_loss, val_acc = run_epoch(valid_dataloader, mode='eval', alpha = alpha)\n",
    "    end_time = time.time()\n",
    "    if val_acc > now_best_acc:\n",
    "        now_best_acc = val_acc\n",
    "        torch.save(student_net.state_dict(), 'student_model.bin')\n",
    "        print('{:4.2f}s, epoch{:>3d}: train loss: {:6.4f}, acc {:6.4f} valid loss: {:6.4f}, acc {:6.4f}'.format(end_time - start_time, epoch, train_loss, train_acc, val_loss, val_acc))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N9xGgDMl10Vm"
   },
   "outputs": [],
   "source": [
    "!cp /content/student_model.bin /content/drive/My\\ Drive/hw7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "roMPMH70Dyw5"
   },
   "source": [
    "## 1.3 Network Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OTu_LJJMDyw6"
   },
   "source": [
    "Network Pruning的基本思路是：\n",
    "- 评价net中的不重要参数\n",
    "- 设置新模型\n",
    "- 微调，保存最好结果\n",
    "- net = 新模型，回到第一步\n",
    "\n",
    "notes：Neuron Pruning\n",
    "\n",
    "**如何评价每Neuron的重要性？**\n",
    "\n",
    "实际上必须理解以下几件事\n",
    "\n",
    "1. 当你删除一个Neuron的时候，你会改变连接该Neuron前后的所有weight。也就是说，你会删除掉前两个矩阵。\n",
    "2. dw和pw的cnn是特殊的，在一个cnn层中，我们可以通过其中BatchNorm层的$\\gamma$参数评价filter的重要性，我们会删除不重要的filter（就是cnn中的前后的weight matrix），这个参数和通道的数量是一致的。所以这种网络下的“Neuron”比较抽象。\n",
    "\n",
    "> **Weight & Neuron Pruning**\n",
    "* weight和neuron pruning差別在於prune掉一個neuron就等於是把一個matrix的整個column全部砍掉。但如此一來速度就會比較快。因為neuron pruning後matrix整體變小，但weight pruning大小不變，只是有很多空洞。\n",
    "\n",
    ">  **What to Prune?**\n",
    "\n",
    ">* 既然要Neuron Pruning，那就必須要先衡量Neuron的重要性。衡量完所有的Neuron後，就可以把比較不重要的Neuron刪減掉。\n",
    "* 在這裡我們介紹一個很簡單可以衡量Neuron重要性的方法 - 就是看batchnorm layer的$\\gamma$因子來決定neuron的重要性。 (by paper - Network Slimming)\n",
    "  ![](https://i.imgur.com/JVpCm2r.png)\n",
    "* 相信大家看這個pytorch提供的batchnorm公式應該就可以意識到為甚麼$\\gamma$可以當作重要性來衡量了:)\n",
    "* Network Slimming其實步驟沒有這麼簡單，有興趣的同學可以check以下連結。[Netowrk Slimming](https://arxiv.org/abs/1708.06519)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PHKg-yX5Dyw7"
   },
   "source": [
    "**如何实现？**\n",
    "\n",
    "其实实现起来比较困难，它的基本思路是这样的，把pruning的cnn层次中的不重要filter删除，需要处理整个cnn中各个层次的参数，一并删除。想要完成这件事，必须要知道cnn中每个参数的shape，parameters的构造。\n",
    "\n",
    "助教提供了这样的神表：\n",
    "\n",
    "\n",
    ">* 在Design Architecure內，model的一個block，名稱所對應的Weight；\n",
    "\n",
    ">|#|name|meaning|code|weight shape|\n",
    "|-|-|-|-|-|\n",
    "|0|cnn.{i}.0|Depthwise Convolution Layer|nn.Conv2d(x, x, 3, 1, 1, group=x)|(x, 1, 3, 3)|\n",
    "|1|cnn.{i}.1|Batch Normalization|nn.BatchNorm2d(x)|(x)|\n",
    "|2||ReLU6|nn.ReLU6||\n",
    "|3|cnn.{i}.3|Pointwise Convolution Layer|nn.Conv2d(x, y, 1),|(y, x, 1, 1)|\n",
    "|4||MaxPooling|nn.MaxPool2d(2, 2, 0)||\n",
    "\n",
    "注：\n",
    "- 上述x为cnn层输入dim，y为输出dim\n",
    "- 除了pw层，其他层均可以直接用p[select]，最后一层需要同时处理输出，输入维度\n",
    "- relu和maxpooling是没有参数的，所以可以忽略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3MDFFg3KDyw7"
   },
   "outputs": [],
   "source": [
    "def network_slimming(old_model, new_model):\n",
    "    params = old_model.state_dict()\n",
    "    new_params = new_model.state_dict()\n",
    "    \n",
    "    # selected_idx: 每一層所選擇的neuron index\n",
    "    selected_idx = []\n",
    "    # 我們總共有7層CNN，因此逐一抓取選擇的neuron index們。\n",
    "    for i in range(8):\n",
    "        # 根據上表，我們要抓的gamma係數在cnn.{i}.1.weight內。\n",
    "        importance = params[f'cnn.{i}.1.weight']\n",
    "        # 抓取總共要篩選幾個neuron。\n",
    "        old_dim = len(importance)\n",
    "        new_dim = len(new_params[f'cnn.{i}.1.weight'])\n",
    "        # 以Ranking做Index排序，較大的會在前面(descending=True)。\n",
    "        ranking = torch.argsort(importance, descending=True)\n",
    "        # 把篩選結果放入selected_idx中。\n",
    "        selected_idx.append(ranking[:new_dim])\n",
    "\n",
    "    now_processed = 1\n",
    "    for (name, p1), (name2, p2) in zip(params.items(), new_params.items()):\n",
    "        # 如果是cnn層，則移植參數。\n",
    "        # 如果是FC層，或是該參數只有一個數字(例如batchnorm的tracenum等等資訊)，那麼就直接複製。\n",
    "        if name.startswith('cnn') and p1.size() != torch.Size([]) and now_processed != len(selected_idx):\n",
    "            # 當處理到Pointwise的weight時，讓now_processed+1，表示該層的移植已經完成。\n",
    "            if name.startswith(f'cnn.{now_processed}.3'):\n",
    "                now_processed += 1\n",
    "\n",
    "            # 如果是pointwise，weight會被上一層的pruning和下一層的pruning所影響，因此需要特判。\n",
    "            if name.endswith('3.weight'):\n",
    "                # 如果是最後一層cnn，則輸出的neuron不需要prune掉。\n",
    "                if len(selected_idx) == now_processed:\n",
    "                    new_params[name] = p1[:,selected_idx[now_processed-1]] # [output, input, 1, 1], 值pruning input\n",
    "                # 反之，就依照上層和下層所選擇的index進行移植。\n",
    "                # 這裡需要注意的是Conv2d(x,y,1)的weight shape是(y,x,1,1)，順序是反的。\n",
    "                else:\n",
    "                    new_params[name] = p1[selected_idx[now_processed]][:,selected_idx[now_processed-1]]# [output, input, 1, 1], pruning 两者\n",
    "            else:\n",
    "                # cnn中除了pointwise层次，其他bias，或者什么都直接使用选择部分\n",
    "                new_params[name] = p1[selected_idx[now_processed]]\n",
    "        else:\n",
    "            new_params[name] = p1\n",
    "\n",
    "    # 讓新model load進被我們篩選過的parameters，並回傳new_model。        \n",
    "    new_model.load_state_dict(new_params)\n",
    "    return new_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y0XZuYINDyw_"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gu4WAe9qDyxC"
   },
   "outputs": [],
   "source": [
    "net = StudentNet().to(device)\n",
    "net.load_state_dict(torch.load('./stu_model_250000_p095_1.bin'))\n",
    "# get dataloader\n",
    "valid_dataloader = get_dataloader(val_set, 'eval', batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7626,
     "status": "ok",
     "timestamp": 1589197264443,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "52-Xdg85HlfR",
    "outputId": "8c71d774-0d25-40d7-bf55-9a6a8b78baa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8137026239067056\n"
     ]
    }
   ],
   "source": [
    "# get dataloader\n",
    "train_dataloader = get_dataloader(train_set, 'training', batch_size=64)\n",
    "valid_dataloader = get_dataloader(val_set, 'eval', batch_size=64)\n",
    "net.eval()\n",
    "hits,num = 0,0\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in valid_dataloader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device, dtype = torch.long)\n",
    "        pred_batch = net(x_batch)\n",
    "        hits += torch.sum((pred_batch.max(1)[1] == y_batch)).item()\n",
    "        num += len(y_batch)\n",
    "print(hits/num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 773
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1294,
     "status": "ok",
     "timestamp": 1589196649750,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "6nvOPye_DyxO",
    "outputId": "006280a0-d44f-42da-ebdb-dd6dd979aedf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "           Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "==============================================================================\n",
      "               Conv2d-1     [1, 16, 128, 128]             448             448\n",
      "          BatchNorm2d-2     [1, 16, 128, 128]              32              32\n",
      "                ReLU6-3     [1, 16, 128, 128]               0               0\n",
      "            MaxPool2d-4       [1, 16, 64, 64]               0               0\n",
      "               Conv2d-5       [1, 16, 64, 64]             160             160\n",
      "          BatchNorm2d-6       [1, 16, 64, 64]              32              32\n",
      "                ReLU6-7       [1, 16, 64, 64]               0               0\n",
      "               Conv2d-8       [1, 32, 64, 64]             544             544\n",
      "            MaxPool2d-9       [1, 32, 32, 32]               0               0\n",
      "              Conv2d-10       [1, 32, 32, 32]             320             320\n",
      "         BatchNorm2d-11       [1, 32, 32, 32]              64              64\n",
      "               ReLU6-12       [1, 32, 32, 32]               0               0\n",
      "              Conv2d-13       [1, 64, 32, 32]           2,112           2,112\n",
      "           MaxPool2d-14       [1, 64, 16, 16]               0               0\n",
      "              Conv2d-15       [1, 64, 16, 16]             640             640\n",
      "         BatchNorm2d-16       [1, 64, 16, 16]             128             128\n",
      "               ReLU6-17       [1, 64, 16, 16]               0               0\n",
      "              Conv2d-18      [1, 128, 16, 16]           8,320           8,320\n",
      "           MaxPool2d-19        [1, 128, 8, 8]               0               0\n",
      "              Conv2d-20        [1, 128, 8, 8]           1,280           1,280\n",
      "         BatchNorm2d-21        [1, 128, 8, 8]             256             256\n",
      "               ReLU6-22        [1, 128, 8, 8]               0               0\n",
      "              Conv2d-23        [1, 256, 8, 8]          33,024          33,024\n",
      "              Conv2d-24        [1, 256, 8, 8]           2,560           2,560\n",
      "         BatchNorm2d-25        [1, 256, 8, 8]             512             512\n",
      "               ReLU6-26        [1, 256, 8, 8]               0               0\n",
      "              Conv2d-27        [1, 256, 8, 8]          65,792          65,792\n",
      "              Conv2d-28        [1, 256, 8, 8]           2,560           2,560\n",
      "         BatchNorm2d-29        [1, 256, 8, 8]             512             512\n",
      "               ReLU6-30        [1, 256, 8, 8]               0               0\n",
      "              Conv2d-31        [1, 256, 8, 8]          65,792          65,792\n",
      "              Conv2d-32        [1, 256, 8, 8]           2,560           2,560\n",
      "         BatchNorm2d-33        [1, 256, 8, 8]             512             512\n",
      "               ReLU6-34        [1, 256, 8, 8]               0               0\n",
      "              Conv2d-35        [1, 256, 8, 8]          65,792          65,792\n",
      "   AdaptiveAvgPool2d-36        [1, 256, 1, 1]               0               0\n",
      "              Linear-37               [1, 11]           2,827           2,827\n",
      "==============================================================================\n",
      "Total params: 256,779\n",
      "Trainable params: 256,779\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(summary(net, torch.zeros(1, 3, 128, 128).to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mi9-91ETPLCp"
   },
   "outputs": [],
   "source": [
    "def run_epoch_pruning(data_loader, mode = 'train'):\n",
    "    total_loss, hits, num = 0, 0, 0\n",
    "    loss_fun = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "    for i, (x_batch, y_batch) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device, dtype = torch.long)\n",
    "        pred_batch = net(x_batch)\n",
    "        loss = loss_fun(pred_batch, y_batch)\n",
    "        if mode == 'train':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        hits += torch.sum(pred_batch.max(1)[1]==y_batch).item()\n",
    "        total_loss += loss.item() * len(y_batch)\n",
    "        num += len(y_batch)\n",
    "\n",
    "    return total_loss/num, hits/num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OUVKdGfld41A"
   },
   "outputs": [],
   "source": [
    "drive_path = '/content/drive/My Drive/hw7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 728646,
     "status": "ok",
     "timestamp": 1589203139524,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "snv9tWSYG4gP",
    "outputId": "2401c9b3-894a-404c-f33d-5e1b4db32a6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "base acc 0.7580174927113703 after pruning\n",
      "fine tuning\n",
      "Saving with acc : 0.8011661807580175\n",
      "49.31s, epoch  0: train loss: 0.3924, acc 0.8806 valid loss: 0.8183, acc 0.8012\n",
      "49.42s, epoch  1: train loss: 0.3352, acc 0.8897 valid loss: 0.9254, acc 0.7805\n",
      "49.43s, epoch  2: train loss: 0.3317, acc 0.8889 valid loss: 1.0012, acc 0.7566\n",
      "Saving with acc : 0.8032069970845481\n",
      "49.36s, epoch  3: train loss: 0.3213, acc 0.8915 valid loss: 0.8206, acc 0.8032\n",
      "49.22s, epoch  4: train loss: 0.3097, acc 0.9003 valid loss: 0.8136, acc 0.7997\n",
      "---------------------------------------\n",
      "base acc 0.7344023323615161 after pruning\n",
      "fine tuning\n",
      "Saving with acc : 0.793002915451895\n",
      "49.42s, epoch  0: train loss: 0.3392, acc 0.8872 valid loss: 0.7704, acc 0.7930\n",
      "49.72s, epoch  1: train loss: 0.3273, acc 0.8903 valid loss: 0.8039, acc 0.7901\n",
      "49.78s, epoch  2: train loss: 0.3115, acc 0.8961 valid loss: 0.8176, acc 0.7878\n",
      "49.84s, epoch  3: train loss: 0.3196, acc 0.8925 valid loss: 0.7770, acc 0.7913\n",
      "49.24s, epoch  4: train loss: 0.2940, acc 0.9032 valid loss: 0.8207, acc 0.7886\n",
      "---------------------------------------\n",
      "base acc 0.7393586005830903 after pruning\n",
      "fine tuning\n",
      "Saving with acc : 0.789795918367347\n",
      "48.92s, epoch  0: train loss: 0.3861, acc 0.8663 valid loss: 0.7648, acc 0.7898\n",
      "48.83s, epoch  1: train loss: 0.3705, acc 0.8750 valid loss: 0.8104, acc 0.7746\n",
      "Saving with acc : 0.7915451895043731\n",
      "48.66s, epoch  2: train loss: 0.3459, acc 0.8827 valid loss: 0.7744, acc 0.7915\n",
      "48.69s, epoch  3: train loss: 0.3436, acc 0.8847 valid loss: 0.7900, acc 0.7898\n",
      "48.65s, epoch  4: train loss: 0.3242, acc 0.8910 valid loss: 0.8802, acc 0.7784\n",
      "---------------------------------------\n",
      "base acc 0.7072886297376093 after pruning\n",
      "fine tuning\n",
      "Saving with acc : 0.787463556851312\n",
      "48.65s, epoch  0: train loss: 0.3779, acc 0.8762 valid loss: 0.8359, acc 0.7875\n",
      "48.61s, epoch  1: train loss: 0.3753, acc 0.8719 valid loss: 0.7817, acc 0.7843\n",
      "Saving with acc : 0.7886297376093294\n",
      "48.67s, epoch  2: train loss: 0.3553, acc 0.8819 valid loss: 0.8326, acc 0.7886\n",
      "Saving with acc : 0.7965014577259475\n",
      "48.67s, epoch  3: train loss: 0.3497, acc 0.8852 valid loss: 0.8124, acc 0.7965\n",
      "48.74s, epoch  4: train loss: 0.3416, acc 0.8830 valid loss: 0.7745, acc 0.7910\n",
      "---------------------------------------\n",
      "base acc 0.6959183673469388 after pruning\n",
      "fine tuning\n",
      "Saving with acc : 0.7845481049562683\n",
      "49.56s, epoch  0: train loss: 0.3924, acc 0.8680 valid loss: 0.8167, acc 0.7845\n",
      "49.67s, epoch  1: train loss: 0.3868, acc 0.8721 valid loss: 0.8656, acc 0.7697\n",
      "Saving with acc : 0.7848396501457726\n",
      "49.66s, epoch  2: train loss: 0.3790, acc 0.8727 valid loss: 0.7655, acc 0.7848\n",
      "49.59s, epoch  3: train loss: 0.3513, acc 0.8823 valid loss: 0.8262, acc 0.7761\n",
      "49.62s, epoch  4: train loss: 0.3619, acc 0.8763 valid loss: 0.7926, acc 0.7816\n",
      "---------------------------------------\n",
      "base acc 0.7282798833819242 after pruning\n",
      "fine tuning\n",
      "Saving with acc : 0.7836734693877551\n",
      "48.55s, epoch  0: train loss: 0.4218, acc 0.8600 valid loss: 0.7948, acc 0.7837\n",
      "48.56s, epoch  1: train loss: 0.3878, acc 0.8711 valid loss: 0.8213, acc 0.7743\n",
      "48.63s, epoch  2: train loss: 0.3945, acc 0.8686 valid loss: 0.7950, acc 0.7808\n",
      "Saving with acc : 0.7895043731778426\n",
      "48.50s, epoch  3: train loss: 0.3762, acc 0.8734 valid loss: 0.7582, acc 0.7895\n",
      "48.55s, epoch  4: train loss: 0.3686, acc 0.8776 valid loss: 0.8302, acc 0.7802\n",
      "---------------------------------------\n",
      "base acc 0.6801749271137026 after pruning\n",
      "fine tuning\n",
      "Saving with acc : 0.7641399416909621\n",
      "47.73s, epoch  0: train loss: 0.4268, acc 0.8568 valid loss: 0.8260, acc 0.7641\n",
      "Saving with acc : 0.7839650145772594\n",
      "47.92s, epoch  1: train loss: 0.4099, acc 0.8665 valid loss: 0.7622, acc 0.7840\n",
      "49.17s, epoch  2: train loss: 0.3980, acc 0.8671 valid loss: 0.8057, acc 0.7758\n",
      "48.31s, epoch  3: train loss: 0.3926, acc 0.8726 valid loss: 0.8531, acc 0.7723\n",
      "47.78s, epoch  4: train loss: 0.3707, acc 0.8732 valid loss: 0.8149, acc 0.7840\n",
      "---------------------------------------\n",
      "base acc 0.7221574344023324 after pruning\n",
      "fine tuning\n",
      "Saving with acc : 0.7775510204081633\n",
      "48.88s, epoch  0: train loss: 0.4637, acc 0.8489 valid loss: 0.7822, acc 0.7776\n",
      "48.05s, epoch  1: train loss: 0.4220, acc 0.8585 valid loss: 0.8478, acc 0.7673\n",
      "47.56s, epoch  2: train loss: 0.4273, acc 0.8533 valid loss: 0.8236, acc 0.7688\n",
      "47.80s, epoch  3: train loss: 0.4068, acc 0.8658 valid loss: 0.7931, acc 0.7767\n",
      "Saving with acc : 0.7807580174927113\n",
      "48.82s, epoch  4: train loss: 0.3984, acc 0.8615 valid loss: 0.8004, acc 0.7808\n",
      "---------------------------------------\n",
      "base acc 0.6212827988338192 after pruning\n",
      "fine tuning\n",
      "Saving with acc : 0.7653061224489796\n",
      "48.01s, epoch  0: train loss: 0.4613, acc 0.8500 valid loss: 0.8808, acc 0.7653\n",
      "Saving with acc : 0.7655976676384839\n",
      "47.96s, epoch  1: train loss: 0.4354, acc 0.8547 valid loss: 0.8739, acc 0.7656\n",
      "47.97s, epoch  2: train loss: 0.4279, acc 0.8617 valid loss: 0.8222, acc 0.7650\n",
      "Saving with acc : 0.7857142857142857\n",
      "47.91s, epoch  3: train loss: 0.4133, acc 0.8631 valid loss: 0.7941, acc 0.7857\n",
      "47.96s, epoch  4: train loss: 0.4358, acc 0.8538 valid loss: 0.8015, acc 0.7711\n",
      "---------------------------------------\n",
      "base acc 0.6941690962099125 after pruning\n",
      "fine tuning\n",
      "Saving with acc : 0.773469387755102\n",
      "47.68s, epoch  0: train loss: 0.4935, acc 0.8331 valid loss: 0.7964, acc 0.7735\n",
      "47.64s, epoch  1: train loss: 0.4493, acc 0.8513 valid loss: 0.9439, acc 0.7472\n",
      "47.61s, epoch  2: train loss: 0.4354, acc 0.8560 valid loss: 0.8671, acc 0.7554\n",
      "Saving with acc : 0.7810495626822157\n",
      "47.64s, epoch  3: train loss: 0.4345, acc 0.8563 valid loss: 0.7608, acc 0.7810\n",
      "Saving with acc : 0.7862973760932944\n",
      "47.55s, epoch  4: train loss: 0.4210, acc 0.8550 valid loss: 0.7793, acc 0.7863\n"
     ]
    }
   ],
   "source": [
    "# get dataloader\n",
    "train_dataloader = get_dataloader(train_set, 'training', batch_size=64)\n",
    "valid_dataloader = get_dataloader(val_set, 'eval', batch_size=64)\n",
    "device = torch.device('cuda')\n",
    "net = StudentNet().to(device)\n",
    "pruning_rate = 0.95\n",
    "n_pruning = 10\n",
    "width_mult = 1\n",
    "epochs = 5\n",
    "for i in range(n_pruning):\n",
    "    # update\n",
    "    net.load_state_dict( torch.load(os.path.join(drive_path, f'stu_model_250000_p095_{width_mult}.bin')))\n",
    "    width_mult *= pruning_rate\n",
    "    # pruning\n",
    "    net_new = StudentNet(width_mult=width_mult).to(device)\n",
    "    net = network_slimming(net, net_new)\n",
    "    net.eval()\n",
    "    val_loss, val_acc = run_epoch_pruning(valid_dataloader, mode = 'eval')\n",
    "    best_acc = val_acc\n",
    "    print('---------------------------------------')\n",
    "    print('base acc {} after pruning'.format(val_acc))\n",
    "    print('fine tuning')\n",
    "    # fine tuning\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        net.train()\n",
    "        train_loss, train_acc = run_epoch_pruning(train_dataloader, mode = 'train')\n",
    "        net.eval()\n",
    "        val_loss, val_acc = run_epoch_pruning(valid_dataloader, mode = 'eval')\n",
    "        end_time = time.time()\n",
    "        if best_acc < val_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(net.state_dict(),os.path.join(drive_path, f'stu_model_250000_p095_{width_mult}.bin') )\n",
    "            print('Saving with acc : {}'.format(val_acc))\n",
    "        print('{:4.2f}s, epoch{:>3d}: train loss: {:6.4f}, acc {:6.4f} valid loss: {:6.4f}, acc {:6.4f}'.format(end_time - start_time, epoch, train_loss, train_acc, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2424926,
     "status": "ok",
     "timestamp": 1589205564480,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "fsYZ6DJgfqk2",
    "outputId": "00a859bf-b086-49cd-ffca-422a4c4d781a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "base acc 0.6720116618075802 after pruning\n",
      "fine tuning\n",
      "Saving with acc : 0.7793002915451895\n",
      "48.95s, epoch  0: train loss: 0.4017, acc 0.8715 valid loss: 0.8940, acc 0.7793\n",
      "Saving with acc : 0.7895043731778426\n",
      "48.94s, epoch  1: train loss: 0.3776, acc 0.8751 valid loss: 0.8064, acc 0.7895\n",
      "Saving with acc : 0.793002915451895\n",
      "49.00s, epoch  2: train loss: 0.3531, acc 0.8835 valid loss: 0.8348, acc 0.7930\n",
      "49.03s, epoch  3: train loss: 0.3362, acc 0.8879 valid loss: 0.8480, acc 0.7860\n",
      "49.06s, epoch  4: train loss: 0.3410, acc 0.8864 valid loss: 0.8217, acc 0.7866\n",
      "---------------------------------------\n",
      "base acc 0.5918367346938775 after pruning\n",
      "fine tuning\n",
      "Saving with acc : 0.7784256559766763\n",
      "48.72s, epoch  0: train loss: 0.4529, acc 0.8494 valid loss: 0.8275, acc 0.7784\n",
      "48.78s, epoch  1: train loss: 0.3997, acc 0.8665 valid loss: 0.8294, acc 0.7665\n",
      "Saving with acc : 0.7830903790087463\n",
      "48.70s, epoch  2: train loss: 0.3875, acc 0.8704 valid loss: 0.8100, acc 0.7831\n",
      "48.77s, epoch  3: train loss: 0.3848, acc 0.8713 valid loss: 0.8619, acc 0.7761\n",
      "48.76s, epoch  4: train loss: 0.3620, acc 0.8779 valid loss: 0.8010, acc 0.7831\n",
      "---------------------------------------\n",
      "base acc 0.6545189504373178 after pruning\n",
      "fine tuning\n",
      "Saving with acc : 0.7795918367346939\n",
      "49.68s, epoch  0: train loss: 0.4970, acc 0.8336 valid loss: 0.7816, acc 0.7796\n",
      "49.80s, epoch  1: train loss: 0.4499, acc 0.8489 valid loss: 0.8655, acc 0.7665\n",
      "Saving with acc : 0.785131195335277\n",
      "49.69s, epoch  2: train loss: 0.4331, acc 0.8574 valid loss: 0.7770, acc 0.7851\n",
      "49.65s, epoch  3: train loss: 0.4199, acc 0.8587 valid loss: 0.8217, acc 0.7755\n",
      "Saving with acc : 0.7880466472303207\n",
      "49.69s, epoch  4: train loss: 0.3974, acc 0.8677 valid loss: 0.7847, acc 0.7880\n",
      "---------------------------------------\n",
      "base acc 0.6416909620991254 after pruning\n",
      "fine tuning\n",
      "Saving with acc : 0.7676384839650146\n",
      "48.52s, epoch  0: train loss: 0.5062, acc 0.8334 valid loss: 0.8236, acc 0.7676\n",
      "48.02s, epoch  1: train loss: 0.4822, acc 0.8386 valid loss: 0.8177, acc 0.7665\n",
      "47.85s, epoch  2: train loss: 0.4609, acc 0.8490 valid loss: 0.8422, acc 0.7662\n",
      "Saving with acc : 0.7944606413994169\n",
      "49.15s, epoch  3: train loss: 0.4476, acc 0.8516 valid loss: 0.7276, acc 0.7945\n",
      "48.59s, epoch  4: train loss: 0.4425, acc 0.8549 valid loss: 0.7906, acc 0.7843\n",
      "---------------------------------------\n",
      "base acc 0.6609329446064139 after pruning\n",
      "fine tuning\n",
      "Saving with acc : 0.7612244897959184\n",
      "47.38s, epoch  0: train loss: 0.5522, acc 0.8187 valid loss: 0.8372, acc 0.7612\n",
      "Saving with acc : 0.7688046647230321\n",
      "47.42s, epoch  1: train loss: 0.5159, acc 0.8261 valid loss: 0.7747, acc 0.7688\n",
      "47.38s, epoch  2: train loss: 0.5119, acc 0.8295 valid loss: 0.8589, acc 0.7569\n",
      "47.30s, epoch  3: train loss: 0.4897, acc 0.8367 valid loss: 0.8214, acc 0.7665\n",
      "Saving with acc : 0.7728862973760933\n",
      "47.34s, epoch  4: train loss: 0.4844, acc 0.8383 valid loss: 0.7702, acc 0.7729\n",
      "---------------------------------------\n",
      "base acc 0.6192419825072887 after pruning\n",
      "fine tuning\n",
      "Saving with acc : 0.7518950437317784\n",
      "47.10s, epoch  0: train loss: 0.5615, acc 0.8155 valid loss: 0.8567, acc 0.7519\n",
      "Saving with acc : 0.7620991253644315\n",
      "47.09s, epoch  1: train loss: 0.5423, acc 0.8238 valid loss: 0.7890, acc 0.7621\n",
      "47.13s, epoch  2: train loss: 0.5125, acc 0.8269 valid loss: 0.8834, acc 0.7528\n",
      "47.20s, epoch  3: train loss: 0.5200, acc 0.8273 valid loss: 0.8311, acc 0.7577\n",
      "Saving with acc : 0.7728862973760933\n",
      "47.20s, epoch  4: train loss: 0.5030, acc 0.8326 valid loss: 0.7818, acc 0.7729\n",
      "---------------------------------------\n",
      "base acc 0.5927113702623906 after pruning\n",
      "fine tuning\n",
      "Saving with acc : 0.7498542274052478\n",
      "45.80s, epoch  0: train loss: 0.6439, acc 0.7846 valid loss: 0.8281, acc 0.7499\n",
      "Saving with acc : 0.7606413994169097\n",
      "45.74s, epoch  1: train loss: 0.5715, acc 0.8055 valid loss: 0.8225, acc 0.7606\n",
      "45.76s, epoch  2: train loss: 0.5637, acc 0.8109 valid loss: 0.8103, acc 0.7554\n",
      "Saving with acc : 0.7661807580174927\n",
      "45.70s, epoch  3: train loss: 0.5527, acc 0.8154 valid loss: 0.8151, acc 0.7662\n",
      "45.59s, epoch  4: train loss: 0.5449, acc 0.8199 valid loss: 0.8097, acc 0.7618\n",
      "---------------------------------------\n",
      "base acc 0.4775510204081633 after pruning\n",
      "fine tuning\n",
      "Saving with acc : 0.7548104956268221\n",
      "45.42s, epoch  0: train loss: 0.6957, acc 0.7692 valid loss: 0.7671, acc 0.7548\n",
      "45.35s, epoch  1: train loss: 0.6338, acc 0.7903 valid loss: 0.8547, acc 0.7391\n",
      "Saving with acc : 0.7591836734693878\n",
      "45.40s, epoch  2: train loss: 0.6234, acc 0.7904 valid loss: 0.7972, acc 0.7592\n",
      "Saving with acc : 0.773469387755102\n",
      "45.39s, epoch  3: train loss: 0.5922, acc 0.8051 valid loss: 0.7514, acc 0.7735\n",
      "45.27s, epoch  4: train loss: 0.5850, acc 0.8066 valid loss: 0.8413, acc 0.7472\n",
      "---------------------------------------\n",
      "base acc 0.5629737609329446 after pruning\n",
      "fine tuning\n",
      "Saving with acc : 0.7486880466472303\n",
      "45.58s, epoch  0: train loss: 0.7092, acc 0.7667 valid loss: 0.8287, acc 0.7487\n",
      "Saving with acc : 0.7574344023323615\n",
      "45.59s, epoch  1: train loss: 0.6705, acc 0.7778 valid loss: 0.8099, acc 0.7574\n",
      "45.66s, epoch  2: train loss: 0.6602, acc 0.7776 valid loss: 0.8324, acc 0.7487\n",
      "Saving with acc : 0.7594752186588921\n",
      "45.61s, epoch  3: train loss: 0.6272, acc 0.7912 valid loss: 0.8078, acc 0.7595\n",
      "Saving with acc : 0.7690962099125365\n",
      "45.70s, epoch  4: train loss: 0.6183, acc 0.7979 valid loss: 0.7487, acc 0.7691\n",
      "---------------------------------------\n",
      "base acc 0.5915451895043732 after pruning\n",
      "fine tuning\n",
      "Saving with acc : 0.7463556851311953\n",
      "44.93s, epoch  0: train loss: 0.7481, acc 0.7485 valid loss: 0.8375, acc 0.7464\n",
      "Saving with acc : 0.7574344023323615\n",
      "45.05s, epoch  1: train loss: 0.7100, acc 0.7655 valid loss: 0.7826, acc 0.7574\n",
      "Saving with acc : 0.7603498542274052\n",
      "45.08s, epoch  2: train loss: 0.6698, acc 0.7798 valid loss: 0.7838, acc 0.7603\n",
      "45.13s, epoch  3: train loss: 0.6792, acc 0.7765 valid loss: 0.8168, acc 0.7510\n",
      "45.03s, epoch  4: train loss: 0.6649, acc 0.7802 valid loss: 0.8640, acc 0.7344\n"
     ]
    }
   ],
   "source": [
    "# get dataloader\n",
    "train_dataloader = get_dataloader(train_set, 'training', batch_size=64)\n",
    "valid_dataloader = get_dataloader(val_set, 'eval', batch_size=64)\n",
    "device = torch.device('cuda')\n",
    "net = StudentNet().to(device)\n",
    "pruning_rate = 0.90\n",
    "n_pruning = 10\n",
    "width_mult = 1\n",
    "epochs = 5\n",
    "for i in range(n_pruning):\n",
    "    # update\n",
    "    net.load_state_dict( torch.load(os.path.join(drive_path, f'stu_model_250000_p090_{width_mult}.bin')))\n",
    "    width_mult *= pruning_rate\n",
    "    # pruning\n",
    "    net_new = StudentNet(width_mult=width_mult).to(device)\n",
    "    net = network_slimming(net, net_new)\n",
    "    net.eval()\n",
    "    val_loss, val_acc = run_epoch_pruning(valid_dataloader, mode = 'eval')\n",
    "    best_acc = val_acc\n",
    "    print('---------------------------------------')\n",
    "    print('base acc {} after pruning'.format(val_acc))\n",
    "    print('fine tuning')\n",
    "    # fine tuning\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        net.train()\n",
    "        train_loss, train_acc = run_epoch_pruning(train_dataloader, mode = 'train')\n",
    "        net.eval()\n",
    "        val_loss, val_acc = run_epoch_pruning(valid_dataloader, mode = 'eval')\n",
    "        end_time = time.time()\n",
    "        if best_acc < val_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(net.state_dict(),os.path.join(drive_path, f'stu_model_250000_p090_{width_mult}.bin') )\n",
    "            print('Saving with acc : {}'.format(val_acc))\n",
    "        print('{:4.2f}s, epoch{:>3d}: train loss: {:6.4f}, acc {:6.4f} valid loss: {:6.4f}, acc {:6.4f}'.format(end_time - start_time, epoch, train_loss, train_acc, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1tzbE3SWV2G2"
   },
   "source": [
    "## 1.4 Weight Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9NyCQg3ZPKO7"
   },
   "outputs": [],
   "source": [
    "改变参数类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7fKW0clitxUE"
   },
   "outputs": [],
   "source": [
    "def to_float16(params):\n",
    "    for name,p in params.items():\n",
    "        if p.shape != torch.Size([]):\n",
    "            params[name] =  p.to(device, dtype = torch.float16)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YpmW2NrutxUG"
   },
   "outputs": [],
   "source": [
    "params = torch.load('./student_model.bin')\n",
    "device = torch.device('cuda')\n",
    "params = to_float16(params)\n",
    "torch.save(params, './student_model_f16.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r-k4jbdJ_xwV"
   },
   "outputs": [],
   "source": [
    "stu_model_250000_p095_0.6634204312890623.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O6QWwzH751CH"
   },
   "outputs": [],
   "source": [
    "# stu model 250000 \n",
    "params = torch.load('./stu_model_250000_p095_0.6634204312890623.bin')\n",
    "device = torch.device('cuda')\n",
    "params = to_float16(params)\n",
    "torch.save(params, './stu_model_250000_p095_0.6634204312890623_f16.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14870,
     "status": "ok",
     "timestamp": 1589188437530,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "o0eO2-cB9BhH",
    "outputId": "9ec40736-6c29-4213-e4e6-899c1fc26dea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width_mult： 0.6634204312890623\n",
      "size: 558717 \n",
      "acc: 0.7728862973760933\n",
      "width_mult： 0.6634204312890623\n",
      "size: 285032 \n",
      "acc: 0.7723032069970845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_state_dict('stu_model_250000_p095_0.6634204312890623.bin')\n",
    "eval_state_dict('stu_model_250000_p095_0.6634204312890623_f16.bin')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hvK7JUud6mrh"
   },
   "outputs": [],
   "source": [
    "def eval_state_dict(name, base = 16, path = './'):\n",
    "    # width_mult = float(re.findall('0\\.\\d+', name)[0])\n",
    "    width_mult = float(name.split('_')[-1][:-4])\n",
    "    print('width_mult： {}'.format(width_mult))\n",
    "    net = StudentNet(base=base, width_mult=width_mult).to(device)\n",
    "    params = torch.load(os.path.join(path, name))\n",
    "    size = os.stat(os.path.join(path, name)).st_size\n",
    "    print(\"size: {} \".format(size))\n",
    "    net.load_state_dict(params)\n",
    "    # get dataloader\n",
    "    valid_dataloader = get_dataloader(val_set, 'eval', batch_size=64)\n",
    "    net.eval()\n",
    "    hits,num = 0,0\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in valid_dataloader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device, dtype = torch.long)\n",
    "            pred_batch = net(x_batch)\n",
    "            hits += torch.sum((pred_batch.max(1)[1] == y_batch)).item()\n",
    "            num += len(y_batch)\n",
    "    acc = hits/num\n",
    "    print('acc: {}'.format(acc))\n",
    "    return acc, size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "la8IiaiFERlL"
   },
   "source": [
    "## 1.5 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e9uMeQ3zE_Nf"
   },
   "outputs": [],
   "source": [
    "def test_model(net):\n",
    "    labels = []\n",
    "    net.eval()\n",
    "    hits,num = 0,0\n",
    "    data_loader = get_dataloader(test_set, 'eval', batch_size=64)\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for x_batch,_ in data_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            pred_batch = net(x_batch)\n",
    "            labels_batch = pred_batch.max(1)[1]\n",
    "            labels += list(labels_batch.cpu().numpy())\n",
    "    return np.array(labels)\n",
    "\n",
    "def save_csv(labels):\n",
    "    with open(\"./predict.csv\", 'w') as f:\n",
    "        f.write('id,label\\n')\n",
    "        for i, y in  enumerate(labels):\n",
    "            f.write('{},{}\\n'.format(i, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jh_SrujzlXQf"
   },
   "outputs": [],
   "source": [
    "def test_model_by_resnet(name):\n",
    "    f16_name = f'f16_{name}'\n",
    "    width_mult = float(name.split('_')[-1][:-4])\n",
    "    params = torch.load(f'./{name}')\n",
    "    params = to_float16(params)\n",
    "    torch.save(params, f'./{f16_name}')\n",
    "    resnet = models.resnet18(pretrained=False, num_classes=11).to(device)\n",
    "    resnet.load_state_dict(torch.load(f'./teacher_resnet18.bin'))\n",
    "    y_resnet = test_model(resnet)\n",
    "    params = torch.load(f'./{name}')\n",
    "    student_net = StudentNet(base=16, width_mult = width_mult).to(device)\n",
    "    student_net.load_state_dict(params)\n",
    "    y_stu = test_model(student_net)\n",
    "    params_f16 = torch.load(f'./{f16_name}')\n",
    "    student_net_f16 = StudentNet(base=16, width_mult = width_mult).to(device)\n",
    "    student_net_f16.load_state_dict(params_f16)\n",
    "    y_stu_f16 = test_model(student_net_f16)\n",
    "\n",
    "    print('resnet_score : {}'.format(0.88822))\n",
    "    stu_rate = np.sum(y_stu==y_resnet)/len(y_stu)\n",
    "    stu_f16_rate = np.sum(y_stu_f16==y_resnet)/len(y_stu)\n",
    "    print(f'stu rate: {stu_rate},  score: {stu_rate * 0.88822}')\n",
    "    print(f'stu_f16 rate: {stu_f16_rate},  score:{stu_f16_rate * 0.88822}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24108,
     "status": "ok",
     "timestamp": 1589199250874,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "cHI2sw-imBX8",
    "outputId": "6983ba1d-c6b1-4936-e2ee-825ec7841d04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet_score : 0.88822\n",
      "stu rate: 0.8380639378547954,  acc: 0.7443851508813863, score: 0.8380639378547954\n",
      "stu_f16 rate: 0.8377651628323872,  acc:0.744119772930983\n"
     ]
    }
   ],
   "source": [
    "# 助教提供的1m模型的baseline\n",
    "test_model_by_resnet('stu_model_250000_p090_1.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23745,
     "status": "ok",
     "timestamp": 1589206231856,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "plyeH8xWESHI",
    "outputId": "18dc5f28-6914-4b90-cae3-6eb7e01f3da9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet_score : 0.88822\n",
      "stu rate: 0.8004182850313714,  score: 0.7109475291305647\n",
      "stu_f16 rate: 0.799521959964147,  score:0.7101513952793547\n"
     ]
    }
   ],
   "source": [
    "test_model_by_resnet('stu_model_250000_p095_0.6634204312890623.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23694,
     "status": "ok",
     "timestamp": 1589206255563,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "Ize0BIQDEaZE",
    "outputId": "6c8917de-fe47-478f-be44-0873ec6bdf34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet_score : 0.88822\n",
      "stu rate: 0.8135643860173289,  score: 0.7226241589483119\n",
      "stu_f16 rate: 0.8138631610397371,  score:0.7228895368987153\n"
     ]
    }
   ],
   "source": [
    "test_model_by_resnet('stu_model_250000_p090_0.6561000000000001.bin')\n",
    "# score 0.82665"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14342,
     "status": "ok",
     "timestamp": 1589277447246,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "daLF2lh2SxK6",
    "outputId": "2c3339f3-0d65-4a74-edfb-e51363241128"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet_score : 0.88822\n",
      "stu rate: 0.8108754108156558,  score: 0.7202357573946818\n",
      "stu_f16 rate: 0.8111741858380639,  score:0.7205011353450851\n"
     ]
    }
   ],
   "source": [
    "test_model_by_resnet('stu_model_150000_1.bin')\n",
    "# score 0.822"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SzlBRHMVots7"
   },
   "outputs": [],
   "source": [
    "# kaggle\n",
    "f16_name = 'f16_stu_model_150000_1.bin'\n",
    "params_f16 = torch.load(f'./{f16_name}')\n",
    "student_net_f16 = StudentNet(base=12, width_mult = 1).to(device)\n",
    "student_net_f16.load_state_dict(params_f16)\n",
    "y_stu_f16 = test_model(student_net_f16)\n",
    "save_csv(y_stu_f16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7438,
     "status": "ok",
     "timestamp": 1589206415035,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "Iq5bu2tRFR0n",
    "outputId": "2eac7b26-5ce9-470a-d91a-b878018829e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width_mult： 0.6561000000000001\n",
      "size: 280567 \n",
      "acc: 0.79533527696793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.79533527696793, 280567)"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_state_dict('f16_stu_model_250000_p090_0.6561000000000001.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1OwnKs9qtxUJ"
   },
   "source": [
    "# 2. Experimentation\n",
    "\n",
    "1. 請從 Network Pruning/Quantization/Knowledge Distillation/Low Rank Approximation/Design Architecture  選擇兩者實做並詳述你的方法，將同一個大 model 壓縮至接近相同的參數量，並紀錄其 accuracy。 (2%)\n",
    "2. 請嘗試比較以下 accuracy (兩個 Teacher Net 由助教提供)以及 student的總參數量以及架構，並嘗試解釋為甚麼有這樣的結果。你的 Student Net 的參數量必須要小於 Teacher Net 的參數量。 (2%)\n",
    "\n",
    "    x. Teacher net architecture and # of parameters: torchvision’s ResNet18, with 11,182,155 parameters.\n",
    "\n",
    "    y. Student net architecture and # of parameters: \n",
    "\n",
    "    a. Teacher net (ResNet18) from scratch: 80.09%\n",
    "\n",
    "    b. Teacher net (ResNet18) ImageNet pretrained & fine-tune: 88.41%\n",
    "\n",
    "    c. Your student net from scratch:\n",
    "\n",
    "    d. Your student net KD from (a.):\n",
    "\n",
    "    e. Your student net KD from (b.):\n",
    "\n",
    "3. 請使用兩種以上的 pruning rate 畫出 X 軸為參數量，Y軸為 validation accuracy 的折線圖。\n",
    "你的圖上應會有兩條以上的折線。 (2%)\n",
    "4. 請嘗試比較以下 validation accuracy，並且模型大小要接近1MB: (2%)\n",
    "a. 原始 CNN model (用一般的 Convolution Layer) 的 accuracy\n",
    "b. 將 CNN model 的 Convolution Layer 換成總參數量接近的 Depthwise & Pointwise 後的 accuracy\n",
    "c. 將 CNN model 的 Convolution Layer 換成總參數量接近的 Group Convolution Layer (Group 數量自訂，但不要設為 1 或 in_filters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N8dupA1ztxUJ"
   },
   "source": [
    "## 2.1 模型重设计\n",
    "\n",
    "明明结构一模一样，加载助教的params，却有些小问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vjAcam_FtxUL"
   },
   "outputs": [],
   "source": [
    "# class StudentNet(nn.Module):\n",
    "#     def __init__(self, base=16, width_mult = 1):\n",
    "#         super(StudentNet, self).__init__()\n",
    "#         multiplier = [1, 2, 4, 8, 16, 16, 16, 16]\n",
    "\n",
    "#         # bandwidth: 每一層Layer所使用的ch數量\n",
    "#         bandwidth = [ base * m for m in multiplier]\n",
    "\n",
    "#         # 我們只Pruning第三層以後的Layer\n",
    "#         for i in range(3, 7):\n",
    "#             bandwidth[i] = int(bandwidth[i] * width_mult)\n",
    "        \n",
    "#         layers = self.init_cnn_layers(bandwidth)\n",
    "#         self.cnn = nn.Sequential(*layers)\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(bandwidth[-1], 11)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = self.cnn(x)\n",
    "#         out = out.view(out.size()[0], -1)\n",
    "#         return self.fc(out)\n",
    "\n",
    "#     def init_cnn_layers(self, bandwidth):\n",
    "#         def cnn_block(in_c, out_c, downsampling = True):\n",
    "#             if downsampling:\n",
    "#                 return nn.Sequential(\n",
    "#                     nn.Conv2d(in_c, in_c, 3, 1, 1, groups=in_c),\n",
    "#                     nn.BatchNorm2d(in_c),\n",
    "#                     nn.ReLU6(),\n",
    "#                     nn.Conv2d(in_c, out_c, 1),\n",
    "#                     nn.MaxPool2d(2, 2, 0),\n",
    "#                 )\n",
    "#             return nn.Sequential(\n",
    "#                     nn.Conv2d(in_c, in_c, 3, 1, 1, groups=in_c),\n",
    "#                     nn.BatchNorm2d(in_c),\n",
    "#                     nn.ReLU6(),\n",
    "#                     nn.Conv2d(in_c, out_c, 1),\n",
    "#                 )\n",
    "\n",
    "#         layers = []\n",
    "#         layers.append(\n",
    "#                 nn.Sequential(\n",
    "#                     nn.Conv2d(3, bandwidth[0], 3, 1, 1),\n",
    "#                     nn.BatchNorm2d(bandwidth[0]),\n",
    "#                     nn.ReLU6(),\n",
    "#                     nn.MaxPool2d(2, 2, 0))\n",
    "#         )\n",
    "#         downsampling = True\n",
    "#         for i in range(len(bandwidth)-1):\n",
    "#             if i == 2:\n",
    "#                 downsampling = False\n",
    "#             layers.append(cnn_block(bandwidth[i], bandwidth[i+1], downsampling = downsampling))\n",
    "\n",
    "#         # notes: 這邊我們採用Global Average Pooling。\n",
    "#         # 如果輸入圖片大小不一樣的話，就會因為Global Average Pooling壓成一樣的形狀，這樣子接下來做FC就不會對不起來。         \n",
    "#         layers.append(nn.AdaptiveAvgPool2d((1,1)))\n",
    "#         return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 773
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 968,
     "status": "ok",
     "timestamp": 1589206495382,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "Sz_Hq2kItxUO",
    "outputId": "8555f60d-7e3f-469b-f941-2189de5ce2ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "           Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "==============================================================================\n",
      "               Conv2d-1     [1, 12, 128, 128]             336             336\n",
      "          BatchNorm2d-2     [1, 12, 128, 128]              24              24\n",
      "                ReLU6-3     [1, 12, 128, 128]               0               0\n",
      "            MaxPool2d-4       [1, 12, 64, 64]               0               0\n",
      "               Conv2d-5       [1, 12, 64, 64]             120             120\n",
      "          BatchNorm2d-6       [1, 12, 64, 64]              24              24\n",
      "                ReLU6-7       [1, 12, 64, 64]               0               0\n",
      "               Conv2d-8       [1, 24, 64, 64]             312             312\n",
      "            MaxPool2d-9       [1, 24, 32, 32]               0               0\n",
      "              Conv2d-10       [1, 24, 32, 32]             240             240\n",
      "         BatchNorm2d-11       [1, 24, 32, 32]              48              48\n",
      "               ReLU6-12       [1, 24, 32, 32]               0               0\n",
      "              Conv2d-13       [1, 48, 32, 32]           1,200           1,200\n",
      "           MaxPool2d-14       [1, 48, 16, 16]               0               0\n",
      "              Conv2d-15       [1, 48, 16, 16]             480             480\n",
      "         BatchNorm2d-16       [1, 48, 16, 16]              96              96\n",
      "               ReLU6-17       [1, 48, 16, 16]               0               0\n",
      "              Conv2d-18       [1, 96, 16, 16]           4,704           4,704\n",
      "           MaxPool2d-19         [1, 96, 8, 8]               0               0\n",
      "              Conv2d-20         [1, 96, 8, 8]             960             960\n",
      "         BatchNorm2d-21         [1, 96, 8, 8]             192             192\n",
      "               ReLU6-22         [1, 96, 8, 8]               0               0\n",
      "              Conv2d-23        [1, 192, 8, 8]          18,624          18,624\n",
      "              Conv2d-24        [1, 192, 8, 8]           1,920           1,920\n",
      "         BatchNorm2d-25        [1, 192, 8, 8]             384             384\n",
      "               ReLU6-26        [1, 192, 8, 8]               0               0\n",
      "              Conv2d-27        [1, 192, 8, 8]          37,056          37,056\n",
      "              Conv2d-28        [1, 192, 8, 8]           1,920           1,920\n",
      "         BatchNorm2d-29        [1, 192, 8, 8]             384             384\n",
      "               ReLU6-30        [1, 192, 8, 8]               0               0\n",
      "              Conv2d-31        [1, 192, 8, 8]          37,056          37,056\n",
      "              Conv2d-32        [1, 192, 8, 8]           1,920           1,920\n",
      "         BatchNorm2d-33        [1, 192, 8, 8]             384             384\n",
      "               ReLU6-34        [1, 192, 8, 8]               0               0\n",
      "              Conv2d-35        [1, 192, 8, 8]          37,056          37,056\n",
      "   AdaptiveAvgPool2d-36        [1, 192, 1, 1]               0               0\n",
      "              Linear-37               [1, 11]           2,123           2,123\n",
      "==============================================================================\n",
      "Total params: 147,563\n",
      "Trainable params: 147,563\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = StudentNet(base=12).to(device)\n",
    "print(summary(model, torch.zeros(1,3,128,128).to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 773
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1273,
     "status": "ok",
     "timestamp": 1589206527029,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "llOEit-4e2fv",
    "outputId": "0730f31f-b2db-4519-cc06-e8961a6dc61f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "           Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "==============================================================================\n",
      "               Conv2d-1     [1, 12, 128, 128]             336             336\n",
      "          BatchNorm2d-2     [1, 12, 128, 128]              24              24\n",
      "                ReLU6-3     [1, 12, 128, 128]               0               0\n",
      "            MaxPool2d-4       [1, 12, 64, 64]               0               0\n",
      "               Conv2d-5       [1, 12, 64, 64]             120             120\n",
      "          BatchNorm2d-6       [1, 12, 64, 64]              24              24\n",
      "                ReLU6-7       [1, 12, 64, 64]               0               0\n",
      "               Conv2d-8       [1, 24, 64, 64]             312             312\n",
      "            MaxPool2d-9       [1, 24, 32, 32]               0               0\n",
      "              Conv2d-10       [1, 24, 32, 32]             240             240\n",
      "         BatchNorm2d-11       [1, 24, 32, 32]              48              48\n",
      "               ReLU6-12       [1, 24, 32, 32]               0               0\n",
      "              Conv2d-13       [1, 48, 32, 32]           1,200           1,200\n",
      "           MaxPool2d-14       [1, 48, 16, 16]               0               0\n",
      "              Conv2d-15       [1, 48, 16, 16]             480             480\n",
      "         BatchNorm2d-16       [1, 48, 16, 16]              96              96\n",
      "               ReLU6-17       [1, 48, 16, 16]               0               0\n",
      "              Conv2d-18       [1, 96, 16, 16]           4,704           4,704\n",
      "           MaxPool2d-19         [1, 96, 8, 8]               0               0\n",
      "              Conv2d-20         [1, 96, 8, 8]             960             960\n",
      "         BatchNorm2d-21         [1, 96, 8, 8]             192             192\n",
      "               ReLU6-22         [1, 96, 8, 8]               0               0\n",
      "              Conv2d-23        [1, 192, 8, 8]          18,624          18,624\n",
      "              Conv2d-24        [1, 192, 8, 8]           1,920           1,920\n",
      "         BatchNorm2d-25        [1, 192, 8, 8]             384             384\n",
      "               ReLU6-26        [1, 192, 8, 8]               0               0\n",
      "              Conv2d-27        [1, 192, 8, 8]          37,056          37,056\n",
      "              Conv2d-28        [1, 192, 8, 8]           1,920           1,920\n",
      "         BatchNorm2d-29        [1, 192, 8, 8]             384             384\n",
      "               ReLU6-30        [1, 192, 8, 8]               0               0\n",
      "              Conv2d-31        [1, 192, 8, 8]          37,056          37,056\n",
      "              Conv2d-32        [1, 192, 8, 8]           1,920           1,920\n",
      "         BatchNorm2d-33        [1, 192, 8, 8]             384             384\n",
      "               ReLU6-34        [1, 192, 8, 8]               0               0\n",
      "              Conv2d-35        [1, 192, 8, 8]          37,056          37,056\n",
      "   AdaptiveAvgPool2d-36        [1, 192, 1, 1]               0               0\n",
      "              Linear-37               [1, 11]           2,123           2,123\n",
      "==============================================================================\n",
      "Total params: 147,563\n",
      "Trainable params: 147,563\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = StudentNet(base=12).to(device)\n",
    "print(summary(model, torch.zeros(1,3,128,128).to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7132,
     "status": "error",
     "timestamp": 1589206520654,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "2WnUHYREtxUR",
    "outputId": "529ffa82-1848-44da-bb2f-58c718f1015a"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-3180b881c349>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mstudent_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mstudent_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-b3539671147c>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(data_loader, mode, alpha)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0mpred_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudent_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoft_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mtotal_hit\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mtotal_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# get dataloader\n",
    "train_dataloader = get_dataloader(train_set, batch_size=64)\n",
    "valid_dataloader = get_dataloader(val_set, batch_size=64)\n",
    "# net init\n",
    "teacher_net = models.resnet18(pretrained=False, num_classes=11).to(device)\n",
    "student_net = StudentNet(base=12).to(device)\n",
    "teacher_net.load_state_dict(torch.load(f'./teacher_resnet18.bin'))\n",
    "# training student_net\n",
    "alpha = 0.5\n",
    "epochs = 300\n",
    "model_name = 'smodel_base12'\n",
    "teacher_net.eval()\n",
    "now_best_acc = 0\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    student_net.train()\n",
    "    train_loss, train_acc = run_epoch(train_dataloader, mode = 'train', alpha = alpha)\n",
    "    student_net.eval()\n",
    "    val_loss, val_acc = run_epoch(valid_dataloader, mode='eval', alpha = alpha)\n",
    "    end_time = time.time()\n",
    "    if val_acc > now_best_acc:\n",
    "        now_best_acc = val_acc\n",
    "        torch.save(student_net.state_dict(), f'{model_name}.bin')\n",
    "        print('Saving with acc {}'.format(now_best_acc))\n",
    "    print('{:4.2f}s, epoch{:>3d}: train loss: {:6.4f}, acc {:6.4f} valid loss: {:6.4f}, acc {:6.4f}'.format(end_time - start_time, epoch, train_loss, train_acc, val_loss, val_acc))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fAvljmr8t7GV"
   },
   "source": [
    "## 2.2 两个方案的对比\n",
    "\n",
    "1. 参数量250000的student net，knowledge distillation需要pruning到0.57M，最后quantization到0.29m以下，最终acc为79%，score为82.6%\n",
    "2.  参数量150000的student net，knowledge distillation，然后直接quantization到0.3m，最终acc为78%，score为82.2%\n",
    "\n",
    "事实证明，小网络比较难train，原来我以为绕过pruning这一关，因为它稍微pruning之后，acc就降了2，3个百分点。但实际上没有用，小网络很难trian到超过80%。我train到78.6%放弃了，也是colab比较麻烦，最近被拉黑太多次。\n",
    "\n",
    "我认为可能的改进方法：\n",
    "\n",
    "250000以上的参数，train好一点，至少超过81.3%acc，然后pruning，降到0.57m以下，再用微调的方式，调到超过acc 79%\n",
    "\n",
    "但是突破strong basline还是不行……助教81.3%的model压到0.5m之后score才83.3，也就是，我首先得train出一个84，85的model才行，这个pruning之后能保存一些。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QhtqJDRT38dT"
   },
   "outputs": [],
   "source": [
    "drive_path = '/content/drive/My Drive/hw7'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z8XwDbXG2-Vx"
   },
   "source": [
    "150000参数的student net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y4cZgcjB2MNh"
   },
   "outputs": [],
   "source": [
    "model_name = 'stu_model_150000'\n",
    "drive_path = '/content/drive/My Drive/hw7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gJZjKNwg2McV"
   },
   "outputs": [],
   "source": [
    "# get dataloader\n",
    "train_dataloader = get_dataloader(train_set, batch_size=64)\n",
    "valid_dataloader = get_dataloader(val_set, batch_size=64)\n",
    "# net init\n",
    "teacher_net = models.resnet18(pretrained=False, num_classes=11).to(device)\n",
    "student_net = StudentNet(base=12).to(device)\n",
    "teacher_net.load_state_dict(torch.load(f'./teacher_resnet18_nopre.bin'))\n",
    "# training student_net\n",
    "alpha = 0.5\n",
    "epochs = 300\n",
    "# break-point training\n",
    "epochs = 50\n",
    "student_net.load_state_dict(torch.load(os.path.join(f'/content/drive/My Drive/hw7', model_name+'.bin')))\n",
    "now_best_acc = 0.775801749271137\n",
    "lr =  1e-4\n",
    "# epoch 100\n",
    "# epoch 100 lr = 0.001 0.775801749271137\n",
    "# epoch 50 lr = 0.0003 0.7848396501457726"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 819
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 357234,
     "status": "error",
     "timestamp": 1589276949968,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "1bNqhzs6OMca",
    "outputId": "19687a30-977d-48c6-a0d9-57329fcdd60f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving with acc 0.7833819241982507\n",
      "35.25s, epoch  0: train loss: 1.4999, acc 0.8922 valid loss: 1.9421, acc 0.7834\n",
      "35.25s, epoch  1: train loss: 1.4963, acc 0.8925 valid loss: 1.9540, acc 0.7805\n",
      "35.24s, epoch  2: train loss: 1.5119, acc 0.8900 valid loss: 1.9875, acc 0.7776\n",
      "35.15s, epoch  3: train loss: 1.4880, acc 0.8826 valid loss: 1.9407, acc 0.7810\n",
      "Saving with acc 0.7860058309037901\n",
      "35.15s, epoch  4: train loss: 1.4912, acc 0.8875 valid loss: 1.9557, acc 0.7860\n",
      "35.12s, epoch  5: train loss: 1.5191, acc 0.8851 valid loss: 1.9335, acc 0.7831\n",
      "35.00s, epoch  6: train loss: 1.5024, acc 0.8872 valid loss: 1.9401, acc 0.7828\n",
      "35.08s, epoch  7: train loss: 1.4919, acc 0.8815 valid loss: 1.9590, acc 0.7784\n",
      "35.07s, epoch  8: train loss: 1.5188, acc 0.8875 valid loss: 1.9428, acc 0.7822\n",
      "Saving with acc 0.7862973760932944\n",
      "35.09s, epoch  9: train loss: 1.5041, acc 0.8865 valid loss: 1.9476, acc 0.7863\n",
      "35.08s, epoch 10: train loss: 1.5081, acc 0.8854 valid loss: 1.9410, acc 0.7854\n",
      "35.10s, epoch 11: train loss: 1.4888, acc 0.8871 valid loss: 1.9388, acc 0.7848\n",
      "35.07s, epoch 12: train loss: 1.4952, acc 0.8878 valid loss: 1.9620, acc 0.7802\n",
      "35.05s, epoch 13: train loss: 1.4960, acc 0.8878 valid loss: 1.9455, acc 0.7851\n",
      "35.07s, epoch 14: train loss: 1.4962, acc 0.8879 valid loss: 1.9293, acc 0.7822\n",
      "35.06s, epoch 15: train loss: 1.4959, acc 0.8889 valid loss: 1.9555, acc 0.7793\n",
      "35.04s, epoch 16: train loss: 1.5008, acc 0.8913 valid loss: 1.9735, acc 0.7860\n",
      "35.02s, epoch 17: train loss: 1.4813, acc 0.8845 valid loss: 1.9698, acc 0.7813\n",
      "35.03s, epoch 18: train loss: 1.4814, acc 0.8928 valid loss: 1.9813, acc 0.7790\n",
      "35.02s, epoch 19: train loss: 1.4799, acc 0.8873 valid loss: 1.9634, acc 0.7799\n",
      "34.95s, epoch 20: train loss: 1.4995, acc 0.8841 valid loss: 1.9676, acc 0.7840\n",
      "35.08s, epoch 21: train loss: 1.4840, acc 0.8934 valid loss: 1.9308, acc 0.7848\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-3d166f6b0748>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstudent_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mstudent_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-710acdb47760>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(data_loader, mode, alpha, learning_rate)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0mpred_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudent_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoft_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mtotal_hit\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mtotal_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "teacher_net.eval()\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    student_net.train()\n",
    "    train_loss, train_acc = run_epoch(train_dataloader, mode = 'train', alpha = alpha,learning_rate = lr)\n",
    "    student_net.eval()\n",
    "    val_loss, val_acc = run_epoch(valid_dataloader, mode='eval', alpha = alpha)\n",
    "    end_time = time.time()\n",
    "    if val_acc > now_best_acc:\n",
    "        now_best_acc = val_acc\n",
    "        torch.save(student_net.state_dict(), os.path.join(drive_path, f'{model_name}.bin'))\n",
    "        print('Saving with acc {}'.format(now_best_acc))\n",
    "    print('{:4.2f}s, epoch{:>3d}: train loss: {:6.4f}, acc {:6.4f} valid loss: {:6.4f}, acc {:6.4f}'.format(end_time - start_time, epoch, train_loss, train_acc, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 953
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 195392,
     "status": "ok",
     "timestamp": 1589275882173,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "QgTbnKyG-HqE",
    "outputId": "5afbef8d-4922-48d6-e612-09e3299cd33e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving with acc 0.7845481049562683\n",
      "35.15s, epoch  0: train loss: 1.6849, acc 0.8654 valid loss: 2.0271, acc 0.7845\n",
      "35.18s, epoch  1: train loss: 1.6725, acc 0.8630 valid loss: 2.0176, acc 0.7825\n",
      "35.14s, epoch  2: train loss: 1.6696, acc 0.8697 valid loss: 2.0650, acc 0.7790\n",
      "35.23s, epoch  3: train loss: 1.6457, acc 0.8715 valid loss: 2.0427, acc 0.7743\n",
      "35.22s, epoch  4: train loss: 1.6447, acc 0.8695 valid loss: 2.0700, acc 0.7790\n",
      "35.18s, epoch  5: train loss: 1.6226, acc 0.8747 valid loss: 2.0512, acc 0.7810\n",
      "35.19s, epoch  6: train loss: 1.6388, acc 0.8729 valid loss: 2.0607, acc 0.7755\n",
      "35.19s, epoch  7: train loss: 1.6210, acc 0.8761 valid loss: 2.0959, acc 0.7708\n",
      "35.13s, epoch  8: train loss: 1.6178, acc 0.8739 valid loss: 2.0376, acc 0.7793\n",
      "35.19s, epoch  9: train loss: 1.6008, acc 0.8732 valid loss: 2.0866, acc 0.7799\n",
      "35.13s, epoch 10: train loss: 1.6006, acc 0.8778 valid loss: 2.0569, acc 0.7790\n",
      "35.07s, epoch 11: train loss: 1.6250, acc 0.8805 valid loss: 2.0611, acc 0.7764\n",
      "35.09s, epoch 12: train loss: 1.5995, acc 0.8773 valid loss: 2.0318, acc 0.7793\n",
      "35.08s, epoch 13: train loss: 1.5871, acc 0.8771 valid loss: 2.0511, acc 0.7776\n",
      "35.22s, epoch 14: train loss: 1.5971, acc 0.8752 valid loss: 2.0413, acc 0.7729\n",
      "35.17s, epoch 15: train loss: 1.6112, acc 0.8748 valid loss: 2.0689, acc 0.7781\n",
      "35.09s, epoch 16: train loss: 1.6268, acc 0.8759 valid loss: 2.0332, acc 0.7813\n",
      "35.01s, epoch 17: train loss: 1.6026, acc 0.8785 valid loss: 2.0508, acc 0.7741\n",
      "35.04s, epoch 18: train loss: 1.5930, acc 0.8788 valid loss: 2.0132, acc 0.7770\n",
      "35.04s, epoch 19: train loss: 1.5961, acc 0.8811 valid loss: 2.0471, acc 0.7813\n",
      "35.06s, epoch 20: train loss: 1.6180, acc 0.8765 valid loss: 2.1177, acc 0.7758\n",
      "35.10s, epoch 21: train loss: 1.6237, acc 0.8734 valid loss: 2.0326, acc 0.7845\n",
      "35.12s, epoch 22: train loss: 1.5896, acc 0.8793 valid loss: 2.0111, acc 0.7802\n",
      "35.14s, epoch 23: train loss: 1.5884, acc 0.8782 valid loss: 2.0467, acc 0.7813\n",
      "35.04s, epoch 24: train loss: 1.5647, acc 0.8764 valid loss: 2.0187, acc 0.7805\n",
      "35.00s, epoch 25: train loss: 1.5674, acc 0.8818 valid loss: 2.0212, acc 0.7793\n",
      "35.04s, epoch 26: train loss: 1.5976, acc 0.8742 valid loss: 2.0607, acc 0.7770\n",
      "35.01s, epoch 27: train loss: 1.5718, acc 0.8813 valid loss: 2.0572, acc 0.7758\n",
      "35.03s, epoch 28: train loss: 1.5860, acc 0.8749 valid loss: 2.0970, acc 0.7685\n",
      "34.97s, epoch 29: train loss: 1.5846, acc 0.8762 valid loss: 2.0224, acc 0.7776\n",
      "35.03s, epoch 30: train loss: 1.5928, acc 0.8756 valid loss: 2.0615, acc 0.7778\n",
      "35.11s, epoch 31: train loss: 1.5814, acc 0.8788 valid loss: 2.0488, acc 0.7790\n",
      "35.04s, epoch 32: train loss: 1.5890, acc 0.8779 valid loss: 2.0983, acc 0.7787\n",
      "35.02s, epoch 33: train loss: 1.5898, acc 0.8816 valid loss: 2.0280, acc 0.7764\n",
      "35.07s, epoch 34: train loss: 1.5870, acc 0.8746 valid loss: 2.1031, acc 0.7784\n",
      "34.97s, epoch 35: train loss: 1.5726, acc 0.8817 valid loss: 2.0482, acc 0.7825\n",
      "35.11s, epoch 36: train loss: 1.5720, acc 0.8823 valid loss: 2.0330, acc 0.7796\n",
      "34.94s, epoch 37: train loss: 1.5760, acc 0.8811 valid loss: 2.0568, acc 0.7784\n",
      "34.89s, epoch 38: train loss: 1.5668, acc 0.8782 valid loss: 2.1583, acc 0.7694\n",
      "Saving with acc 0.7848396501457726\n",
      "35.03s, epoch 39: train loss: 1.5530, acc 0.8838 valid loss: 2.0324, acc 0.7848\n",
      "34.95s, epoch 40: train loss: 1.5602, acc 0.8829 valid loss: 2.0886, acc 0.7761\n",
      "34.96s, epoch 41: train loss: 1.5708, acc 0.8800 valid loss: 2.0547, acc 0.7834\n",
      "35.02s, epoch 42: train loss: 1.5688, acc 0.8792 valid loss: 2.0341, acc 0.7793\n",
      "35.00s, epoch 43: train loss: 1.5645, acc 0.8779 valid loss: 2.0094, acc 0.7776\n",
      "35.02s, epoch 44: train loss: 1.5483, acc 0.8845 valid loss: 2.0714, acc 0.7810\n",
      "35.05s, epoch 45: train loss: 1.5636, acc 0.8820 valid loss: 1.9839, acc 0.7828\n",
      "35.06s, epoch 46: train loss: 1.5525, acc 0.8823 valid loss: 2.0760, acc 0.7755\n",
      "35.11s, epoch 47: train loss: 1.5754, acc 0.8778 valid loss: 2.0691, acc 0.7738\n",
      "35.09s, epoch 48: train loss: 1.5545, acc 0.8824 valid loss: 2.0310, acc 0.7773\n",
      "35.12s, epoch 49: train loss: 1.5482, acc 0.8827 valid loss: 2.0556, acc 0.7749\n"
     ]
    }
   ],
   "source": [
    "teacher_net.eval()\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    student_net.train()\n",
    "    train_loss, train_acc = run_epoch(train_dataloader, mode = 'train', alpha = alpha,learning_rate = lr)\n",
    "    student_net.eval()\n",
    "    val_loss, val_acc = run_epoch(valid_dataloader, mode='eval', alpha = alpha)\n",
    "    end_time = time.time()\n",
    "    if val_acc > now_best_acc:\n",
    "        now_best_acc = val_acc\n",
    "        torch.save(student_net.state_dict(), os.path.join(drive_path, f'{model_name}.bin'))\n",
    "        print('Saving with acc {}'.format(now_best_acc))\n",
    "    print('{:4.2f}s, epoch{:>3d}: train loss: {:6.4f}, acc {:6.4f} valid loss: {:6.4f}, acc {:6.4f}'.format(end_time - start_time, epoch, train_loss, train_acc, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JXUQ_eOHEQfh"
   },
   "outputs": [],
   "source": [
    "params = student_net.state_dict()\n",
    "params = to_float16(params)\n",
    "torch.save(params, os.path.join(drive_path, f'{model_name}.bin'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ls63j1AfyjH2"
   },
   "source": [
    "## 2.3 使用两种不同的Teacher net，对比student net的结果\n",
    "\n",
    "1. resnet18 with pretrained, 上面的实验已经完成\n",
    "2. resnet18 without pretained\n",
    "\n",
    "结果如下\n",
    "\n",
    "- x. Teacher net architecture and # of parameters: torchvision’s ResNet18, with 11,182,155 parameters.\n",
    "-y. Student net architecture and # of parameters: \n",
    "\n",
    "- a. Teacher net (ResNet18) from scratch: 80.09%\n",
    "\n",
    "- b. Teacher net (ResNet18) ImageNet pretrained & fine-tune: 88.41%\n",
    "\n",
    "- c. Your student net from scratch:\n",
    "\n",
    "- d. Your student net KD from (a.): 准确率81.3%，我觉得可以更高。\n",
    "\n",
    "- e. Your student net KD from (b.): 跑了100个epoch，准确率只有76.5%，我印象中使用pretrained resnet，一百个epoch可以达到79%，但具体再跑下去怎么样，我这边实验只做到这里。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QWMreAki2VVA"
   },
   "source": [
    "bad teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vDp7OE2s08QS"
   },
   "outputs": [],
   "source": [
    "model_name = 'stu_model_nopre_1'\n",
    "drive_path = '/content/drive/My Drive/hw7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1353,
     "status": "ok",
     "timestamp": 1589281698554,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "EXkTrHpI0DxN",
    "outputId": "f0beaf49-1fe9-4e52-d7fd-8312207d83fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get dataloader\n",
    "train_dataloader = get_dataloader(train_set, batch_size=64)\n",
    "valid_dataloader = get_dataloader(val_set, batch_size=64)\n",
    "# net init\n",
    "teacher_net = models.resnet18(pretrained=False, num_classes=11).to(device)\n",
    "student_net = StudentNet(base=16).to(device)\n",
    "teacher_net.load_state_dict(torch.load(f'./teacher_resnet18_nopre.bin'))\n",
    "# training student_net\n",
    "alpha = 0.5\n",
    "epochs = 50\n",
    "lr = 3*1e-4\n",
    "now_best_acc = 0.6726\n",
    "student_net.load_state_dict(torch.load(os.path.join(f'/content/drive/My Drive/hw7', model_name+'.bin')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3994129,
     "status": "ok",
     "timestamp": 1589285697123,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "T7HDwC2m0J4z",
    "outputId": "9ff5fa6b-653a-4ae5-c13e-14b6b84bd510"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving with acc: 0.7335276967930029\n",
      "79.85s, epoch  0: train loss: 3.5267, acc 0.7048 valid loss: 3.0911, acc 0.7335\n",
      "Saving with acc: 0.736734693877551\n",
      "79.91s, epoch  1: train loss: 3.3208, acc 0.7217 valid loss: 3.0225, acc 0.7367\n",
      "79.96s, epoch  2: train loss: 3.2701, acc 0.7167 valid loss: 3.0388, acc 0.7364\n",
      "79.86s, epoch  3: train loss: 3.2782, acc 0.7223 valid loss: 3.0240, acc 0.7335\n",
      "Saving with acc: 0.7440233236151603\n",
      "79.84s, epoch  4: train loss: 3.2003, acc 0.7295 valid loss: 2.9841, acc 0.7440\n",
      "Saving with acc: 0.7457725947521866\n",
      "79.77s, epoch  5: train loss: 3.1869, acc 0.7286 valid loss: 2.9432, acc 0.7458\n",
      "79.97s, epoch  6: train loss: 3.1716, acc 0.7259 valid loss: 2.9354, acc 0.7388\n",
      "79.75s, epoch  7: train loss: 3.1253, acc 0.7327 valid loss: 2.9254, acc 0.7431\n",
      "80.00s, epoch  8: train loss: 3.1328, acc 0.7334 valid loss: 2.9407, acc 0.7449\n",
      "80.09s, epoch  9: train loss: 3.0802, acc 0.7362 valid loss: 2.8661, acc 0.7408\n",
      "80.09s, epoch 10: train loss: 3.0883, acc 0.7392 valid loss: 2.8545, acc 0.7440\n",
      "80.02s, epoch 11: train loss: 3.0392, acc 0.7352 valid loss: 2.8419, acc 0.7429\n",
      "Saving with acc: 0.7489795918367347\n",
      "80.00s, epoch 12: train loss: 3.0383, acc 0.7316 valid loss: 2.8631, acc 0.7490\n",
      "80.03s, epoch 13: train loss: 3.0301, acc 0.7346 valid loss: 2.8425, acc 0.7420\n",
      "Saving with acc: 0.7527696793002916\n",
      "80.01s, epoch 14: train loss: 3.0382, acc 0.7424 valid loss: 2.8456, acc 0.7528\n",
      "80.11s, epoch 15: train loss: 3.0248, acc 0.7371 valid loss: 2.8317, acc 0.7504\n",
      "80.08s, epoch 16: train loss: 3.0047, acc 0.7419 valid loss: 2.8089, acc 0.7455\n",
      "Saving with acc: 0.7533527696793003\n",
      "80.05s, epoch 17: train loss: 2.9750, acc 0.7442 valid loss: 2.8023, acc 0.7534\n",
      "80.03s, epoch 18: train loss: 2.9791, acc 0.7452 valid loss: 2.7909, acc 0.7484\n",
      "80.00s, epoch 19: train loss: 2.9917, acc 0.7410 valid loss: 2.8039, acc 0.7475\n",
      "Saving with acc: 0.7565597667638484\n",
      "79.98s, epoch 20: train loss: 2.9422, acc 0.7471 valid loss: 2.7827, acc 0.7566\n",
      "79.81s, epoch 21: train loss: 2.9538, acc 0.7443 valid loss: 2.7775, acc 0.7499\n",
      "80.00s, epoch 22: train loss: 2.9550, acc 0.7474 valid loss: 2.7637, acc 0.7510\n",
      "80.09s, epoch 23: train loss: 2.9716, acc 0.7469 valid loss: 2.7381, acc 0.7545\n",
      "79.98s, epoch 24: train loss: 2.9264, acc 0.7524 valid loss: 2.7458, acc 0.7539\n",
      "80.07s, epoch 25: train loss: 2.9112, acc 0.7468 valid loss: 2.7320, acc 0.7545\n",
      "80.02s, epoch 26: train loss: 2.8999, acc 0.7463 valid loss: 2.7440, acc 0.7534\n",
      "Saving with acc: 0.7571428571428571\n",
      "80.08s, epoch 27: train loss: 2.8985, acc 0.7485 valid loss: 2.7037, acc 0.7571\n",
      "80.02s, epoch 28: train loss: 2.8705, acc 0.7546 valid loss: 2.7470, acc 0.7510\n",
      "Saving with acc: 0.7620991253644315\n",
      "79.92s, epoch 29: train loss: 2.9038, acc 0.7498 valid loss: 2.7275, acc 0.7621\n",
      "78.71s, epoch 30: train loss: 2.8896, acc 0.7497 valid loss: 2.7098, acc 0.7522\n",
      "78.67s, epoch 31: train loss: 2.8367, acc 0.7527 valid loss: 2.7282, acc 0.7525\n",
      "78.93s, epoch 32: train loss: 2.8548, acc 0.7518 valid loss: 2.7269, acc 0.7603\n",
      "78.92s, epoch 33: train loss: 2.8614, acc 0.7494 valid loss: 2.7243, acc 0.7554\n",
      "79.05s, epoch 34: train loss: 2.8441, acc 0.7579 valid loss: 2.7082, acc 0.7595\n",
      "79.60s, epoch 35: train loss: 2.8710, acc 0.7541 valid loss: 2.7136, acc 0.7574\n",
      "80.19s, epoch 36: train loss: 2.8447, acc 0.7558 valid loss: 2.6582, acc 0.7598\n",
      "79.99s, epoch 37: train loss: 2.8308, acc 0.7570 valid loss: 2.7036, acc 0.7609\n",
      "79.07s, epoch 38: train loss: 2.8020, acc 0.7571 valid loss: 2.6990, acc 0.7577\n",
      "80.04s, epoch 39: train loss: 2.7985, acc 0.7600 valid loss: 2.7137, acc 0.7612\n",
      "80.08s, epoch 40: train loss: 2.8027, acc 0.7557 valid loss: 2.6937, acc 0.7618\n",
      "80.03s, epoch 41: train loss: 2.7648, acc 0.7594 valid loss: 2.6719, acc 0.7528\n",
      "Saving with acc: 0.7650145772594752\n",
      "80.09s, epoch 42: train loss: 2.7881, acc 0.7581 valid loss: 2.6265, acc 0.7650\n",
      "80.03s, epoch 43: train loss: 2.7696, acc 0.7587 valid loss: 2.7105, acc 0.7633\n",
      "80.00s, epoch 44: train loss: 2.7514, acc 0.7626 valid loss: 2.6334, acc 0.7618\n",
      "79.93s, epoch 45: train loss: 2.7496, acc 0.7604 valid loss: 2.6450, acc 0.7633\n",
      "79.94s, epoch 46: train loss: 2.7414, acc 0.7637 valid loss: 2.6688, acc 0.7618\n",
      "Saving with acc: 0.7661807580174927\n",
      "79.93s, epoch 47: train loss: 2.7262, acc 0.7657 valid loss: 2.6676, acc 0.7662\n",
      "79.84s, epoch 48: train loss: 2.7359, acc 0.7637 valid loss: 2.6721, acc 0.7633\n",
      "80.20s, epoch 49: train loss: 2.7375, acc 0.7653 valid loss: 2.6431, acc 0.7656\n"
     ]
    }
   ],
   "source": [
    "teacher_net.eval()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    student_net.train()\n",
    "    train_loss, train_acc = run_epoch(train_dataloader, mode = 'train', alpha = alpha, learning_rate = lr)\n",
    "    student_net.eval()\n",
    "    val_loss, val_acc = run_epoch(valid_dataloader, mode='eval', alpha = alpha)\n",
    "    end_time = time.time()\n",
    "    if val_acc > now_best_acc:\n",
    "        now_best_acc = val_acc\n",
    "        torch.save(student_net.state_dict(), os.path.join(drive_path, f'{model_name}.bin'))\n",
    "        print('Saving with acc: {}'.format(now_best_acc))\n",
    "    print('{:4.2f}s, epoch{:>3d}: train loss: {:6.4f}, acc {:6.4f} valid loss: {:6.4f}, acc {:6.4f}'.format(end_time - start_time, epoch, train_loss, train_acc, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xbvq77QWCa-5"
   },
   "source": [
    "## 2.4 研究pruning rate与准确率的关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3AaR7LCNCh--"
   },
   "outputs": [],
   "source": [
    "def eval_state_dict(name, base = 16, path = './'):\n",
    "    # width_mult = float(re.findall('0\\.\\d+', name)[0])\n",
    "    width_mult = float(name.split('_')[-1][:-4])\n",
    "    print('width_mult： {}'.format(width_mult))\n",
    "    net = StudentNet(base=base, width_mult=width_mult).to(device)\n",
    "    params = torch.load(os.path.join(path, name))\n",
    "    size = os.stat(os.path.join(path, name)).st_size\n",
    "    print(\"size: {} \".format(size))\n",
    "    net.load_state_dict(params)\n",
    "    # get dataloader\n",
    "    valid_dataloader = get_dataloader(val_set, 'eval', batch_size=64)\n",
    "    net.eval()\n",
    "    hits,num = 0,0\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in valid_dataloader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device, dtype = torch.long)\n",
    "            pred_batch = net(x_batch)\n",
    "            hits += torch.sum((pred_batch.max(1)[1] == y_batch)).item()\n",
    "            num += len(y_batch)\n",
    "    acc = hits/num\n",
    "    print('acc: {}'.format(acc))\n",
    "    return acc, size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 137963,
     "status": "ok",
     "timestamp": 1589205976460,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "5DgE1Th4JW7W",
    "outputId": "2a63536a-cde4-4ece-dab0-a543d346f9c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width_mult： 0.5987369392383786\n",
      "size: 485276 \n",
      "acc: 0.7862973760932944\n",
      "width_mult： 0.6302494097246091\n",
      "size: 521284 \n",
      "acc: 0.7857142857142857\n",
      "width_mult： 0.6634204312890623\n",
      "size: 558568 \n",
      "acc: 0.7807580174927113\n",
      "width_mult： 0.6983372960937497\n",
      "size: 602540 \n",
      "acc: 0.7839650145772594\n",
      "width_mult： 0.7350918906249998\n",
      "size: 652816 \n",
      "acc: 0.7895043731778426\n",
      "width_mult： 0.7737809374999999\n",
      "size: 704968 \n",
      "acc: 0.7848396501457726\n",
      "width_mult： 0.8145062499999999\n",
      "size: 759200 \n",
      "acc: 0.7965014577259475\n",
      "width_mult： 0.8573749999999999\n",
      "size: 820580 \n",
      "acc: 0.7915451895043731\n",
      "width_mult： 0.9025\n",
      "size: 890892 \n",
      "acc: 0.793002915451895\n",
      "width_mult： 0.95\n",
      "size: 964044 \n",
      "acc: 0.8032069970845481\n",
      "width_mult： 1.0\n",
      "size: 1047430 \n",
      "acc: 0.8137026239067056\n",
      "width_mult： 0.34867844010000015\n",
      "size: 243332 \n",
      "acc: 0.7603498542274052\n",
      "width_mult： 0.38742048900000015\n",
      "size: 275772 \n",
      "acc: 0.7690962099125365\n",
      "width_mult： 0.43046721000000016\n",
      "size: 314086 \n",
      "acc: 0.773469387755102\n",
      "width_mult： 0.47829690000000014\n",
      "size: 358340 \n",
      "acc: 0.7661807580174927\n",
      "width_mult： 0.5314410000000002\n",
      "size: 413490 \n",
      "acc: 0.7728862973760933\n",
      "width_mult： 0.5904900000000002\n",
      "size: 476476 \n",
      "acc: 0.7728862973760933\n",
      "width_mult： 0.6561000000000001\n",
      "size: 549172 \n",
      "acc: 0.7944606413994169\n",
      "width_mult： 0.7290000000000001\n",
      "size: 642592 \n",
      "acc: 0.7880466472303207\n",
      "width_mult： 0.81\n",
      "size: 753150 \n",
      "acc: 0.7830903790087463\n",
      "width_mult： 0.9\n",
      "size: 885516 \n",
      "acc: 0.793002915451895\n",
      "width_mult： 1.0\n",
      "size: 1047430 \n",
      "acc: 0.8137026239067056\n"
     ]
    }
   ],
   "source": [
    "p095_states = sorted([p for p in  os.listdir('./') if p.startswith('stu_model_250000_p095')])\n",
    "p095_acc,p095_size  = [],[]\n",
    "for name in p095_states:\n",
    "    acc, size = eval_state_dict(name)\n",
    "    p095_acc.append(acc)\n",
    "    p095_size.append(size)\n",
    "p090_states = sorted([p for p in  os.listdir('./') if p.startswith('stu_model_250000_p090')])\n",
    "p090_acc,p090_size  = [],[]\n",
    "for name in p090_states:\n",
    "    acc, size = eval_state_dict(name)\n",
    "    p090_acc.append(acc)\n",
    "    p090_size.append(size)\n",
    "# 558717"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 134310,
     "status": "ok",
     "timestamp": 1589205976462,
     "user": {
      "displayName": "KD Lin",
      "photoUrl": "",
      "userId": "07150804307204552996"
     },
     "user_tz": -480
    },
    "id": "pWoc4zWVKbDx",
    "outputId": "c631f2be-1db7-479d-84b4-7865d8d2f540"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f167519b5f8>"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(np.array(p095_size)/1000,p095_acc, \"o-\",  label = '0.95')\n",
    "plt.plot(np.array(p090_size)/1000, p090_acc, \"*-\",  label = '0.90')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ezb96y6sTrN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "main.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
