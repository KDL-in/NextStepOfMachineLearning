{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"“hw7_Knowledge_Distillation.ipynb”的副本","provenance":[{"file_id":"1iuEkPP-SvCopHEN9X6xiPA8E6eACbL5u","timestamp":1588989835136}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"b5cFq_TgWlQ_","colab_type":"text"},"source":["# Homework 7 - Network Compression (Knowledge Distillation)\n","\n","> Author: Arvin Liu (b05902127@ntu.edu.tw)\n","\n","若有任何問題，歡迎來信至助教信箱 ntu-ml-2020spring-ta@googlegroups.com"]},{"cell_type":"code","metadata":{"id":"bpmQUZhukmqe","colab_type":"code","colab":{}},"source":["# Download dataset\n","!gdown --id '19CzXudqN58R3D-1G8KeFWk8UDQwlb8is' --output food-11.zip\n","# Unzip the files\n","!unzip food-11.zip"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vNiZCGrIYKdR","colab_type":"text"},"source":["# Readme\n","\n","\n","HW7的任務是模型壓縮 - Neural Network Compression。\n","\n","Compression有很多種門派，在這裡我們會介紹上課出現過的其中四種，分別是:\n","\n","* 知識蒸餾 Knowledge Distillation\n","* 網路剪枝 Network Pruning\n","* 用少量參數來做CNN Architecture Design\n","* 參數量化 Weight Quantization\n","\n","在這個notebook中我們會介紹Knowledge Distillation，\n","而我們有提供已經學習好的大model方便大家做Knowledge Distillation。\n","而我們使用的小model是\"Architecture Design\"過的model。\n","\n","* Architecute Design在同目錄中的hw7_Architecture_Design.ipynb。\n","* 下載pretrained大model(47.2M): https://drive.google.com/file/d/1B8ljdrxYXJsZv2vmTequdPOofp3VF3NN/view?usp=sharing\n","  * 請使用torchvision提供的ResNet18，把num_classes改成11後load進去即可。(後面有範例。)"]},{"cell_type":"code","metadata":{"id":"XdzskhdEb65Z","colab_type":"code","outputId":"5197b6fa-b795-40c8-e634-3f3e83e4fdbd","executionInfo":{"status":"ok","timestamp":1589086488455,"user_tz":-480,"elapsed":70331,"user":{"displayName":"KD Lin","photoUrl":"","userId":"07150804307204552996"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["import torch\n","import os\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.models as models\n","# Load進我們的Model架構(在hw7_Architecture_Design.ipynb內)\n","!gdown --id '1lJS0ApIyi7eZ2b3GMyGxjPShI8jXM2UC' --output \"hw7_Architecture_Design.ipynb\"\n","%run \"hw7_Architecture_Design.ipynb\""],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1lJS0ApIyi7eZ2b3GMyGxjPShI8jXM2UC\n","To: /content/hw7_Architecture_Design.ipynb\n","\r  0% 0.00/8.78k [00:00<?, ?B/s]\r100% 8.78k/8.78k [00:00<00:00, 7.06MB/s]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bdUtCxBBcH0B","colab_type":"text"},"source":["Knowledge Distillation\n","===\n","\n","<img src=\"https://i.imgur.com/H2aF7Rv.png=100x\" width=\"500px\">\n","\n","簡單上來說就是讓已經做得很好的大model們去告訴小model\"如何\"學習。\n","而我們如何做到這件事情呢? 就是利用大model預測的logits給小model當作標準就可以了。\n","\n","## 為甚麼這會work?\n","* 例如當data不是很乾淨的時候，對一般的model來說他是個noise，只會干擾學習。透過去學習其他大model預測的logits會比較好。\n","* label和label之間可能有關連，這可以引導小model去學習。例如數字8可能就和6,9,0有關係。\n","* 弱化已經學習不錯的target(?)，避免讓其gradient干擾其他還沒學好的task。\n","\n","\n","## 要怎麼實作?\n","* $Loss = \\alpha T^2 \\times KL(\\frac{\\text{Teacher's Logits}}{T} || \\frac{\\text{Student's Logits}}{T}) + (1-\\alpha)(\\text{原本的Loss})$\n","\n","\n","* 以下code為甚麼要對student使用log_softmax: https://github.com/peterliht/knowledge-distillation-pytorch/issues/2\n","* reference: [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)"]},{"cell_type":"code","metadata":{"id":"M-dSi_P-4les","colab_type":"code","colab":{}},"source":["def loss_fn_kd(outputs, labels, teacher_outputs, T=20, alpha=0.5):\n","    # 一般的Cross Entropy\n","    hard_loss = F.cross_entropy(outputs, labels) * (1. - alpha)\n","    # 讓logits的log_softmax對目標機率(teacher的logits/T後softmax)做KL Divergence。\n","    soft_loss = nn.KLDivLoss(reduction='batchmean')(F.log_softmax(outputs/T, dim=1),\n","                             F.softmax(teacher_outputs/T, dim=1)) * (alpha * T * T)\n","    return hard_loss + soft_loss"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NfnRoOt5VIze","colab_type":"text"},"source":["# Data Processing\n","\n","我們的Dataset使用的是跟Hw3 - CNN同樣的Dataset，因此這個區塊的Augmentation / Read Image大家參考或直接抄就好。\n","\n","如果有不會的話可以回去看Hw3的colab。\n","\n","需要注意的是如果要自己寫的話，Augment的方法最好使用我們的方法，避免輸入有差異導致Teacher Net預測不好。"]},{"cell_type":"code","metadata":{"id":"ExdUvTRaVNOT","colab_type":"code","colab":{}},"source":["import re\n","import torch\n","from glob import glob\n","from PIL import Image\n","import torchvision.transforms as transforms\n","\n","class MyDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, folderName, transform=None):\n","        self.transform = transform\n","        self.data = []\n","        self.label = []\n","\n","        for img_path in sorted(glob(folderName + '/*.jpg')):\n","            try:\n","                # Get classIdx by parsing image path\n","                class_idx = int(re.findall(re.compile(r'\\d+'), img_path)[1])\n","            except:\n","                # if inference mode (there's no answer), class_idx default 0\n","                class_idx = 0\n","\n","            image = Image.open(img_path)\n","            # Get File Descriptor\n","            image_fp = image.fp\n","            image.load()\n","            # Close File Descriptor (or it'll reach OPEN_MAX)\n","            image_fp.close()\n","\n","            self.data.append(image)\n","            self.label.append(class_idx)\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","        image = self.data[idx]\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, self.label[idx]\n","\n","\n","trainTransform = transforms.Compose([\n","    transforms.RandomCrop(256, pad_if_needed=True, padding_mode='symmetric'),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(15),\n","    transforms.ToTensor(),\n","])\n","testTransform = transforms.Compose([\n","    transforms.CenterCrop(256),\n","    transforms.ToTensor(),\n","])\n","\n","def get_dataloader(mode='training', batch_size=32):\n","\n","    assert mode in ['training', 'testing', 'validation']\n","\n","    dataset = MyDataset(\n","        f'./food-11/{mode}',\n","        transform=trainTransform if mode == 'training' else testTransform)\n","\n","    dataloader = torch.utils.data.DataLoader(\n","        dataset,\n","        batch_size=batch_size,\n","        shuffle=(mode == 'training'))\n","\n","    return dataloader\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ACPwL9_JWceQ","colab_type":"text"},"source":["# Pre-processing\n","\n","我們已經提供TeacherNet的state_dict，其架構是torchvision提供的ResNet18。\n","\n","至於StudentNet的架構則在hw7_Architecture_Design.ipynb中。\n","\n","這裡我們使用的Optimizer為AdamW，沒有為甚麼，就純粹我想用。"]},{"cell_type":"code","metadata":{"id":"wzuuGvnbWkG8","colab_type":"code","colab":{}},"source":["# get dataloader\n","train_dataloader = get_dataloader('training', batch_size=32)\n","valid_dataloader = get_dataloader('validation', batch_size=32)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZWdQtDtgoGCp","colab_type":"code","outputId":"c30d9b66-2830-4a09-db99-bb74e7470729","executionInfo":{"status":"ok","timestamp":1589086568920,"user_tz":-480,"elapsed":148255,"user":{"displayName":"KD Lin","photoUrl":"","userId":"07150804307204552996"}},"colab":{"base_uri":"https://localhost:8080/","height":89}},"source":["!gdown --id '1B8ljdrxYXJsZv2vmTequdPOofp3VF3NN' --output teacher_resnet18.bin\n","\n","teacher_net = models.resnet18(pretrained=False, num_classes=11).cuda()\n","student_net = StudentNet(base=16).cuda()\n","\n","teacher_net.load_state_dict(torch.load(f'./teacher_resnet18.bin'))\n","optimizer = optim.AdamW(student_net.parameters(), lr=1e-3)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1B8ljdrxYXJsZv2vmTequdPOofp3VF3NN\n","To: /content/teacher_resnet18.bin\n","44.8MB [00:00, 123MB/s]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Wvc1W5yO2QaE","colab_type":"text"},"source":["# Start Training\n","\n","* 剩下的步驟與你在做Hw3 - CNN的時候一樣。\n","\n","## 小提醒\n","\n","* torch.no_grad是指接下來的運算或該tensor不需要算gradient。\n","* model.eval()與model.train()差在於Batchnorm要不要紀錄，以及要不要做Dropout。\n","\n"]},{"cell_type":"code","metadata":{"id":"-TzmWtT62Qmy","colab_type":"code","outputId":"c59d863d-45ba-4552-c87a-ea8e1d7ae748","executionInfo":{"status":"error","timestamp":1583671594964,"user_tz":-480,"elapsed":639,"user":{"displayName":"李宏毅","photoUrl":"","userId":"14645962671355321712"}},"colab":{"base_uri":"https://localhost:8080/","height":233}},"source":["def run_epoch(dataloader, update=True, alpha=0.5):\n","    total_num, total_hit, total_loss = 0, 0, 0\n","    for now_step, batch_data in enumerate(dataloader):\n","        # 清空 optimizer\n","        optimizer.zero_grad()\n","        # 處理 input\n","        inputs, hard_labels = batch_data\n","        inputs = inputs.cuda()\n","        hard_labels = torch.LongTensor(hard_labels).cuda()\n","        # 因為Teacher沒有要backprop，所以我們使用torch.no_grad\n","        # 告訴torch不要暫存中間值(去做backprop)以浪費記憶體空間。\n","        with torch.no_grad():\n","            soft_labels = teacher_net(inputs)\n","\n","        if update:\n","            logits = student_net(inputs)\n","            # 使用我們之前所寫的融合soft label&hard label的loss。\n","            # T=20是原始論文的參數設定。\n","            loss = loss_fn_kd(logits, hard_labels, soft_labels, 20, alpha)\n","            loss.backward()\n","            optimizer.step()    \n","        else:\n","            # 只是算validation acc的話，就開no_grad節省空間。\n","            with torch.no_grad():\n","                logits = student_net(inputs)\n","                loss = loss_fn_kd(logits, hard_labels, soft_labels, 20, alpha)\n","            \n","        total_hit += torch.sum(torch.argmax(logits, dim=1) == hard_labels).item()\n","        total_num += len(inputs)\n","\n","        total_loss += loss.item() * len(inputs)\n","    return total_loss / total_num, total_hit / total_num\n","\n","\n","# TeacherNet永遠都是Eval mode.\n","teacher_net.eval()\n","now_best_acc = 0\n","for epoch in range(200):\n","    student_net.train()\n","    train_loss, train_acc = run_epoch(train_dataloader, update=True)\n","    student_net.eval()\n","    valid_loss, valid_acc = run_epoch(valid_dataloader, update=False)\n","\n","    # 存下最好的model。\n","    if valid_acc > now_best_acc:\n","        now_best_acc = valid_acc\n","        torch.save(student_net.state_dict(), 'student_model.bin')\n","    print('epoch {:>3d}: train loss: {:6.4f}, acc {:6.4f} valid loss: {:6.4f}, acc {:6.4f}'.format(\n","        epoch, train_loss, train_acc, valid_loss, valid_acc))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["epoch   0: train loss: 15.0696, acc 0.3129 valid loss: 14.6785, acc 0.4009\n","epoch   1: train loss: 13.4078, acc 0.3976 valid loss: 14.6179, acc 0.4143\n","epoch   2: train loss: 12.5794, acc 0.4428 valid loss: 12.6703, acc 0.5070\n","epoch   3: train loss: 11.7921, acc 0.4846 valid loss: 11.9102, acc 0.5388\n","epoch   4: train loss: 11.1280, acc 0.5067 valid loss: 11.5166, acc 0.5402\n","epoch   5: train loss: 10.5860, acc 0.5384 valid loss: 11.2337, acc 0.5315\n","epoch   6: train loss: 10.2720, acc 0.5528 valid loss: 10.3372, acc 0.5723\n","epoch   7: train loss: 9.8336, acc 0.5677 valid loss: 10.4162, acc 0.5991\n","epoch   8: train loss: 9.4553, acc 0.5860 valid loss: 11.3114, acc 0.5262\n","epoch   9: train loss: 9.0750, acc 0.5976 valid loss: 9.2036, acc 0.6315\n","epoch  10: train loss: 8.9201, acc 0.6024 valid loss: 10.4709, acc 0.5933\n","epoch  11: train loss: 8.5036, acc 0.6253 valid loss: 9.0605, acc 0.6210\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0GObCiGNtPkZ","colab_type":"text"},"source":["# Inference\n","\n","同Hw3，請參考該作業:)。\n"]},{"cell_type":"markdown","metadata":{"id":"DIcblvbUCTOP","colab_type":"text"},"source":["# Q&A\n","\n","有任何問題Network Compression的問題可以寄信到b05902127@ntu.edu.tw / ntu-ml-2020spring-ta@googlegroups.com。\n","\n","時間允許的話我會更新在這裡。"]}]}